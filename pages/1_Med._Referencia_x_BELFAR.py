# --- IMPORTS ---
import streamlit as st
# from style_utils import hide_streamlit_toolbar # Removi a depend√™ncia que n√£o estava no c√≥digo
import fitz # PyMuPDF
import docx
import re
import spacy
from thefuzz import fuzz
from spellchecker import SpellChecker
import difflib
import unicodedata

hide_streamlit_UI = """
<style>
/* Esconde o cabe√ßalho do Streamlit Cloud (com 'Fork' e GitHub) */
[data-testid="stHeader"] {
display: none !important;
visibility: hidden !important;
}
/* Esconde o menu hamburger (dentro do app) */
[data-testid="main-menu-button"] {
display: none !important;
}
/* Esconde o rodap√© gen√©rico (garantia extra) */
footer {
display: none !important;
visibility: hidden !important;
}

/* --- NOVOS SELETORES (MAIS AGRESSIVOS) PARA O BADGE INFERIOR --- */

/* Esconde o container principal do badge */
[data-testid="stStatusWidget"] {
display: none !important;
visibility: hidden !important;
}

/* Esconde o 'Created by' */
[data-testid="stCreatedBy"] {
display: none !important;
visibility: hidden !important;
}

/* Esconde o 'Hosted with Streamlit' */
[data-testid="stHostedBy"] {
display: none !important;
visibility: hidden !important;
}
</style>
"""
st.markdown(hide_streamlit_UI, unsafe_allow_html=True)


# ----------------- MODELO NLP -----------------
@st.cache_resource
def carregar_modelo_spacy():
    """Carrega o modelo de linguagem SpaCy de forma otimizada."""
    try:
        return spacy.load("pt_core_news_lg")
    except OSError:
        st.error("Modelo 'pt_core_news_lg' n√£o encontrado. Execute: python -m spacy download pt_core_news_lg")
        return None

nlp = carregar_modelo_spacy()

# ----------------- EXTRA√á√ÉO -----------------
def extrair_texto(arquivo, tipo_arquivo):
    if arquivo is None:
        return "", f"Arquivo {tipo_arquivo} n√£o enviado."
    try:
        arquivo.seek(0)
        texto = ""
        if tipo_arquivo == 'pdf':
            full_text_list = []
            with fitz.open(stream=arquivo.read(), filetype="pdf") as doc:
                for page in doc:
                    blocks = page.get_text("blocks", sort=True)
                    page_text = "".join([b[4] for b in blocks])
                    full_text_list.append(page_text)
            texto = "\n".join(full_text_list)
        elif tipo_arquivo == 'docx':
            doc = docx.Document(arquivo)
            texto = "\n".join([p.text for p in doc.paragraphs])
            
        if texto:
            caracteres_invisiveis = ['\u00AD', '\u200B', '\u200C', '\u200D', '\uFEFF']
            for char in caracteres_invisiveis:
                texto = texto.replace(char, '')
            texto = texto.replace('\r\n', '\n').replace('\r', '\n')
            texto = texto.replace('\u00A0', ' ')
            texto = re.sub(r'(\w+)-\n(\w+)', r'\1\2', texto, flags=re.IGNORECASE)
            linhas = texto.split('\n')
            padrao_rodape = re.compile(r'bula do paciente|p√°gina \d+\s*de\s*\d+', re.IGNORECASE)
            linhas_filtradas = [linha for linha in linhas if not padrao_rodape.search(linha.strip())]
            texto = "\n".join(linhas_filtradas)
            texto = re.sub(r'\n{3,}', '\n\n', texto)
            texto = re.sub(r'[ \t]+', ' ', texto)
            texto = texto.strip()

        return texto, None
    except Exception as e:
        return "", f"Erro ao ler o arquivo {tipo_arquivo}: {e}"

def truncar_apos_anvisa(texto):
    if not isinstance(texto, str):
        return texto
    regex_anvisa = r"(aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova√ß√£o\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    match = re.search(regex_anvisa, texto, re.IGNORECASE)
    if match:
        end_of_line_pos = texto.find('\n', match.end())
        if end_of_line_pos != -1:
            return texto[:end_of_line_pos]
        else:
            return texto
    return texto

# ----------------- CONFIGURA√á√ÉO DE SE√á√ïES -----------------
def obter_secoes_por_tipo(tipo_bula):
    secoes = {
        "Paciente": [
            "APRESENTA√á√ïES", "COMPOSI√á√ÉO", "PARA QUE ESTE MEDICAMENTO √â INDICADO",
            "COMO ESTE MEDICAMENTO FUNCIONA?", "QUANDO N√ÉO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
            "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
            "COMO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
            # --- [CORRE√á√ÉO PROBLEMA 3] --- 
            # Adicionei o "PODE ME CAUSAR" como um alias mental, mas o t√≠tulo correto √© "PODE CAUSAR"
            "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?", 
            "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
            "DIZERES LEGAIS"
        ],
        "Profissional": [
            "APRESENTA√á√ïES", "COMPOSI√á√ÉO", "INDICA√á√ïES", "RESULTADOS DE EFIC√ÅCIA",
            "CARACTER√çSTICAS FARMACOL√ìGICAS", "CONTRAINDICA√á√ïES",
            "ADVERT√äNCIAS E PRECAU√á√ïES", "INTERA√á√ïES MEDICAMENTOSAS",
            "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO", "POSOLOGIA E MODO DE USAR",
            "REA√á√ïES ADVERSAS", "SUPERDOSE", "DIZERES LEGAIS"
        ]
    }
    return secoes.get(tipo_bula, [])

def obter_aliases_secao():
    return {
        "INDICA√á√ïES": "PARA QUE ESTE MEDICAMENTO √â INDICADO?",
        "CONTRAINDICA√á√ïES": "QUANDO N√ÉO DEVO USAR ESTE MEDICAMENTO?",
        "POSOLOGIA E MODO DE USAR": "COMO DEVO USAR ESTE MEDICAMENTO?",
        # --- [CORRE√á√ÉO PROBLEMA 3] ---
        # Adicionei o "PODE ME CAUSAR?" como um alias para "PODE CAUSAR?"
        "REA√á√ïES ADVERSAS": "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?",
        "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?": "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?",
        "SUPERDOSE": "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
        "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO": "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?"
    }

def obter_secoes_ignorar_ortografia():
    return ["COMPOSI√á√ÉO", "DIZERES LEGAIS"]

def obter_secoes_ignorar_comparacao():
    return ["COMPOSI√á√ÉO", "DIZERES LEGAIS", "APRESENTA√á√ïES", "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?"]

# ----------------- NORMALIZA√á√ÉO -----------------
def normalizar_texto(texto):
    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')
    texto = re.sub(r'[^\w\s]', '', texto)
    texto = ' '.join(texto.split())
    return texto.lower()

def normalizar_titulo_para_comparacao(texto):
    """Normaliza√ß√£o robusta para t√≠tulos, removendo acentos, pontua√ß√£o e numera√ß√£o inicial."""
    texto_norm = normalizar_texto(texto)
    texto_norm = re.sub(r'^\d+\s*[\.\-)]*\s*', '', texto_norm).strip()
    return texto_norm

# --- [NOVO] ---
# Helper para criar IDs √∫nicos para as √¢ncoras HTML
def _create_anchor_id(secao_nome, prefix):
    """Cria um ID HTML seguro para a √¢ncora."""
    norm = normalizar_texto(secao_nome)
    # Remove caracteres que podem quebrar o seletor JS
    norm_safe = re.sub(r'[^a-z0-9\-]', '-', norm)
    return f"anchor-{prefix}-{norm_safe}"

# ----------------- ARQUITETURA DE MAPEAMENTO DE SE√á√ïES (VERS√ÉO FINAL) -----------------
def is_titulo_secao(linha):
    """Retorna True se a linha for um poss√≠vel t√≠tulo de se√ß√£o puro."""
    linha = linha.strip()
    if len(linha) < 4:
        return False
    # Aumentei de 12 para 20 palavras
    if len(linha.split()) > 20:
        return False
    if linha.endswith('.') or linha.endswith(':'):
        return False
    if re.search(r'\>\s*\<', linha):
        return False
    # Aumentei de 80 para 120 caracteres
    if len(linha) > 120:
        return False
    return True

def mapear_secoes(texto_completo, secoes_esperadas):
    mapa = []
    linhas = texto_completo.split('\n')
    aliases = obter_aliases_secao()
    titulos_possiveis = {}
    for secao in secoes_esperadas:
        titulos_possiveis[secao] = secao
    for alias, canonico in aliases.items():
        if canonico in secoes_esperadas:
            titulos_possiveis[alias] = canonico

    for idx, linha in enumerate(linhas):
        linha_limpa = linha.strip()
        if not is_titulo_secao(linha_limpa):
            continue

        linha_norm = normalizar_texto(linha_limpa)
        if not linha_norm:
            continue

        best_match_score = 0
        best_match_canonico = None

        for titulo_possivel, titulo_canonico in titulos_possiveis.items():
            score = fuzz.token_set_ratio(normalizar_titulo_para_comparacao(titulo_possivel), normalizar_titulo_para_comparacao(linha_limpa))
            if score > best_match_score:
                best_match_score = score
                best_match_canonico = titulo_canonico

        if best_match_score >= 98:
            if not mapa or mapa[-1]['canonico'] != best_match_canonico:
                mapa.append({
                    'canonico': best_match_canonico,
                    'titulo_encontrado': linha_limpa,
                    'linha_inicio': idx,
                    'score': best_match_score
                })
    mapa.sort(key=lambda x: x['linha_inicio'])
    return mapa

# --- [CORRE√á√ÉO T√çTULOS DE 3 LINHAS] ---
def obter_dados_secao(secao_canonico, mapa_secoes, linhas_texto, tipo_bula):
    """
    Extrai o conte√∫do de uma se√ß√£o, procurando ativamente pelo pr√≥ximo t√≠tulo para determinar o fim.
    Esta vers√£o verifica se o pr√≥ximo t√≠tulo est√° em 1, 2 ou 3 linhas consecutivas.
    """
    # T√≠tulos oficiais da bula para o tipo selecionado
    TITULOS_OFICIAIS = {
        "Paciente": [
            "APRESENTA√á√ïES", "COMPOSI√á√ÉO", "PARA QUE ESTE MEDICAMENTO √â INDICADO",
            "COMO ESTE MEDICAMENTO FUNCIONA?", "QUANDO N√ÉO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
            "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
            "COMO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
            "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?", # Corrigido aqui
            "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
            "DIZERES LEGAIS"
        ],
        "Profissional": [
            "APRESENTA√á√ïES", "COMPOSI√á√ÉO", "INDICA√á√ïES", "RESULTADOS DE EFIC√ÅCIA",
            "CARACTER√çSTICAS FARMACOL√ìGICAS", "CONTRAINDICA√á√ïES",
            "ADVERT√äNCIAS E PRECAU√á√ïES", "INTERA√á√ïES MEDICAMENTOSAS",
            "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO", "POSOLOGIA E MODO DE USAR",
            "REA√á√ïES ADVERSAS", "SUPERDOSE", "DIZERES LEGAIS"
        ]
    }

    titulos_lista = TITULOS_OFICIAIS.get(tipo_bula, [])
    # Normaliza a lista de t√≠tulos oficiais uma vez para otimizar a busca
    titulos_norm_set = {normalizar_titulo_para_comparacao(t) for t in titulos_lista}
    
    # Adiciona os aliases ao set de t√≠tulos para busca
    aliases = obter_aliases_secao()
    for alias, canonico in aliases.items():
        if canonico in titulos_lista:
                titulos_norm_set.add(normalizar_titulo_para_comparacao(alias))


    for i, secao_mapa in enumerate(mapa_secoes):
        if secao_mapa['canonico'] != secao_canonico:
            continue

        titulo_encontrado = secao_mapa['titulo_encontrado']
        linha_inicio = secao_mapa['linha_inicio']
        linha_inicio_conteudo = linha_inicio + 1

        # --- L√ìGICA DE BUSCA APRIMORADA (1, 2 ou 3 linhas) ---
        prox_idx = None
        for j in range(linha_inicio_conteudo, len(linhas_texto)):
            # Verifica a linha atual (busca de 1 linha)
            linha_atual = linhas_texto[j].strip()
            linha_atual_norm = normalizar_titulo_para_comparacao(linha_atual)

            
            if linha_atual_norm in titulos_norm_set: 
                prox_idx = j # Encontrou um t√≠tulo em uma √∫nica linha
                break # Para o loop 'j'

            # Se n√£o encontrou, verifica a combina√ß√£o da linha atual + pr√≥xima (busca de 2 linhas)
            if (j + 1) < len(linhas_texto):
                linha_seguinte = linhas_texto[j + 1].strip()
                # Concatena a linha atual com a pr√≥xima para formar um poss√≠vel t√≠tulo
                titulo_duas_linhas = f"{linha_atual} {linha_seguinte}"
                titulo_duas_linhas_norm = normalizar_titulo_para_comparacao(titulo_duas_linhas)

                if titulo_duas_linhas_norm in titulos_norm_set: 
                    prox_idx = j # Encontrou um t√≠tulo dividido em duas linhas
                    break # Para o loop 'j'

            # --- [IN√çCIO DA NOVA L√ìGICA (T√çTULO 3 LINHAS)] ---
            # Se n√£o encontrou, verifica a combina√ß√£o de 3 linhas
            if (j + 2) < len(linhas_texto):
                linha_seguinte = linhas_texto[j + 1].strip()
                linha_terceira = linhas_texto[j + 2].strip()
                
                # Combina as 3 linhas
                titulo_tres_linhas = f"{linha_atual} {linha_seguinte} {linha_terceira}"
                titulo_tres_linhas_norm = normalizar_titulo_para_comparacao(titulo_tres_linhas)

                if titulo_tres_linhas_norm in titulos_norm_set:
                    prox_idx = j # Encontrou um t√≠tulo dividido em TR√äS linhas
                    break # Para o loop 'j'
            # --- [FIM DA NOVA L√ìGICA (T√çTULO 3 LINHAS)] ---
        # --- FIM DA L√ìGICA DE BUSCA ---

        linha_fim = prox_idx if prox_idx is not None else len(linhas_texto)

        conteudo = [linhas_texto[idx] for idx in range(linha_inicio_conteudo, linha_fim)]
        conteudo_final = "\n".join(conteudo).strip()
        return True, titulo_encontrado, conteudo_final

    return False, None, ""

# ----------------- COMPARA√á√ÉO DE CONTE√öDO -----------------
# --- [CORRE√á√ÉO MOSTRAR TODAS AS SE√á√ïES] ---
def verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula):
    secoes_esperadas = obter_secoes_por_tipo(tipo_bula)
    secoes_faltantes, diferencas_conteudo, similaridades_secoes, diferencas_titulos = [], [], [], []
    secoes_analisadas = [] # <-- [NOVO] Lista para todas as se√ß√µes
    
    secoes_ignorar_upper = [s.upper() for s in obter_secoes_ignorar_comparacao()]

    linhas_ref = texto_ref.split('\n')
    linhas_belfar = texto_belfar.split('\n')
    mapa_ref = mapear_secoes(texto_ref, secoes_esperadas)
    mapa_belfar = mapear_secoes(texto_belfar, secoes_esperadas)

    secoes_belfar_encontradas = {m['canonico']: m for m in mapa_belfar}

    for secao in secoes_esperadas:
        melhor_titulo = None 
        encontrou_ref, _, conteudo_ref = obter_dados_secao(secao, mapa_ref, linhas_ref, tipo_bula)
        encontrou_belfar, titulo_belfar, conteudo_belfar = obter_dados_secao(secao, mapa_belfar, linhas_belfar, tipo_bula)

        if not encontrou_belfar:
            melhor_score = 0
            melhor_titulo = None
            for m in mapa_belfar:
                score = fuzz.token_set_ratio(normalizar_titulo_para_comparacao(secao), normalizar_titulo_para_comparacao(m['titulo_encontrado']))
                if score > melhor_score:
                    melhor_score = score
                    melhor_titulo = m['titulo_encontrado']
            if melhor_score >= 95:
                diferencas_titulos.append({'secao_esperada': secao, 'titulo_encontrado': melhor_titulo})
                for m in mapa_belfar:
                    if m['titulo_encontrado'] == melhor_titulo:
                        # L√≥gica para pegar conte√∫do da se√ß√£o encontrada por similaridade
                        next_section_start = len(linhas_belfar)
                        current_index = mapa_belfar.index(m)
                        if current_index + 1 < len(mapa_belfar):
                            next_section_start = mapa_belfar[current_index + 1]['linha_inicio']
                        
                        # Pega o conte√∫do a partir da linha *ap√≥s* o t√≠tulo encontrado
                        conteudo_belfar = "\n".join(linhas_belfar[m['linha_inicio']+1:next_section_start])
                        break
                encontrou_belfar = True
            else:
                secoes_faltantes.append(secao)
                continue

        if encontrou_ref and encontrou_belfar:
            secao_comp = normalizar_titulo_para_comparacao(secao)
            # Usa o 'titulo_belfar' (da busca direta) ou 'melhor_titulo' (da busca fuzzy)
            titulo_belfar_comp = normalizar_titulo_para_comparacao(titulo_belfar if titulo_belfar else melhor_titulo)

            if secao_comp != titulo_belfar_comp:
                if not any(d['secao_esperada'] == secao for d in diferencas_titulos):
                    diferencas_titulos.append({'secao_esperada': secao, 'titulo_encontrado': titulo_belfar if titulo_belfar else melhor_titulo})
            
            titulo_real_encontrado = titulo_belfar if titulo_belfar else melhor_titulo
            
            if secao.upper() in secoes_ignorar_upper:
                # --- [NOVO] ---
                # Adiciona √† lista, mas marca como ignorada
                secoes_analisadas.append({
                    'secao': secao,
                    'conteudo_ref': conteudo_ref,
                    'conteudo_belfar': conteudo_belfar,
                    'titulo_encontrado': titulo_real_encontrado,
                    'tem_diferenca': False,
                    'ignorada': True
                })
                # --- [FIM NOVO] ---
                continue

            # --- [NOVO] ---
            # Verifica a diferen√ßa e armazena o resultado
            tem_diferenca = False
            if normalizar_texto(conteudo_ref) != normalizar_texto(conteudo_belfar):
                tem_diferenca = True
                
                diferencas_conteudo.append({
                    'secao': secao, 
                    'conteudo_ref': conteudo_ref, 
                    'conteudo_belfar': conteudo_belfar,
                    'titulo_encontrado': titulo_real_encontrado # <-- Salva o t√≠tulo real
                })
                similaridades_secoes.append(0)
            else:
                similaridades_secoes.append(100)

            # --- [NOVO] ---
            # Adiciona *todas* as se√ß√µes encontradas e comparadas √† lista
            secoes_analisadas.append({
                'secao': secao,
                'conteudo_ref': conteudo_ref,
                'conteudo_belfar': conteudo_belfar,
                'titulo_encontrado': titulo_real_encontrado,
                'tem_diferenca': tem_diferenca,
                'ignorada': False
            })
            # --- [FIM NOVO] ---

    # --- [MODIFICADO] ---
    # Retorna a nova lista de se√ß√µes analisadas
    return secoes_faltantes, diferencas_conteudo, similaridades_secoes, diferencas_titulos, secoes_analisadas
    # --- [FIM MODIFICADO] ---


# ----------------- ORTOGRAFIA -----------------
def checar_ortografia_inteligente(texto_para_checar, texto_referencia, tipo_bula):
    if not nlp or not texto_para_checar:
        return []

    try:
        secoes_ignorar = obter_secoes_ignorar_ortografia()
        secoes_todas = obter_secoes_por_tipo(tipo_bula)
        texto_filtrado_para_checar = []

        mapa_secoes = mapear_secoes(texto_para_checar, secoes_todas)
        linhas_texto = texto_para_checar.split('\n')

        for secao_nome in secoes_todas:
            if secao_nome.upper() in [s.upper() for s in secoes_ignorar]:
                continue
            encontrou, _, conteudo = obter_dados_secao(secao_nome, mapa_secoes, linhas_texto, tipo_bula)
            if encontrou and conteudo:
                linhas_conteudo = conteudo.split('\n')
                if len(linhas_conteudo) > 1:
                    texto_filtrado_para_checar.append('\n'.join(linhas_conteudo[1:]))

        texto_final_para_checar = '\n'.join(texto_filtrado_para_checar)
        if not texto_final_para_checar:
            return []

        spell = SpellChecker(language='pt')
        palavras_a_ignorar = {"alair", "belfar", "peticionamento", "urotrobel"}
        vocab_referencia = set(re.findall(r'\b[a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß√º]+\b', texto_referencia.lower()))
        doc = nlp(texto_para_checar)
        entidades = {ent.text.lower() for ent in doc.ents}

        spell.word_frequency.load_words(
            vocab_referencia.union(entidades).union(palavras_a_ignorar)
        )

        palavras = re.findall(r'\b[a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß√º]+\b', texto_final_para_checar.lower())
        erros = spell.unknown(palavras)
        return list(sorted(set([e for e in erros if len(e) > 3])))[:20]

    except Exception as e:
        return []

# ----------------- DIFEREN√áAS PALAVRA A PALAVRA -----------------
def marcar_diferencas_palavra_por_palavra(texto_ref, texto_belfar, eh_referencia):
    def tokenizar(txt):
        return re.findall(r'\n|[A-Za-z√Ä-√ñ√ò-√∂√∏-√ø0-9_]+|[^\w\s]', txt, re.UNICODE)

    def norm(tok):
        # --- [CORRE√á√ÉO PROBLEMA 2] ---
        # Trata quebras de linha como espa√ßo *apenas para a compara√ß√£o*,
        # evitando que diferen√ßas de formata√ß√£o sejam marcadas como diverg√™ncia.
        if tok == '\n':
            return ' '
        # --- [FIM DA CORRE√á√ÉO] ---
        
        if re.match(r'[A-Za-z√Ä-√ñ√ò-√∂√∏-√ø0-9_]+$', tok):
            return normalizar_texto(tok)
        return tok

    ref_tokens = tokenizar(texto_ref)
    bel_tokens = tokenizar(texto_belfar)
    ref_norm = [norm(t) for t in ref_tokens]
    bel_norm = [norm(t) for t in bel_tokens]

    matcher = difflib.SequenceMatcher(None, ref_norm, bel_norm, autojunk=False)
    indices = set()
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag != 'equal':
            indices.update(range(i1, i2) if eh_referencia else range(j1, j2))

    tokens = ref_tokens if eh_referencia else bel_tokens
    marcado = []
    for idx, tok in enumerate(tokens):
        if idx in indices and tok.strip() != '':
            marcado.append(f"<mark style='background-color: #ffff99; padding: 2px;'>{tok}</mark>")
        else:
            marcado.append(tok)

    resultado = ""
    for i, tok in enumerate(tokens):
        if i == 0:
            resultado += tok
            continue
        raw_tok = re.sub(r'^<mark[^>]*>|</mark>$', '', tok)
        
        # --- [CORRE√á√ÉO PROBLEMA 2 - AJUSTE] ---
        # Impede que um espa√ßo seja adicionado *antes* de uma quebra de linha.
        if raw_tok == '\n':
            resultado += tok
        elif re.match(r'^[^\w\s]$', raw_tok):
            resultado += tok
        # --- [FIM DA CORRE√á√ÉO] ---
        else:
            resultado += " " + tok
            
    resultado = re.sub(r'\s+([.,;:!?)])', r'\1', resultado)
    resultado = re.sub(r'(\()\s+', r'\1', resultado)
    resultado = re.sub(r"(</mark>)\s+(<mark[^>]*>)", " ", resultado)
    return resultado

# ----------------- MARCA√á√ÉO POR SE√á√ÉO COM √çNDICES -----------------
# --- [MODIFICADO] ---
# Esta fun√ß√£o agora adiciona um <div id="..."> em volta do conte√∫do divergente
def marcar_divergencias_html(texto_original, secoes_problema, erros_ortograficos, tipo_bula, eh_referencia=False):
    texto_trabalho = texto_original
    if secoes_problema:
        for diff in secoes_problema:
            conteudo_ref = diff['conteudo_ref']
            conteudo_belfar = diff['conteudo_belfar']
            conteudo_a_marcar = conteudo_ref if eh_referencia else conteudo_belfar
            conteudo_marcado = marcar_diferencas_palavra_por_palavra(
                conteudo_ref,
                conteudo_belfar,
                eh_referencia
            )
            
            # --- [NOVA L√ìGICA] ---
            # Cria o ID da √¢ncora e envolve o conte√∫do marcado com ele
            secao_canonico = diff['secao']
            anchor_id = _create_anchor_id(secao_canonico, "ref" if eh_referencia else "bel")
            # Adiciona a √¢ncora (div) em volta do conte√∫do
            # scroll-margin-top adiciona um "padding" ao rolar, para o t√≠tulo n√£o ficar colado no topo
            conteudo_com_ancora = f"<div id='{anchor_id}' style='scroll-margin-top: 20px;'>{conteudo_marcado}</div>"

            if conteudo_a_marcar in texto_trabalho:
                # Substitui o conte√∫do original pelo conte√∫do marcado E com √¢ncora
                texto_trabalho = texto_trabalho.replace(conteudo_a_marcar, conteudo_com_ancora)
            # --- [FIM DA NOVA L√ìGICA] ---

    if erros_ortograficos and not eh_referencia:
        for erro in erros_ortograficos:
            pattern = r'(?<![<>a-zA-Z])(?<!mark>)(?<!;>)\b(' + re.escape(erro) + r')\b(?![<>])'
            texto_trabalho = re.sub(
                pattern,
                r"<mark style='background-color: #FFDDC1; padding: 2px;'>\1</mark>",
                texto_trabalho,
                flags=re.IGNORECASE
            )
            
    regex_anvisa = r"((?:aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova√ß√£o\s+na\s+anvisa:)\s*[\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    match = re.search(regex_anvisa, texto_original, re.IGNORECASE)
    if match:
        frase_anvisa = match.group(1)
        if frase_anvisa in texto_trabalho:
            texto_trabalho = texto_trabalho.replace(
                frase_anvisa,
                f"<mark style='background-color: #cce5ff; padding: 2px; font-weight: 500;'>{frase_anvisa}</mark>",
                1
            )

    return texto_trabalho
# ----------------- RELAT√ìRIO -----------------
# --- [CORRE√á√ÉO MOSTRAR TODAS AS SE√á√ïES] ---
def gerar_relatorio_final(texto_ref, texto_belfar, nome_ref, nome_belfar, tipo_bula):
    
    # --- [NOVO] Script Global (Plano C) ---
    # Injeta a fun√ß√£o de rolagem no escopo GLOBAL (window)
    # Isso garante que a fun√ß√£o `onclick` possa encontr√°-la.
    js_scroll_script = """
    <script>
    // Verifica se a fun√ß√£o j√° n√£o existe para evitar re-declara√ß√£o
    if (!window.handleBulaScroll) {
        window.handleBulaScroll = function(anchorIdRef, anchorIdBel) {
            // Log para debug (Aperte F12 no navegador para ver)
            console.log("Chamada handleBulaScroll:", anchorIdRef, anchorIdBel);

            var containerRef = document.getElementById('container-ref-scroll');
            var containerBel = document.getElementById('container-bel-scroll');
            var anchorRef = document.getElementById(anchorIdRef);
            var anchorBel = document.getElementById(anchorIdBel);

            if (!containerRef || !containerBel) {
                console.error("ERRO: Containers 'container-ref-scroll' ou 'container-bel-scroll' n√£o encontrados.");
                return;
            }
            if (!anchorRef || !anchorBel) {
                console.error("ERRO: √Çncoras '" + anchorIdRef + "' ou '" + anchorIdBel + "' n√£o encontradas.");
                return;
            }

            // 1. Rola a P√ÅGINA PRINCIPAL para a visualiza√ß√£o
            containerRef.scrollIntoView({ behavior: 'smooth', block: 'start' });

            // 2. Rola DENTRO dos containers (ap√≥s a rolagem principal)
            setTimeout(() => {
                try {
                    var topPosRef = anchorRef.offsetTop - containerRef.offsetTop;
                    containerRef.scrollTo({ top: topPosRef - 20, behavior: 'smooth' });
                    // Destaque visual
                    anchorRef.style.transition = 'background-color 0.5s ease-in-out';
                    anchorRef.style.backgroundColor = '#e6f7ff';
                    setTimeout(() => { anchorRef.style.backgroundColor = 'transparent'; }, 2500);
                    
                    var topPosBel = anchorBel.offsetTop - containerBel.offsetTop;
                    containerBel.scrollTo({ top: topPosBel - 20, behavior: 'smooth' });
                    // Destaque visual
                    anchorBel.style.transition = 'background-color 0.5s ease-in-out';
                    anchorBel.style.backgroundColor = '#e6f7ff';
                    setTimeout(() => { anchorBel.style.backgroundColor = 'transparent'; }, 2500);

                    console.log("Rolagem interna EXECUTADA.");
                } catch (e) {
                    console.error("Erro durante a rolagem interna:", e);
                }
            }, 700); // 700ms de espera
        }
        console.log("Fun√ß√£o window.handleBulaScroll DEFINIDA.");
    }
    </script>
    """
    # Injeta o script uma vez no topo do relat√≥rio
    st.markdown(js_scroll_script, unsafe_allow_html=True)
    # --- [FIM DO SCRIPT] ---


    st.header("Relat√≥rio de Auditoria Inteligente")
    regex_anvisa = r"(aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova√ß√£o\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    match_ref = re.search(regex_anvisa, texto_ref.lower())
    match_belfar = re.search(regex_anvisa, texto_belfar.lower())
    data_ref = match_ref.group(2).strip() if match_ref else "N√£o encontrada"
    data_belfar = match_belfar.group(2).strip() if match_belfar else "N√£o encontrada"

    # --- [MODIFICADO] ---
    # Captura a nova lista 'secoes_analisadas'
    secoes_faltantes, diferencas_conteudo, similaridades, diferencas_titulos, secoes_analisadas = verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula)
    # --- [FIM MODIFICADO] ---
    
    erros_ortograficos = checar_ortografia_inteligente(texto_belfar, texto_ref, tipo_bula)
    score_similaridade_conteudo = sum(similaridades) / len(similaridades) if similaridades else 100.0

    st.subheader("Dashboard de Veredito")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Conformidade de Conte√∫do", f"{score_similaridade_conteudo:.0f}%")
    col2.metric("Erros Ortogr√°ficos", len(erros_ortograficos))
    col3.metric("Data ANVISA (BELFAR)", data_belfar)
    col4.metric("Se√ß√µes Faltantes", f"{len(secoes_faltantes)}")

    st.divider()
    st.subheader("Detalhes dos Problemas Encontrados")
    st.info(f"‚ÑπÔ∏è **Datas de Aprova√ß√£o ANVISA:**\n - Refer√™ncia: `{data_ref}`\n - BELFAR: `{data_belfar}`")

    if secoes_faltantes:
        st.error(f"üö® **Se√ß√µes faltantes na bula BELFAR ({len(secoes_faltantes)})**:\n" + "\n".join([f" - {s}" for s in secoes_faltantes]))
    else:
        st.success("‚úÖ Todas as se√ß√µes obrigat√≥rias est√£o presentes")
        
    # --- [IN√çCIO DA MODIFICA√á√ÉO: MOSTRAR TUDO] ---
    # Troca 'if diferencas_conteudo:' por 'if secoes_analisadas:'
    # e itera sobre a nova lista completa.
    if secoes_analisadas:
        
        # Mudei o t√≠tulo para um mais gen√©rico
        st.warning(f"‚ö†Ô∏è **An√°lise de conte√∫do das se√ß√µes (encontradas {len(secoes_analisadas)}):**")

        expander_caixa_style = (
            "height: 350px; overflow-y: auto; border: 2px solid #d0d0d0; border-radius: 6px; "
            "padding: 16px; background-color: #ffffff; font-size: 14px; line-height: 1.8; "
            "font-family: 'Georgia', 'Times New Roman', serif; text-align: justify;"
        )

        # Itera sobre a lista completa
        for diff in secoes_analisadas:
            
            secao_canonico_raw = diff['secao'] # Pega o nome can√¥nico (Ex: "QUAIS OS MALES...")
            titulo_display = diff.get('titulo_encontrado') or secao_canonico_raw
            
            if not titulo_display: 
                titulo_display = secao_canonico_raw

            # L√≥gica para for√ßar o n√∫mero 9 na Se√ß√£o 9
            secao_canonico_norm = normalizar_texto(secao_canonico_raw)
            if "o que fazer se alguem usar uma quantidade maior" in secao_canonico_norm:
                if not normalizar_texto(titulo_display).startswith("9"):
                    titulo_display = f"9. {titulo_display}"

            # --- [NOVA L√ìGICA] ---
            # Define o t√≠tulo e o estado (aberto/fechado) do expander
            # com base nos flags 'tem_diferenca' e 'ignorada'
            if diff['ignorada']:
                expander_label = f"üìÑ {titulo_display} - ‚ö†Ô∏è COMPARA√á√ÉO IGNORADA"
                expander_expanded = False
            elif diff['tem_diferenca']:
                expander_label = f"üìÑ {titulo_display} - ‚ùå CONTE√öDO DIVERGENTE"
                expander_expanded = True # Abre se√ß√µes com problemas
            else:
                expander_label = f"üìÑ {titulo_display} - ‚úÖ CONTE√öDO ID√äNTICO"
                expander_expanded = False # Mant√©m se√ß√µes id√™nticas fechadas
            # --- [FIM NOVA L√ìGICA] ---

            with st.expander(expander_label, expanded=expander_expanded):
                
                secao_canonico = diff['secao']
                anchor_id_ref = _create_anchor_id(secao_canonico, "ref")
                anchor_id_bel = _create_anchor_id(secao_canonico, "bel")
                
                expander_html_ref = marcar_diferencas_palavra_por_palavra(
                    diff['conteudo_ref'], diff['conteudo_belfar'], eh_referencia=True
                ).replace('\n', '<br>')
                expander_html_belfar = marcar_diferencas_palavra_por_palavra(
                    diff['conteudo_ref'], diff['conteudo_belfar'], eh_referencia=False
                ).replace('\n', '<br>')
                
                # Adiciona 'cursor: pointer;' e um 'title' para feedback
                clickable_style = expander_caixa_style + " cursor: pointer; transition: background-color 0.3s ease;"
                
                # Criamos o HTML da caixa clic√°vel com o 'onclick' chamando a fun√ß√£o GLOBAL.
                html_ref_box = f"<div onclick='window.handleBulaScroll(\"{anchor_id_ref}\", \"{anchor_id_bel}\")' style='{clickable_style}' title='Clique para ir √† se√ß√£o' onmouseover='this.style.backgroundColor=\"#f0f7ff\"' onmouseout='this.style.backgroundColor=\"#ffffff\"'>{expander_html_ref}</div>"
                
                html_bel_box = f"<div onclick='window.handleBulaScroll(\"{anchor_id_ref}\", \"{anchor_id_bel}\")' style='{clickable_style}' title='Clique para ir √† se√ß√£o' onmouseover='this.style.backgroundColor=\"#f0f7ff\"' onmouseout='this.style.backgroundColor=\"#ffffff\"'>{expander_html_belfar}</div>"

                c1, c2 = st.columns(2)
                with c1:
                    st.markdown("**Refer√™ncia:** (Clique na caixa para rolar)")
                    st.markdown(html_ref_box, unsafe_allow_html=True)
                with c2:
                    st.markdown("**BELFAR:** (Clique na caixa para rolar)")
                    st.markdown(html_bel_box, unsafe_allow_html=True)
                    
    # Se 'secoes_analisadas' estiver vazia E n√£o houver 'diferencas_conteudo'
    elif not diferencas_conteudo:
       st.success("‚úÖ Conte√∫do das se√ß√µes est√° id√™ntico")
    # --- [FIM DA MODIFICA√á√ÉO] ---

    if erros_ortograficos:
        st.info(f"üìù **Poss√≠veis erros ortogr√°ficos ({len(erros_ortograficos)} palavras):**\n" + ", ".join(erros_ortograficos))

    if not any([secoes_faltantes, diferencas_conteudo, diferencas_titulos]) and len(erros_ortograficos) < 5:
        st.success("üéâ **Bula aprovada!** Nenhum problema cr√≠tico encontrado.")

    st.divider()
    st.subheader("Visualiza√ß√£o Lado a Lado com Destaques")
    st.markdown(
        "**Legenda:** <mark style='background-color: #ffff99; padding: 2px;'>Amarelo</mark> = Diverg√™ncias | "
        "<mark style='background-color: #FFDDC1; padding: 2px;'>Rosa</mark> = Erros ortogr√°ficos | "
        "<mark style='background-color: #cce5ff; padding: 2px;'>Azul</mark> = Data ANVISA",
        unsafe_allow_html=True
    )

    html_ref_marcado = marcar_divergencias_html(texto_original=texto_ref, secoes_problema=diferencas_conteudo, erros_ortograficos=[], tipo_bula=tipo_bula, eh_referencia=True).replace('\n', '<br>')
    html_belfar_marcado = marcar_divergencias_html(texto_original=texto_belfar, secoes_problema=diferencas_conteudo, erros_ortograficos=erros_ortograficos, tipo_bula=tipo_bula, eh_referencia=False).replace('\n', '<br>')

    caixa_style = (
        "height: 700px; overflow-y: auto; border: 2px solid #999; border-radius: 4px; "
        "padding: 24px 32px; background-color: #ffffff; "
        "font-family: 'Georgia', 'Times New Roman', serif; font-size: 14px; "
        "line-height: 1.8; box-shadow: 0 2px 12px rgba(0,0,0,0.15); "
        "text-align: justify; color: #000000;"
    )
    col1, col2 = st.columns(2, gap="medium")
    with col1:
        st.markdown(f"**üìÑ {nome_ref}**")
        # ID do container principal
        st.markdown(f"<div id='container-ref-scroll' style='{caixa_style}'>{html_ref_marcado}</div>", unsafe_allow_html=True)
    with col2:
        st.markdown(f"**üìÑ {nome_belfar}**")
        # ID do container principal
        st.markdown(f"<div id='container-bel-scroll' style='{caixa_style}'>{html_belfar_marcado}</div>", unsafe_allow_html=True)
# ----------------- INTERFACE -----------------
st.set_page_config(layout="wide", page_title="Auditoria de Bulas", page_icon="üî¨")
st.title("üî¨ Intelig√™ncia Artificial para Auditoria de Bulas")
st.markdown("Sistema avan√ßado de compara√ß√£o literal e valida√ß√£o de bulas farmac√™uticas")
st.divider()

st.header("üìã Configura√ß√£o da Auditoria")
tipo_bula_selecionado = st.radio("Tipo de Bula:", ("Paciente", "Profissional"), horizontal=True)
col1, col2 = st.columns(2)
with col1:
    st.subheader("üìÑ Med. Refer√™ncia")
    # --- [CORRE√á√ÉO DOCX] ---
    pdf_ref = st.file_uploader("Envie o PDF ou DOCX de refer√™ncia", type=["pdf", "docx"], key="ref")
with col2:
    st.subheader("üìÑ Med. BELFAR")
    # --- [CORRE√á√ÉO DOCX] ---
    pdf_belfar = st.file_uploader("EnvIE o PDF ou DOCX Belfar", type=["pdf", "docx"], key="belfar")

if st.button("üîç Iniciar Auditoria Completa", use_container_width=True, type="primary"):
    if pdf_ref and pdf_belfar:
        with st.spinner("üîÑ Processando e analisando as bulas..."):
            
            # --- [CORRE√á√ÉO DOCX] ---
            # Determina o tipo de arquivo pela extens√£o do nome
            tipo_ref = 'docx' if pdf_ref.name.endswith('.docx') else 'pdf'
            tipo_belfar = 'docx' if pdf_belfar.name.endswith('.docx') else 'pdf'
            
            texto_ref, erro_ref = extrair_texto(pdf_ref, tipo_ref)
            texto_belfar, erro_belfar = extrair_texto(pdf_belfar, tipo_belfar)
            # --- [FIM DA CORRE√á√ÉO] ---

            if not erro_ref:
                texto_ref = truncar_apos_anvisa(texto_ref)
            if not erro_belfar:
                texto_belfar = truncar_apos_anvisa(texto_belfar)

            if erro_ref or erro_belfar:
                st.error(f"Erro ao processar arquivos: {erro_ref or erro_belfar}")
            else:
                gerar_relatorio_final(texto_ref, texto_belfar, "Bula Refer√™ncia", "Bula BELFAR", tipo_bula_selecionado)
    else:
        st.warning("‚ö†Ô∏è Por favor, envie ambos os arquivos PDF ou DOCX para iniciar a auditoria.")

st.divider()
st.caption("Sistema de Auditoria de Bulas v18.4 | Relat√≥rio Completo Ativado | Mapeamento 3 Linhas")
