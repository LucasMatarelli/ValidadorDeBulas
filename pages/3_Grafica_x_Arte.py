# pages/3_Grafica_x_Arte.py
# Vers√£o: v39 (Baseado no v38)
# Auditoria de Bulas ‚Äî Compara√ß√£o: PDF da Gr√°fica x Arte Vigente
# v39: CORRIGE o display do t√≠tulo na "Visualiza√ß√£o Lado a Lado".
# v39: ADICIONA nova fun√ß√£o 'substituir_titulos_por_canonicos' para trocar
#      os t√≠tulos-alias pelos can√¥nicos no texto completo ANTES da exibi√ß√£o final.
# v39: 'gerar_relatorio_final' agora usa essa fun√ß√£o antes de chamar 'marcar_divergencias_html'.
# v39: Mant√©m a corre√ß√£o do NameError da v38 e toda a l√≥gica de OCR/Mapeamento.

# --- IMPORTS ---

# Libs Padr√£o
import re
import difflib
import unicodedata
import io
import html
from typing import Tuple, List, Dict

# Libs de Terceiros (Third-party)
import streamlit as st
import fitz  # PyMuPDF
import docx
import spacy
from thefuzz import fuzz
from spellchecker import SpellChecker
import pytesseract
from PIL import Image

# ----------------- CONFIGURA√á√ÉO DA P√ÅGINA STREAMLIT -----------------
st.set_page_config(layout="wide", page_title="Auditoria de Bulas - Gr√°fica x Arte", page_icon="üî¨")
hide_streamlit_UI = """
<style>
[data-testid="stHeader"], [data-testid="main-menu-button"], footer,
[data-testid="stStatusWidget"], [data-testid="stCreatedBy"], [data-testid="stHostedBy"] {
    display: none !important; visibility: hidden !important;
}
</style>
"""
st.markdown(hide_streamlit_UI, unsafe_allow_html=True)

# ----------------- MODELO NLP -----------------
@st.cache_resource
def carregar_modelo_spacy():
    """Carrega o modelo de linguagem SpaCy de forma otimizada."""
    try:
        return spacy.load("pt_core_news_lg")
    except OSError:
        st.error("Modelo 'pt_core_news_lg' n√£o encontrado. Execute: python -m spacy download pt_core_news_lg")
        return None

nlp = carregar_modelo_spacy()

# ----------------- [MANTIDO - v36] CORRETOR DE ERROS OCR EXPANDIDO -----------------
def corrigir_erros_ocr_comuns(texto: str) -> str:
    if not texto:
        return ""
    
    correcoes = {
        r"(?i)\binbem\b": "inibem", 
        r"(?i)\b(3|1)lfar\b": "Belfar",
        r"(?i)\bBeifar\b": "Belfar",
        r"(?i)\b3elspan\b": "Belspan",
        r"(?i)\barto\b": "parto",
        r"(?i)\bausar\b": "causar",
        r"(?i)\bca√ß√µes\b": "rea√ß√µes",
        r"(?i)\becomendada\b": "recomendada",
        r"(?i)\beduzir\b": "reduzir",
        r"(?i)\belacionados\b": "relacionados",
        r"(?i)\bidministrado\b": "administrado",
        r"(?i)\biparelho\b": "aparelho",
        r"(?i)\bjangramento\b": "sangramento",
        r"(?i)\bjerivados\b": "derivados",
        r"(?i)\bjode\b": "pode",
        r"(?i)\blentro\b": "dentro",
        r"(?i)\bloses\b": "doses",
        r"(?i)\bmecicamentos\b": "medicamentos",
        r"(?i)\bnais\b": "mais",
        r"(?i)\bnedicamentos\b": "medicamentos",
        r"(?i)\bntera√ß√µes\b": "intera√ß√µes",
        r"(?i)\bompensarem\b": "compensarem",
        r"(?i)\bomprimido\b": "comprimido",
        r"(?i)\bont√©m\b": "cont√©m",
        r"(?i)\bratamento\b": "tratamento",
        r"(?i)\brave\b": "grave",
        r"(?i)\bravidez\b": "gravidez",
        r"(?i)\breas\b": "√°reas",
        r"(?i)\brincipalmente\b": "principalmente",
        r"(?i)\broblemas\b": "problemas",
        r"(?i)\br√°vidas\b": "gr√°vidas",
        r"(?i)\bslaucoma\b": "glaucoma",
        r"(?i)\b2\s+a\s+5\s+vez\b": "2 a 5 vezes", 
        r"(?i)\bap√≥s\s+sintomas\b": "ap√≥s os sintomas", 
        r"(?i)\babsor√ß√£o\s+medicamento\b": "absor√ß√£o do medicamento", 
        r"(?i)\bvoc√™\s+aplic\s+sulfato\b": "voc√™ aplicar sulfato", 
        r"(?i)\bbacitracina\s+zinci\b": "bacitracina zincica", 
        r"(?i)\bpoucos\s+dias;1\b": "poucos dias; no", 
        r"(?i)\bpoucos\s+dias(1|I)\b": "poucos dias; no", 
        r"(?i)\bmecicamento\b": "medicamento",
        r"(?i)\bmedicament0\b": "medicamento",
        r"(?i)\bNAO\b": "N√ÉO",
        r"(?i)\bCOMPOSI√áAO\b": "COMPOSI√á√ÉO",
        r"(?i)\bJevido\b": "Devido",
        r"(?i)\bjue\b": "que",
        r"(?i)\bjacientes\b": "pacientes",
        r"(?i)\boc√™\b": "voc√™",
        r"(?i)\basos\b": "casos",
        r"(?i)\b1so\b": "uso",
        r"(?i)\bjaracetamol\b": "paracetamol",
        r"(?i)\beguindo\b": "seguindo",
        r"(?i)\bitua√ß√µes\b": "situa√ß√µes",
        r"(?i)\bress√£o\b": "press√£o",
        r"(?i)\bjortadores\b": "portadores",
        r"(?i)\bjossuem\b": "possuem",
        r"(?i)\bl√©rgica\b": "al√©rgica",
        r"(?i)\bjs\s+sinais\b": "os sinais", 
        r"\.\)\s*s\s+pacientes\b": ". Os pacientes", 
        r"(?i)\bom\s+bolhas\b": "com bolhas", 
        r"(?i)\bcomo\)\s*butilbrometo\b": "como o butilbrometo", 
        r"(?i)\bim\s+caso\b": "em caso",
        r"(?i)\bintoler√¢√°cia\b": "intoler√¢ncia", 
        r"(?i)\ble\s+glicose\b": "de glicose", 
        r"(?i)\bor\s+dose\b": "por dose", 
        r"(?i)\bcom\)\s*uso\b": "com o uso", 
        r"(?i)\bleve\s+ser\b": "deve ser",
        r"(?i)\bnodo\b": "modo", 
        r"(?i)\bomar\s+cuidado\b": "tomar cuidado", 
        r"15\s*Ce\s*30 C": "15¬∞C e 30¬∞C",
        r"15‚Äú\s*Ce\s*30 C": "15¬∞C e 30¬∞C", 
        r"(?i)\bleo paral√≠tico\b": "√≠leo paral√≠tico",
        r"(?i)^1\s+necess√°ria\b": "√â necess√°ria",
        r"(?i)\bmediatamente\b": "imediatamente",
        r"(?i)\bAcido acetilsalic√≠lico\b": "√Åcido acetilsalic√≠lico",
        r"(?i)\bse ALGUM usar\b": "se ALGU√âM usar",
        r"(?i)\blipirona\b": "dipirona", 
        r"(?i)bacitracina\s+z(i|√≠)ncica\s+(?:eee|rereeeio)\s+\d+(?:I|ME)?": "bacitracina z√≠ncica 250 UI",
        r"(?i)excipientes\s+q\.s\.p\s+(?:irem|esses\s+LE)\b": "excipientes q.s.p. 1 g",
        r"(?i)\bneomicina\s+5r\b": "neomicina 5 mg", 
        r"(?i)\b250\s+UN\b": "250 UI", 
        r"\bc\.t\s+": "",
        r"\bq\.s\.p\s+\"?si\s+": "q.s.p. ",
        r"\|": "",
        r"\s+mm\b": "", 
        r"\s+mma\b": "",
        r"\s+([,;:\.\?\!%¬∞])": r"\1",
        r"(\()\s+": r"\1",
        r"\s+(\))": r"\1",
    }

    for padrao, correcao in correcoes.items():
        texto = re.sub(padrao, correcao, texto, flags=re.MULTILINE)
    
    return texto


# ----------------- [MANTIDO - v35] LIMPEZA ULTRA CONSERVADORA -----------------
def melhorar_layout_grafica(texto: str) -> str:
    if not texto or not isinstance(texto, str):
        return ""

    texto = corrigir_erros_ocr_comuns(texto)
    texto = texto.replace('\r\n', '\n').replace('\r', '\n')
    texto = texto.replace('\t', ' ')
    texto = re.sub(r'\u00A0', ' ', texto)
    texto = re.sub(r"(\w+)-\s*\n\s*(\w+)", r"\1\2", texto)
    texto = re.sub(r'(\.|\s){7,}', ' ', texto) 
    texto = re.sub(r'[¬´¬ª"""√â√Ä‚Äú‚Äù&]', '', texto) 
    texto = re.sub(r'\bBEE\s*\*\b', '', texto, flags=re.IGNORECASE)
    
    linhas = texto.split('\n')
    linhas_limpas = []
    
    padroes_lixo_linha_completa = [
        r'^mm\s*$',
        r'^mma\s*$',
        r'^Too\s*$',
        r'^raio\s+ra\s+m-+\s*$',
        r'^HM\s*$',
        r'^TR\s*$',
        r'^BRR\s*$',
        r'^\s*\|\s*$',
        r'^\s*-{5,}\s*$',
        r'^\s*\d+\s*$', 
        r'^\s*‚Äî+\s*\d+\s*$',
        r'^\s*S\s*$',
        r'^\s*E\s*$',
        r'^\s*O\s*$',
        r'^\s*m\s*$',
        r'^\s*EN\s*$',
        r'^m\s+EN\s+\d+\s+\d+\s+a,\s+\d+\s+-$', 
        r'fig\.\s+\d', 
        r'^\s*es\s+New\s+Roman\(\)\s+B\s+E\s+LFAR\s+rpo\s+\d+$', 
        r'^\d+-\s+\d+$', 
        r"^\s*300,00\s*$",
        r"^\s*30,00\s*$",
        r"^\s*1¬∫\s*-\s*prova\s*-'\s*$",
        r"(?i)BUL\s+bacitracin:\s+FRENTE",
        r"(?i)BUL\s+bacitracina\b", 
        r"(?i)Tipologia\s+da\s+bul",
        r"0,\s*00‚Äî\s*to\.\s+Corpo\s+10",
        r"^\s*\d+\s+\d+-\s+\d+\s*$", 
    ]
    
    for linha in linhas:
        linha_limpa = linha.strip()
        
        if not linha_limpa:
            linhas_limpas.append("")
            continue
        
        eh_lixo = False
        for padrao_lixo in padroes_lixo_linha_completa:
            if re.search(padrao_lixo, linha_limpa, re.IGNORECASE): 
                eh_lixo = True
                break
        
        if not eh_lixo:
            linhas_limpas.append(linha)
    
    texto = "\n".join(linhas_limpas)
    texto = re.sub(r'\n{4,}', '\n\n\n', texto)
    
    linhas_final = []
    for linha in texto.split('\n'):
        linha = re.sub(r'[ \t]{2,}', ' ', linha)
        linhas_final.append(linha.strip())
    
    texto = "\n".join(linhas_final)
    
    return texto.strip()


# ----------------- [MANTIDO - v35] OCR DE P√ÅGINA INTEIRA (psm 3) -----------------
def extrair_pdf_ocr_v35_fullpage(arquivo_bytes: bytes) -> str:
    texto_total = ""
    with fitz.open(stream=io.BytesIO(arquivo_bytes), filetype="pdf") as doc:
        st.info(f"For√ßando OCR (v39: psm 3 Full-Page) em {len(doc)} p√°gina(s)...")
        
        ocr_config = r'--psm 3' 
            
        for i, page in enumerate(doc):
            pix_page = page.get_pixmap(dpi=300)
            img_page = Image.open(io.BytesIO(pix_page.tobytes("png")))
            texto_ocr_pagina = pytesseract.image_to_string(img_page, lang='por', config=ocr_config)
            texto_total += texto_ocr_pagina + "\n"
            
    return texto_total

# ----------------- [MANTIDA] FUN√á√ÉO DE EXTRA√á√ÉO PRINCIPAL -----------------
def extrair_texto(arquivo, tipo_arquivo: str) -> Tuple[str, str]:
    if arquivo is None:
        return "", f"Arquivo {tipo_arquivo} n√£o enviado."

    try:
        arquivo.seek(0)
        texto = ""
        arquivo_bytes = arquivo.read()

        if tipo_arquivo == "pdf":
            texto = extrair_pdf_ocr_v35_fullpage(arquivo_bytes)
        
        elif tipo_arquivo == "docx":
            st.info("Extraindo texto de DOCX...")
            doc = docx.Document(io.BytesIO(arquivo_bytes))
            texto = "\n".join([p.text for p in doc.paragraphs])
        
        if texto:
            padroes_ignorados = [
                r"(?i)BELFAR", r"(?i)Papel", r"(?i)Times New Roman",
                r"(?i)Cor[: ]", r"(?i)Frente/?Verso", r"(?i)Medida da bula",
                r"(?i)Contato[: ]", r"(?i)Impress√£o[: ]", r"(?i)Tipologia da bula",
                r"(?i)Ap\s*\d+gr", r"(?i)Artes", r"(?i)gm>>>", r"(?i)450 mm",
                r"BUL\s*BELSPAN\s*COMPRIMIDO", r"BUL\d+V\d+", r"FRENTE:", r"VERSO:",
                r"artes@belfat\.com\.br", r"\(\d+\)\s*\d+-\d+",
                r"e\s*-+\s*\d+mm\s*>>>I\)", 
                r"\d+¬™\s*prova\s*-\s*\d+", 
                r"\d+¬∫\s*prova\s*-", 
                r"^\s*\d+/\d+/\d+\s*$", 
                r"(?i)n\s*Roman\s*U\)", 
                r"(?i)lew\s*Roman\s*U\s*\]", 
                r"KH\s*‚Äî\s*\d+", 
                r"pp\s*\d+", 
                r"^\s*an\s*$", 
                r"^\s*man\s*$", 
                r"^\s*contato\s*$",
                r"^\s*\|\s*$",
                r"\+\|",
                r"^\s*a\s*\?\s*la\s*KH\s*\d+\s*r", 
                r"^mm\s+>>>", 
                r"^\s*nm\s+A\s*$", 
                r"^\s*TE\s*-\s*√Ä\s*$", 
                r"1¬∫\s*PROVA\s*-\s*LA", 
                r"AMO\s+dm\s+JAM\s+Vmindrtoihko\s+amo\s+o",
                r"\[E\s*O\s*\|\s*dj\s*jul",
                r"\+\s*\|\s*hd\s*bl\s*O\s*mm\s*DS\s*AALPRA",
                r"A\s*\+\s*med\s*F√É\s*ias\s*A\s*KA\s*a√µArA\s*\+\s*ima",
                r"BUL\s+BELSPAN\s+COMPR\b", 
                r"BUL\s+BELSPAN\s+COMP\b",
                r"^\s*m--*\s*$",
            ]
            
            linhas_originais = texto.split('\n')
            linhas_filtradas = []
            
            for linha in linhas_originais:
                linha_limpa = linha.strip()
                ignorar_linha = False
                for padrao in padroes_ignorados:
                    if re.search(padrao, linha_limpa, re.IGNORECASE | re.MULTILINE):
                        ignorar_linha = True
                        break
                if not ignorar_linha:
                    linhas_filtradas.append(linha)
            
            texto = "\n".join(linhas_filtradas)

            caracteres_invisiveis = ['\u00AD', '\u200B', '\u200C', '\u200D', '\uFEFF']
            for char in caracteres_invisiveis:
                texto = texto.replace(char, '')

            texto = texto.replace('\r\n', '\n').replace('\r', '\n')
            texto = texto.replace('\u00A0', ' ')
            
            linhas = texto.split('\n')
            padrao_rodape = re.compile(r'bula do paciente|p√°gina \d+\s*de\s*\d+', re.IGNORECASE)
            linhas_filtradas_final = [linha for linha in linhas if not padrao_rodape.search(linha.strip())]
            
            texto = "\n".join(linhas_filtradas_final)
            
            texto = melhorar_layout_grafica(texto)

            texto = re.sub(r'\n{3,}', '\n\n', texto) 
            texto = re.sub(r'[ \t]+', ' ', texto)
            texto = texto.strip()

        return texto, None

    except Exception as e:
        st.error(f"Erro fatal em extrair_texto: {e}", icon="üö®")
        return "", f"Erro ao ler o arquivo {tipo_arquivo}: {e}"


# ----------------- [MANTIDO - v35] TRUNCAR AP√ìS ANVISA -----------------
def truncar_apos_anvisa(texto: str) -> str:
    if not isinstance(texto, str):
        return texto
    
    regex_anvisa = r"(?:aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova√ß√£o\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    
    last_match = None
    for match in re.finditer(regex_anvisa, texto, re.IGNORECASE):
        last_match = match 
        
    if last_match:
        end_of_line_pos = texto.find('\n', last_match.end())
        if end_of_line_pos != -1:
            return texto[:end_of_line_pos]
        else:
            return texto[:last_match.end()]
            
    return texto


# ----------------- SE√á√ïES E NORMALIZA√á√ÉO -----------------
def obter_secoes_por_tipo(tipo_bula: str) -> List[str]:
    secoes = {
        "Paciente": [
            "APRESENTA√á√ïES",
            "COMPOSI√á√ÉO",
            "1. PARA QUE ESTE MEDICAMENTO √â INDICADO?",
            "2. COMO ESTE MEDICAMENTO FUNCIONA?",
            "3. QUANDO N√ÉO DEVO USAR ESTE MEDICAMENTO?",
            "4. O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
            "5. ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
            "6. COMO DEVO USAR ESTE MEDICAMENTO?",
            "7. O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
            "8. QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?",
            "9. O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
            "DIZERES LEGAIS"
        ],
        "Profissional": [
            "APRESENTA√á√ïES",
            "COMPOSI√á√ÉO",
            "1. INDICA√á√ïES",
            "2. RESULTADOS DE EFIC√ÅCIA",
            "3. CARACTER√çSTICAS FARMACOL√ìGICAS",
            "4. CONTRAINDICA√á√ïES",
            "5. ADVERT√äNCIAS E PRECAU√á√ïES",
            "6. INTERA√á√ïES MEDICAMENTOSAS",
            "7. CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO",
            "8. POSOLOGIA E MODO DE USAR",
            "9. REA√á√ïES ADVERSAS",
            "10. SUPERDOSE",
            "DIZERES LEGAIS"
        ]
    }
    return secoes.get(tipo_bula, secoes["Paciente"])

# --- [MANTIDO - v36] ---
def obter_aliases_secao() -> Dict[str, str]:
    return {
        "INDICA√á√ïES": "1. PARA QUE ESTE MEDICAMENTO √â INDICADO?",
        "COMO FUNCIONA?": "2. COMO ESTE MEDICAMENTO FUNCIONA?", # v36
        "CONTRAINDICA√á√ïES": "3. QUANDO N√ÉO DEVO USAR ESTE MEDICAMENTO?",
        "POSOLOGIA E MODO DE USAR": "6. COMO DEVO USAR ESTE MEDICAMENTO?",
        "REA√á√ïES ADVERSAS": "8. QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?",
        "SUPERDOSE": "9. O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
        "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO": "5. ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
        "INDICA√á√ïES": "1. INDICA√á√ïES",
        "CONTRAINDICA√á√ïES": "4. CONTRAINDICA√á√ïES",
        "POSOLOGIA E MODO DE USAR": "8. POSOLOGIA E MODO DE USAR",
        "REA√á√ïES ADVERSAS": "9. REA√á√ïES ADVERSAS",
        "SUPERDOSE": "10. SUPERDOSE",
        "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO": "7. CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO",
    }

def obter_secoes_ignorar_ortografia() -> List[str]:
    return ["COMPOSI√á√ÉO", "DIZERES LEGAIS"]

def obter_secoes_ignorar_comparacao() -> List[str]:
    return ["COMPOSI√á√ÉO", "DIZERES LEGAIS", "APRESENTA√á√ïES"]

def normalizar_para_comparacao_literal(texto: str) -> str:
    if not isinstance(texto, str):
        return ""
    texto = re.sub(r'(?<!\n)\n(?!\n)', ' ', texto) 
    texto = re.sub(r'[\n\r\t]+', ' ', texto) 
    texto = re.sub(r' +', ' ', texto)
    texto = texto.strip()
    return texto.lower()

def normalizar_texto(texto: str) -> str:
    if not isinstance(texto, str):
        return ""
    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')
    texto = re.sub(r'[^\w\s]', '', texto)
    texto = ' '.join(texto.split())
    return texto.lower()

def normalizar_titulo_para_comparacao(texto: str) -> str:
    texto_norm = normalizar_texto(texto)
    texto_norm = re.sub(r'^\d+\s*[\.\-)]*\s*', '', texto_norm).strip()
    return texto_norm

def _create_anchor_id(secao_nome: str, prefix: str) -> str:
    norm = normalizar_texto(secao_nome)
    norm_safe = re.sub(r'[^a-z0-9\-]', '-', norm)
    return f"anchor-{prefix}-{norm_safe}"


# --- [MANTIDO - v37] MAPEAMENTO E EXTRA√á√ÉO DE SE√á√ÉO (ROBUSTO) ---
# Esta l√≥gica de mapeamento (v37) est√° correta.

def mapear_secoes(texto_completo: str, secoes_esperadas: List[str]) -> List[Dict]:
    """
    v37 (Gemini): Mapeia se√ß√µes e calcula 'original_lines_consumed'
    para que 'obter_dados_secao' saiba exatamente onde o t√≠tulo termina.
    """
    mapa_preliminar = []
    
    linhas_nao_vazias = []
    mapa_indices_originais = {} 
    linhas_originais = texto_completo.split('\n')
    
    for i, linha in enumerate(linhas_originais):
        if linha.strip():
            mapa_indices_originais[len(linhas_nao_vazias)] = i
            linhas_nao_vazias.append(linha)

    aliases = obter_aliases_secao()
    titulos_possiveis = {}

    for secao in secoes_esperadas:
        titulos_possiveis[secao] = secao
    for alias, canonico in aliases.items():
        if canonico in secoes_esperadas:
            if alias not in titulos_possiveis:
                titulos_possiveis[alias] = canonico
    
    titulos_norm_map = {norm: canon for norm, canon in 
                        [(normalizar_titulo_para_comparacao(t), c) for t, c in titulos_possiveis.items()]}
    titulos_norm_set = set(titulos_norm_map.keys())

    idx = 0
    while idx < len(linhas_nao_vazias):
        linha_limpa_1 = linhas_nao_vazias[idx].strip()
        linha_norm_1 = normalizar_titulo_para_comparacao(linha_limpa_1)
        
        linha_limpa_2 = ""
        linha_norm_2 = ""
        linha_combinada_2 = ""
        if idx + 1 < len(linhas_nao_vazias):
            linha_limpa_2 = linhas_nao_vazias[idx+1].strip()
            if linha_limpa_2 and len(linha_limpa_2.split()) < 7:
                linha_combinada_2 = f"{linha_limpa_1} {linha_limpa_2}"
                linha_norm_2 = normalizar_titulo_para_comparacao(linha_combinada_2)

        linha_limpa_3 = ""
        linha_norm_3 = ""
        linha_combinada_3 = ""
        if idx + 2 < len(linhas_nao_vazias):
            linha_limpa_3 = linhas_nao_vazias[idx+2].strip()
            if linha_limpa_2 and linha_limpa_3 and len(linha_limpa_3.split()) < 7:
                linha_combinada_3 = f"{linha_limpa_1} {linha_limpa_2} {linha_limpa_3}"
                linha_norm_3 = normalizar_titulo_para_comparacao(linha_combinada_3)

        best_match_score = 0
        best_match_canonico = None
        best_match_titulo_real = ""
        non_empty_lines_consumed = 1 
        
        if linha_norm_3:
            match_3 = difflib.get_close_matches(linha_norm_3, titulos_norm_set, n=1, cutoff=0.96)
            if match_3:
                best_match_score = 99
                best_match_canonico = titulos_norm_map[match_3[0]]
                best_match_titulo_real = linha_combinada_3
                non_empty_lines_consumed = 3

        if linha_norm_2 and best_match_score < 98:
            match_2 = difflib.get_close_matches(linha_norm_2, titulos_norm_set, n=1, cutoff=0.96)
            if match_2:
                best_match_score = 98
                best_match_canonico = titulos_norm_map[match_2[0]]
                best_match_titulo_real = linha_combinada_2
                non_empty_lines_consumed = 2

        if best_match_score < 96:
            match_1 = difflib.get_close_matches(linha_norm_1, titulos_norm_set, n=1, cutoff=0.96)
            if match_1:
                best_match_score = 96
                best_match_canonico = titulos_norm_map[match_1[0]]
                best_match_titulo_real = linha_limpa_1
                non_empty_lines_consumed = 1
        
        if best_match_score < 96:
            for titulo_norm in titulos_norm_set:
                if linha_norm_1.startswith(titulo_norm) and len(linha_norm_1) > len(titulo_norm) + 5:
                    best_match_score = 97
                    best_match_canonico = titulos_norm_map[titulo_norm]
                    # ... (l√≥gica 'startswith' omitida por brevidade) ...
                    non_empty_lines_consumed = 1
                    break

        if best_match_score >= 96:
            if not mapa_preliminar or mapa_preliminar[-1]['canonico'] != best_match_canonico:
                
                indice_original_inicio = mapa_indices_originais.get(idx)
                if indice_original_inicio is None:
                    idx += non_empty_lines_consumed
                    continue # Seguran√ßa, deve nunca acontecer

                fim_idx_nao_vazio = min(idx + non_empty_lines_consumed - 1, len(mapa_indices_originais) - 1)
                indice_original_fim = mapa_indices_originais.get(fim_idx_nao_vazio)
                if indice_original_fim is None:
                    idx += non_empty_lines_consumed
                    continue # Seguran√ßa
                
                original_lines_consumed = (indice_original_fim - indice_original_inicio) + 1

                mapa_preliminar.append({
                    'canonico': best_match_canonico,
                    'titulo_encontrado': best_match_titulo_real,
                    'linha_inicio': indice_original_inicio, 
                    'non_empty_lines_consumed': non_empty_lines_consumed,
                    'original_lines_consumed': original_lines_consumed 
                })
            idx += non_empty_lines_consumed
        else:
            idx += 1
            
    mapa_preliminar.sort(key=lambda x: x['linha_inicio'])
    return mapa_preliminar


def obter_dados_secao(secao_canonico: str, mapa_secoes: List[Dict], linhas_texto: List[str], tipo_bula: str):
    """
    v37 (Gemini): Usa 'original_lines_consumed' para definir o in√≠cio do conte√∫do.
    """
    for i, secao_mapa in enumerate(mapa_secoes):
        if secao_mapa['canonico'] != secao_canonico:
            continue

        titulo_encontrado = secao_mapa['titulo_encontrado']
        linha_inicio = secao_mapa['linha_inicio']
        non_empty_lines = secao_mapa.get('non_empty_lines_consumed', 1)
        original_lines = secao_mapa.get('original_lines_consumed', 1)
              
        if linha_inicio >= len(linhas_texto):
             return False, None, "" 
              
        linha_original_titulo = linhas_texto[linha_inicio].strip()
        
        conteudo_primeira_linha = ""
        match = None
        try:
            match = re.search(re.escape(titulo_encontrado), linha_original_titulo, re.IGNORECASE)
        except re.error:
             pass
        
        if match and non_empty_lines == 1: 
            idx_fim_titulo = match.end()
            conteudo_primeira_linha = linha_original_titulo[idx_fim_titulo:].strip()
            conteudo_primeira_linha = re.sub(r"^[.:\s]+", "", conteudo_primeira_linha)
        
        linha_inicio_conteudo = linha_inicio + original_lines

        linha_fim = len(linhas_texto)
        if (i + 1) < len(mapa_secoes):
            linha_fim = mapa_secoes[i+1]['linha_inicio']

        conteudo_restante = [linhas_texto[idx] for idx in range(linha_inicio_conteudo, linha_fim)]
        
        if conteudo_primeira_linha:
            conteudo_final = (conteudo_primeira_linha + "\n" + "\n".join(conteudo_restante)).strip()
        else:
            conteudo_final = "\n".join(conteudo_restante).strip()
        
        return True, titulo_encontrado, conteudo_final

    return False, None, ""
# --- [FIM - L√ìGICA V37 MANTIDA] ---


# ----------------- COMPARA√á√ÉO DE CONTE√öDO -----------------
def verificar_secoes_e_conteudo(texto_ref: str, texto_belfar: str, tipo_bula: str):
    secoes_esperadas = obter_secoes_por_tipo(tipo_bula)
    secoes_faltantes, diferencas_conteudo, similaridades_secoes, diferencas_titulos = [], [], [], []

    linhas_ref = texto_ref.split('\n')
    linhas_belfar = texto_belfar.split('\n')

    mapa_ref = mapear_secoes(texto_ref, secoes_esperadas)
    mapa_belfar = mapear_secoes(texto_belfar, secoes_esperadas)

    for secao in secoes_esperadas:
        melhor_titulo = None

        encontrou_ref, _, conteudo_ref = obter_dados_secao(secao, mapa_ref, linhas_ref, tipo_bula)
        encontrou_belfar, titulo_belfar, conteudo_belfar = obter_dados_secao(secao, mapa_belfar, linhas_belfar, tipo_bula)

        if not encontrou_belfar:
            melhor_score = 0
            melhor_titulo_encontrado = None
            for m in mapa_belfar:
                score = fuzz.token_set_ratio(normalizar_titulo_para_comparacao(secao), normalizar_titulo_para_comparacao(m['titulo_encontrado']))
                if score > melhor_score:
                    melhor_score = score
                    melhor_titulo_encontrado = m['titulo_encontrado']

            if melhor_score >= 95: 
                for m_similar in mapa_belfar:
                     if m_similar['titulo_encontrado'] == melhor_titulo_encontrado:
                          _, titulo_belfar, conteudo_belfar = obter_dados_secao(m_similar['canonico'], mapa_belfar, linhas_belfar, tipo_bula)
                          encontrou_belfar = True
                          diferencas_titulos.append({'secao_esperada': secao, 'titulo_encontrado': titulo_belfar})
                          break
            else:
                secoes_faltantes.append(secao)
                continue

        if encontrou_ref and encontrou_belfar:
            secao_comp = normalizar_titulo_para_comparacao(secao)
            titulo_belfar_comp = normalizar_titulo_para_comparacao(titulo_belfar if titulo_belfar else "")

            if secao_comp != titulo_belfar_comp:
                if not any(d['secao_esperada'] == secao for d in diferencas_titulos):
                    diferencas_titulos.append({'secao_esperada': secao, 'titulo_encontrado': titulo_belfar})

            secao_canon_norm = normalizar_titulo_para_comparacao(secao)
            ignorar_comparacao_norm = [normalizar_titulo_para_comparacao(s) for s in obter_secoes_ignorar_comparacao()]

            if secao_canon_norm in ignorar_comparacao_norm:
                similaridades_secoes.append(100)
                continue

            if normalizar_para_comparacao_literal(conteudo_ref) != normalizar_para_comparacao_literal(conteudo_belfar):
                titulo_real_encontrado = titulo_belfar
                diferencas_conteudo.append({
                    'secao': secao,
                    'conteudo_ref': conteudo_ref,
                    'conteudo_belfar': conteudo_belfar,
                    'titulo_encontrado': titulo_real_encontrado
                })
                similaridades_secoes.append(0)
            else:
                similaridades_secoes.append(100)

    return secoes_faltantes, diferencas_conteudo, similaridades_secoes, diferencas_titulos

# ----------------- ORTOGRAFIA -----------------
def checar_ortografia_inteligente(texto_para_checar: str, texto_referencia: str, tipo_bula: str) -> List[str]:
    if not nlp or not texto_para_checar:
        return []

    try:
        secoes_ignorar = obter_secoes_ignorar_ortografia()
        secoes_todas = obter_secoes_por_tipo(tipo_bula)

        texto_filtrado_para_checar = []
        mapa_secoes = mapear_secoes(texto_para_checar, secoes_todas)
        linhas_texto = texto_para_checar.split('\n')
        ignorar_norm = [normalizar_titulo_para_comparacao(s) for s in secoes_ignorar]

        for secao_nome in secoes_todas:
            secao_norm = normalizar_titulo_para_comparacao(secao_nome)
            if secao_norm in ignorar_norm:
                continue
            encontrou, _, conteudo = obter_dados_secao(secao_nome, mapa_secoes, linhas_texto, tipo_bula)
            if encontrou and conteudo:
                linhas_conteudo = conteudo.split('\n')
                if len(linhas_conteudo) > 1:
                    texto_filtrado_para_checar.append('\n'.join(linhas_conteudo[1:]))
                elif len(linhas_conteudo) == 1 and conteudo:
                     texto_filtrado_para_checar.append(conteudo)

        texto_final_para_checar = '\n'.join(texto_filtrado_para_checar)
        if not texto_final_para_checar:
            return []

        spell = SpellChecker(language='pt')
        palavras_a_ignorar = {"alair", "belfar", "peticionamento", "urotrobel", "escopolamina", "dipirona", "butilbrometo", "nafazolina", "cloreto", "z√≠ncica"}
        vocab_referencia = set(re.findall(r'\b[a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß√º]+\b', texto_referencia.lower()))

        doc = nlp(texto_para_checar)
        entidades = {ent.text.lower() for ent in doc.ents}

        spell.word_frequency.load_words(vocab_referencia.union(entidades).union(palavras_a_ignorar))
        palavras = re.findall(r'\b[a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß√º]+\b', texto_final_para_checar.lower())
        erros = spell.unknown(palavras)

        return list(sorted(set([e for e in erros if len(e) > 3])))[:40]
    except Exception as e:
        st.error(f"Erro na ortografia: {e}")
        return []

# ----------------- DIFEREN√áAS PALAVRA A PALAVRA -----------------
def marcar_diferencas_palavra_por_palavra(texto_ref: str, texto_belfar: str, eh_referencia: bool):
    def tokenizar(txt: str):
        return re.findall(r'\n|[A-Za-z√Ä-√ñ√ò-√∂√∏-√ø0-9_]+|[^\w\s]', txt, re.UNICODE)

    def norm(tok: str):
        if re.match(r'[A-Za-z√Ä-√ñ√ò-√∂√∏-√ø0-9_]+$', tok):
            return tok.lower()
        return tok
    
    texto_ref = texto_ref or ""
    texto_belfar = texto_belfar or ""

    ref_tokens = tokenizar(texto_ref)
    bel_tokens = tokenizar(texto_belfar)

    ref_norm = [norm(t) for t in ref_tokens]
    bel_norm = [norm(t) for t in bel_tokens]

    matcher = difflib.SequenceMatcher(None, ref_norm, bel_norm, autojunk=False)
    indices = set()
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag != 'equal':
            indices.update(range(i1, i2) if eh_referencia else range(j1, j2))

    tokens = ref_tokens if eh_referencia else bel_tokens
    marcado = []
    for idx, tok in enumerate(tokens):
        if idx in indices and tok.strip() != '':
            marcado.append(f"<mark style='background-color: #ffff99; padding: 2px;'>{html.escape(tok)}</mark>")
        else:
            marcado.append(html.escape(tok))

    resultado = ""
    for i, tok in enumerate(marcado):
        if i == 0:
            resultado += tok
            continue
        raw_tok = re.sub(r'^<mark[^>]*>|</mark>$', '', tok)
        if re.match(r'^[^\w\s]$', raw_tok) or raw_tok == '\n':
            resultado += tok
        else:
            if marcado[i-1] != '\n' and tok != '\n':
                 resultado += " "
            resultado += tok

    resultado = re.sub(r'\s+([.,;:!?)])', r'\1', resultado)
    resultado = re.sub(r'(\()\s+', r'\1', resultado)
    resultado = re.sub(r"(</mark>)\s+(<mark[^>]*>)", r"\1 \2", resultado)
    return resultado

# ----------------- MARCA√á√ÉO POR SE√á√ÉO COM √çNDICES -----------------
def marcar_divergencias_html(texto_original: str, secoes_problema: List[Dict], erros_ortograficos: List[str], tipo_bula: str, eh_referencia: bool=False) -> str:
    texto_trabalho = html.escape(texto_original)
    texto_sem_escape = texto_original

    if secoes_problema:
        for diff in secoes_problema:
            conteudo_ref = diff['conteudo_ref']
            conteudo_belfar = diff['conteudo_belfar']
            conteudo_a_marcar = conteudo_ref if eh_referencia else conteudo_belfar
            
            if conteudo_a_marcar is None:
                conteudo_a_marcar = ""

            conteudo_marcado = marcar_diferencas_palavra_por_palavra(conteudo_ref, conteudo_belfar, eh_referencia)
            secao_canonico = diff['secao']
            anchor_id = _create_anchor_id(secao_canonico, "ref" if eh_referencia else "bel")
            conteudo_com_ancora = f"<div id='{anchor_id}' style='scroll-margin-top: 20px;'>{conteudo_marcado}</div>"

            if conteudo_a_marcar and conteudo_a_marcar in texto_sem_escape:
                texto_sem_escape = texto_sem_escape.replace(conteudo_a_marcar, conteudo_com_ancora, 1) 
            else:
                escaped_marcar = html.escape(conteudo_a_marcar)
                if escaped_marcar in texto_trabalho:
                    texto_trabalho = texto_trabalho.replace(escaped_marcar, conteudo_com_ancora, 1) 

    if erros_ortograficos and not eh_referencia:
        for erro in erros_ortograficos:
            pattern = re.compile(r'\b' + re.escape(erro) + r'\b', flags=re.IGNORECASE)
            texto_sem_escape = pattern.sub(lambda m: f"<mark style='background-color: #FFDDC1; padding: 2px;'>{html.escape(m.group(0))}</mark>", texto_sem_escape)

    regex_anvisa = r"((?:aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova√ß√£o\s+na\s+anvisa:)\s*[\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    
    last_match = None
    for match in re.finditer(regex_anvisa, texto_sem_escape, re.IGNORECASE):
        last_match = match
        
    if last_match:
        frase_anvisa = last_match.group(1)
        start, end = last_match.start(1), last_match.end(1)
        texto_sem_escape = (
            texto_sem_escape[:start] +
            f"<mark style='background-color: #cce5ff; padding: 2px; font-weight: 500;'>{html.escape(frase_anvisa)}</mark>" +
            texto_sem_escape[end:]
        )

    if '<div' in texto_sem_escape or '<mark' in texto_sem_escape:
        texto_final = texto_sem_escape.replace('\n', '<br>')
    else:
        texto_final = html.escape(texto_sem_escape).replace('\n', '<br>')

    return texto_final

# --- [NOVO v39] ---
def substituir_titulos_por_canonicos(texto_completo: str, mapa_secoes: List[Dict]) -> str:
    """
    v39: Substitui t√≠tulos "alias" (ex: 2. COMO FUNCIONA?) no texto
    pelo t√≠tulo can√¥nico (ex: 2. COMO ESTE MEDICAMENTO FUNCIONA?)
    para a exibi√ß√£o final lado-a-lado.
    """
    texto_corrigido = texto_completo
    
    # Itera de tr√°s para frente para n√£o bagun√ßar os √≠ndices de substitui√ß√£o
    for secao_mapa in reversed(mapa_secoes): 
        titulo_encontrado = secao_mapa['titulo_encontrado']
        titulo_canonico = secao_mapa['canonico']
        
        # Normaliza para uma compara√ß√£o simples
        norm_encontrado = normalizar_titulo_para_comparacao(titulo_encontrado)
        norm_canonico = normalizar_titulo_para_comparacao(titulo_canonico)

        if norm_encontrado != norm_canonico:
            # Tenta substituir o t√≠tulo encontrado (exato) pelo can√¥nico
            # Usa re.escape para lidar com caracteres especiais como '?'
            try:
                # Cria um padr√£o que encontra o t√≠tulo exato, ignorando o caso
                pattern = re.compile(re.escape(titulo_encontrado), re.IGNORECASE)
                
                # Substitui apenas a primeira ocorr√™ncia para seguran√ßa
                # Usa uma fun√ß√£o lambda para manter a capitaliza√ß√£o original (se poss√≠vel)
                # Mas para t√≠tulos, √© mais seguro for√ßar o t√≠tulo can√¥nico.
                
                # Encontra o match para saber a posi√ß√£o
                match = pattern.search(texto_corrigido)
                if match:
                    # Substitui mantendo a estrutura de linhas (se houver)
                    # Esta l√≥gica √© mais simples e segura:
                    texto_corrigido = texto_corrigido[:match.start()] + titulo_canonico + texto_corrigido[match.end():]

            except re.error:
                # Fallback se o 'titulo_encontrado' for um regex inv√°lido (raro)
                pass # √â melhor n√£o fazer a substitui√ß√£o do que quebrar
                
    return texto_corrigido


# ----------------- [ATUALIZADO - v39] RELAT√ìRIO E EXPORTA√á√ÉO -----------------
def gerar_relatorio_final(texto_ref: str, texto_belfar: str, nome_ref: str, nome_belfar: str, tipo_bula: str):
    
    regex_anvisa = r"(aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova√ß√£o\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    
    match_ref = list(re.finditer(regex_anvisa, texto_ref, re.IGNORECASE))
    match_belfar = list(re.finditer(regex_anvisa, texto_belfar, re.IGNORECASE))
    
    data_ref = match_ref[-1].group(2).strip() if match_ref else "N√£o encontrada"
    data_belfar = match_belfar[-1].group(2).strip() if match_belfar else "N√£o encontrada"
    
    mapa_ref = mapear_secoes(texto_ref, obter_secoes_por_tipo(tipo_bula))
    mapa_belfar = mapear_secoes(texto_belfar, obter_secoes_por_tipo(tipo_bula))
    
    secoes_faltantes, diferencas_conteudo, similaridades, diferencas_titulos = verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula)
    erros_ortograficos = checar_ortografia_inteligente(texto_belfar, texto_ref, tipo_bula)
    score_similaridade_conteudo = sum(similaridades) / len(similaridades) if similaridades else 100.0

    st.header("Relat√≥rio de Auditoria Inteligente")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Conformidade de Conte√∫do", f"{score_similaridade_conteudo:.0f}%")
    col2.metric("Erros Ortogr√°ficos", len(erros_ortograficos))
    col3.metric("Data ANVISA (BELFAR)", data_belfar)
    col4.metric("Se√ß√µes Faltantes", f"{len(secoes_faltantes)}")

    st.divider()
    st.subheader("Detalhes dos Problemas Encontrados")
    st.info(f"‚ÑπÔ∏è **Datas de Aprova√ß√£o ANVISA (√öltima encontrada):**\n - Arte Vigente: {data_ref}\n - PDF da Gr√°fica: {data_belfar}")

    if secoes_faltantes:
        st.error(f"üö® **Se√ß√µes faltantes na bula BELFAR ({len(secoes_faltantes)})**:\n" + "\n".join([f" - {s}" for s in secoes_faltantes]))
    else:
        st.success("‚úÖ Todas as se√ß√µes obrigat√≥rias est√£o presentes")

    st.warning(f"‚ö†Ô∏è **Relat√≥rio de Conte√∫do por Se√ß√£o:**")
    mapa_diferencas = {diff['secao']: diff for diff in diferencas_conteudo}
    secoes_esperadas = obter_secoes_por_tipo(tipo_bula)
    
    secoes_para_nao_mostrar_expander = [
        "APRESENTA√á√ïES", "COMPOSI√á√ÉO", "DIZERES LEGAIS"
    ]
    secoes_nao_mostrar_norm = [normalizar_titulo_para_comparacao(s) for s in secoes_para_nao_mostrar_expander]
    ignorar_comparacao_norm = [normalizar_titulo_para_comparacao(s) for s in obter_secoes_ignorar_comparacao()]

    expander_caixa_style = (
        "height: 350px; overflow-y: auto; border: 2px solid #d0d0d0; border-radius: 6px; "
        "padding: 16px; background-color: #ffffff; font-size: 14px; line-height: 1.8; "
        "font-family: 'Georgia', 'Times New Roman', serif; text-align: justify;"
    )

    for secao in secoes_esperadas:
        secao_canon_norm = normalizar_titulo_para_comparacao(secao)
        
        if (secao_canon_norm in ignorar_comparacao_norm or 
            secao_canon_norm in secoes_nao_mostrar_norm):
            continue
            
        if secao in secoes_faltantes:
            continue
            
        encontrou_ref, _, conteudo_ref_para_marcar = obter_dados_secao(secao, mapa_ref, texto_ref.split('\n'), tipo_bula)
        encontrou_belfar, titulo_belfar_encontrado, conteudo_bel_para_marcar = obter_dados_secao(secao, mapa_belfar, texto_belfar.split('\n'), tipo_bula)

        if not encontrou_ref or not encontrou_belfar:
            continue 

        diff = mapa_diferencas.get(secao)
        
        # --- [Mantido - v38] ---
        # L√≥gica de exibi√ß√£o do t√≠tulo corrigida
        if diff:
            expander_title = f"üìÑ {secao} - ‚ùå CONTE√öDO DIVERGENTE"
        else:
            expander_title = f"üìÑ {secao} - ‚úÖ CONTE√öDO ID√äNTICO"
        # --- [FIM] ---
            
        with st.expander(expander_title, expanded=bool(diff)): 
            anchor_id_ref = _create_anchor_id(secao, "ref")
            anchor_id_bel = _create_anchor_id(secao, "bel")

            expander_html_ref = marcar_diferencas_palavra_por_palavra(
                conteudo_ref_para_marcar, conteudo_bel_para_marcar, eh_referencia=True
            ).replace('\n', '<br>')
            
            expander_html_belfar = marcar_diferencas_palavra_por_palavra(
                conteudo_bel_para_marcar, conteudo_bel_para_marcar, eh_referencia=False
            ).replace('\n', '<br>')

            clickable_style = expander_caixa_style + " cursor: pointer; transition: background-color 0.3s ease;"
            
            html_ref_box = f"<div onclick='window.handleBulaScroll(\"{anchor_id_ref}\", \"{anchor_id_bel}\")' style='{clickable_style}' title='Clique para ir √† se√ß√£o' onmouseover='this.style.backgroundColor=\"#f0f8ff\"' onmouseout='this.style.backgroundColor=\"#ffffff\"'>{expander_html_ref}</div>"
            html_bel_box = f"<div onclick='window.handleBulaScroll(\"{anchor_id_ref}\", \"{anchor_id_bel}\")' style='{clickable_style}' title='Clique para ir √† se√ß√£o' onmouseover='this.style.backgroundColor=\"#f0f8ff\"' onmouseout='this.style.backgroundColor=\"#ffffff\"'>{expander_html_belfar}</div>"
            
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("**Arte Vigente:** (Clique na caixa para rolar)")
                st.markdown(html_ref_box, unsafe_allow_html=True)
            with c2:
                st.markdown("**PDF da Gr√°fica:** (Clique na caixa para rolar)")
                st.markdown(html_bel_box, unsafe_allow_html=True)
    
    if erros_ortograficos:
        st.info(f"üìù **Poss√≠veis erros ortogr√°ficos ({len(erros_ortograficos)}):**\n" + ", ".join(erros_ortograficos))
    
    if not any([secoes_faltantes, diferencas_conteudo, diferencas_titulos]) and len(erros_ortograficos) < 5:
        st.success("üéâ **Bula aprovada!** Nenhum problema cr√≠tico encontrado.")
    
    st.divider()
    
    st.subheader("Visualiza√ß√£o Lado a Lado com Destaques")
    st.markdown(
        "**Legenda:** <mark style='background-color: #ffff99; padding: 2px;'>Amarelo</mark> = Diverg√™ncias | "
        "<mark style='background-color: #FFDDC1; padding: 2px;'>Rosa</mark> = Erros ortogr√°ficos | "
        "<mark style='background-color: #cce5ff; padding: 2px;'>Azul</mark> = Data ANVISA",
        unsafe_allow_html=True
    )
    
    # --- [IN√çCIO DA CORRE√á√ÉO v39] ---
    # Substitui os t√≠tulos-alias pelos t√≠tulos can√¥nicos
    # ANTES de passar para a fun√ß√£o de marca√ß√£o de HTML.
    texto_ref_com_titulos_corretos = substituir_titulos_por_canonicos(texto_ref, mapa_ref)
    texto_belfar_com_titulos_corretos = substituir_titulos_por_canonicos(texto_belfar, mapa_belfar)
    
    html_ref_marcado = marcar_divergencias_html(
        texto_ref_com_titulos_corretos, # <--- Usa o texto corrigido
        diferencas_conteudo, 
        [], 
        tipo_bula, 
        eh_referencia=True
    )
    html_belfar_marcado = marcar_divergencias_html(
        texto_belfar_com_titulos_corretos, # <--- Usa o texto corrigido
        diferencas_conteudo, 
        erros_ortograficos, 
        tipo_bula, 
        eh_referencia=False
    )
    # --- [FIM DA CORRE√á√ÉO v39] ---
    
    caixa_style = (
        "height: 700px; overflow-y: auto; border: 2px solid #999; border-radius: 4px; "
        "padding: 24px 32px; background-color: #ffffff; "
        "font-family: 'Georgia', 'Times New Roman', serif; font-size: 14px; "
        "line-height: 1.8; box-shadow: 0 2px 12px rgba(0,0,0,0.15);"
    )
    
    col1, col2 = st.columns(2, gap="medium")
    with col1:
        st.markdown(f"**üìÑ {nome_ref}**")
        st.markdown(f"<div id='container-ref-scroll' style='{caixa_style}'>{html_ref_marcado}</div>", unsafe_allow_html=True)
    with col2:
        st.markdown(f"**üìÑ {nome_belfar}**")
        st.markdown(f"<div id='container-bel-scroll' style='{caixa_style}'>{html_belfar_marcado}</div>", unsafe_allow_html=True)

    st.divider()

    relat√≥rio_html = gerar_relatorio_html_para_download(
        titulo="Relat√≥rio de Auditoria - Gr√°fica x Arte",
        nome_ref=nome_ref,
        nome_belfar=nome_belfar,
        data_ref=data_ref,
        data_belfar=data_belfar,
        score=score_similaridade_conteudo,
        erros_ortograficos=erros_ortograficos,
        secoes_faltantes=secoes_faltantes,
        diferencas_conteudo=diferencas_conteudo,
        html_ref=html_ref_marcado, # Passa o HTML j√° corrigido
        html_belfar=html_belfar_marcado # Passa o HTML j√° corrigido
    )


def gerar_relatorio_html_para_download(titulo: str, nome_ref: str, nome_belfar: str, data_ref: str, data_belfar: str, score: float, erros_ortograficos: List[str], secoes_faltantes: List[str], diferencas_conteudo: List[Dict], html_ref: str, html_belfar: str) -> str:
    resumo_erros = ", ".join(erros_ortograficos) if erros_ortograficos else "Nenhum"
    faltantes_html = "<br>".join([f"- {html.escape(s)}" for s in secoes_faltantes]) if secoes_faltantes else "Nenhuma"
    diferencas_lista_html = ""
    if diferencas_conteudo:
        for d in diferencas_conteudo:
            titulo_secao = html.escape(d.get('secao', 'Sec√£o'))
            diferencas_lista_html += f"<li><strong>{titulo_secao}</strong></li>"
    else:
        diferencas_lista_html = "<li>Nenhuma diferen√ßa relevante por se√ß√£o</li>"

    html_page = f"""<!doctype html>
<html lang="pt-BR">
<head>
<meta charset="utf-8" />
<title>{html.escape(titulo)}</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<style>
body{{font-family: Arial, Helvetica, sans-serif; color:#111; margin:20px; background:#f7f7f8}}
.header{{padding:10px 0}}
h1{{margin:0;font-size:22px}}
.metrics{{display:flex;flex-wrap:wrap;gap:12px;margin-top:12px}}
.metric{{background:#fff;padding:10px;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.08)}}
.container{{display:flex;gap:20px;flex-wrap:wrap}}
.column{{flex:1;background:#fff;padding:16px;border-radius:6px;box-shadow:0 1px 8px rgba(0,0,0,0.06);min-width:400px;height:80vh;overflow:auto}}
.legend{{margin:10px 0}}
mark{{background:#ffff99;padding:2px}}
</style>
</head>
<body>
<div class="header">
<h1>{html.escape(titulo)}</h1>
<div class="metrics">
<div class="metric"><strong>Score:</strong> {score:.0f}%</div>
<div class="metric"><strong>Data ANVISA (Ref):</strong> {html.escape(data_ref)}</div>
<div class="metric"><strong>Data ANVISA (BELFAR):</strong> {html.escape(data_belfar)}</div>
<div class="metric"><strong>Erros ortogr√°ficos:</strong> {html.escape(resumo_erros)}</div>
</div>
</div>

<h2>Sum√°rio</h2>
<ul>
<li><strong>Se√ß√µes faltantes:</strong><br>{faltantes_html}</li>
<li><strong>Diferen√ßas por se√ß√£o:</strong><ul>{diferencas_lista_html}</ul></li>
</ul>

<div class="container">
<div class="column">
<h3>{html.escape(nome_ref)}</h3>
{html_ref}
</div>
<div class="column">
<h3>{html.escape(nome_belfar)}</h3>
{html_belfar}
</div>
</div>

<footer style="margin-top:20px;font-size:12px;color:#666">
Gerado pelo sistema de Auditoria de Bulas ‚Äî v39
</footer>
</body>
</html>
"""
    return html_page

# ----------------- [ATUALIZADA - v39] INTERFACE PRINCIPAL -----------------
st.title("üî¨ Intelig√™ncia Artificial para Auditoria de Bulas")
st.markdown("Sistema avan√ßado de compara√ß√£o literal e valida√ß√£o de bulas farmac√™uticas ‚Äî aprimorado para PDFs de gr√°fica")
st.divider()

st.header("üìã Configura√ß√£o da Auditoria")
tipo_bula_selecionado = st.radio("Tipo de Bula:", ("Paciente"), horizontal=True)

col1, col2 = st.columns(2)
with col1:
    st.subheader("üìÑ Arte Vigente")
    pdf_ref = st.file_uploader("Envie o PDF da Arte Vigente", type=["pdf"], key="ref")

with col2:
    st.subheader("üìÑ PDF da Gr√°fica")
    pdf_belfar = st.file_uploader("Envie o PDF da Gr√°fica", type="pdf", key="belfar")

if st.button("üîç Iniciar Auditoria Completa", use_container_width=True, type="primary"):
    if pdf_ref and pdf_belfar:
        with st.spinner("üîÑ Processando e analisando as bulas... (v39 - For√ßando OCR psm 3 Full-Page)"):
            
            tipo_arquivo_ref = 'docx' if pdf_ref.name.lower().endswith('.docx') else 'pdf'
            
            texto_ref, erro_ref = extrair_texto(pdf_ref, tipo_arquivo_ref)
            texto_belfar, erro_belfar = extrair_texto(pdf_belfar, 'pdf')
            
            if not erro_ref:
                texto_ref = truncar_apos_anvisa(texto_ref)
            if not erro_belfar:
                texto_belfar = truncar_apos_anvisa(texto_belfar)

            if erro_ref or erro_belfar:
                st.error(f"Erro ao processar arquivos: {erro_ref or erro_belfar}")
            else:
                # v39: A fun√ß√£o gerar_relatorio_final agora est√° corrigida
                gerar_relatorio_final(texto_ref, texto_belfar, "Arte Vigente", "PDF da Gr√°fica", tipo_bula_selecionado)
    else:
        st.warning("‚ö†Ô∏è Por favor, envie ambos os arquivos (Refer√™ncia e BELFAR) para iniciar a auditoria.")

st.divider()
st.caption("Sistema de Auditoria de Bulas v39 | Corre√ß√£o de Display de T√≠tulo Lado-a-Lado")
