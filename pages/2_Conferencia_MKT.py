# --- IMPORTS ---
import streamlit as st
from style_utils import hide_streamlit_toolbar

hide_streamlit_UI = """
            <style>
            /* Esconde o cabeÃ§alho do Streamlit Cloud (com 'Fork' e GitHub) */
            [data-testid="stHeader"] {
                display: none !important;
                visibility: hidden !important;
            }
            
            /* Esconde o menu hamburger (dentro do app) */
            [data-testid="main-menu-button"] {
                display: none !important;
            }
            
            /* Esconde o rodapÃ© genÃ©rico (garantia extra) */
            footer {
                display: none !important;
                visibility: hidden !important;
            }

            /* --- NOVOS SELETORES (MAIS AGRESSIVOS) PARA O BADGE INFERIOR --- */

            /* Esconde o container principal do badge */
            [data-testid="stStatusWidget"] {
                display: none !important;
                visibility: hidden !important;
            }

            /* Esconde o 'Created by' */
            [data-testid="stCreatedBy"] {
                display: none !important;
                visibility: hidden !important;
            }

            /* Esconde o 'Hosted with Streamlit' */
            [data-testid="stHostedBy"] {
                display: none !important;
                visibility: hidden !important;
            }
            </style>
            """
st.markdown(hide_streamlit_UI, unsafe_allow_html=True)
import fitz  # PyMuPDF
import docx
import re
import spacy
from thefuzz import fuzz
from spellchecker import SpellChecker
import difflib
import unicodedata

# ----------------- MODELO NLP -----------------
@st.cache_resource
def carregar_modelo_spacy():
    """Carrega o modelo de linguagem SpaCy de forma otimizada."""
    try:
        return spacy.load("pt_core_news_lg")
    except OSError:
        st.error("Modelo 'pt_core_news_lg' nÃ£o encontrado. Execute: python -m spacy download pt_core_news_lg")
        return None

nlp = carregar_modelo_spacy()

# ----------------- EXTRAÃ‡ÃƒO -----------------
def extrair_texto(arquivo, tipo_arquivo):
    if arquivo is None:
        return "", f"Arquivo {tipo_arquivo} nÃ£o enviado."
    try:
        arquivo.seek(0)
        texto = ""
        if tipo_arquivo == 'pdf':
            full_text_list = []
            
            # --- MUDANÃ‡A 4: CORRIGIDO O "MEIO" DA PÃGINA ---
            # O corte agora Ã© feito exatamente em 50% (ao "meio")
            # como vocÃª indicou.
            with fitz.open(stream=arquivo.read(), filetype="pdf") as doc:
                for page in doc:
                    rect = page.rect
                    
                    # Define a coluna da esquerda (do inÃ­cio atÃ© o meio)
                    clip_esquerda = fitz.Rect(0, 0, rect.width / 2, rect.height)
                    
                    # Define a coluna da direita (do meio atÃ© o fim)
                    clip_direita = fitz.Rect(rect.width / 2, 0, rect.width, rect.height)

                    # 1. Extrai o texto da coluna da ESQUERDA primeiro
                    texto_esquerda = page.get_text("text", clip=clip_esquerda, sort=True)
                    
                    # 2. Extrai o texto da coluna da DIREITA depois
                    texto_direita = page.get_text("text", clip=clip_direita, sort=True)
                    
                    # 3. Junta as duas colunas na ordem correta
                    full_text_list.append(texto_esquerda)
                    full_text_list.append(texto_direita)
                    
            texto = "\n\n".join(full_text_list) # \n\n para separar colunas/pÃ¡ginas
        
        elif tipo_arquivo == 'docx':
            doc = docx.Document(arquivo)
            texto = "\n".join([p.text for p in doc.paragraphs])
        
        if texto:
            caracteres_invisiveis = ['\u00AD', '\u200B', '\u200C', '\u200D', '\uFEFF']
            for char in caracteres_invisiveis:
                texto = texto.replace(char, '')
            texto = texto.replace('\r\n', '\n').replace('\r', '\n')
            texto = texto.replace('\u00A0', ' ')
            texto = re.sub(r'(\w+)-\n(\w+)', r'\1\2', texto, flags=re.IGNORECASE)
            
            linhas = texto.split('\n')
            
            # --- FILTRO DE RUÃDO APRIMORADO ---
            # Adiciona os novos ruÃ­dos (REZA, GEM) e melhora a detecÃ§Ã£o
            # de "Medida da bula" etc., mesmo com erros de digitaÃ§Ã£o.
            padrao_ruido_linha = re.compile(
                r'bula do paciente|pÃ¡gina \d+\s*de\s*\d+'  # RodapÃ© padrÃ£o
                r'|(Tipologie|Tipologia) da bula:.*|(Merida|Medida) da (bula|trÃºa):?.*' # RuÃ­do do MKT (com erros)
                r'|(ImpressÃ£e|ImpressÃ£o):? Frente/Verso|Papel[\.:]? Ap \d+gr' # RuÃ­do do MKT (com erros)
                r'|Cor:? Preta|contato:?|artes@belfar\.com\.br' # RuÃ­do do MKT
                r'|BUL_CLORIDRATO_DE_NAFAZOLINA_BUL\d+V\d+' # Nome do arquivo
                r'|CLORIDRATO DE NAFAZOLINA: Times New Roman' # RuÃ­do do MKT
                r'|^\s*FRENTE\s*$|^\s*VERSO\s*$' # Indicador de pÃ¡gina
                r'|^\s*\d+\s*mm\s*$' # Medidas (ex: 190 mm, 300 mm)
                r'|^\s*-\s*Normal e Negrito\. Corpo \d+\s*$' # Linha de formataÃ§Ã£o
                r'|^\s*BELFAR\s*$|^\s*REZA\s*$|^\s*GEM\s*$|^\s*ALTEFAR\s*$|^\s*RECICLAVEL\s*$|^\s*BUL\d+\s*$' # RuÃ­do do rodapÃ©
            , re.IGNORECASE)
            
            linhas_filtradas = []
            for linha in linhas:
                linha_strip = linha.strip()
                # Remove linhas de ruÃ­do E linhas muito curtas (lixo de extraÃ§Ã£o)
                # MantÃ©m a exceÃ§Ã£o para tÃ­tulos curtos (ex: USO NASAL)
                if not padrao_ruido_linha.search(linha_strip):
                    if len(linha_strip) > 1 or (len(linha_strip) == 1 and linha_strip.isdigit()):
                        linhas_filtradas.append(linha_strip)
                    elif linha_strip.isupper() and len(linha_strip) > 0: # Salva "USO NASAL" etc.
                        linhas_filtradas.append(linha_strip)
            
            texto = "\n".join(linhas_filtradas)
            
            texto = re.sub(r'\n{3,}', '\n\n', texto) 
            texto = re.sub(r'[ \t]+', ' ', texto)
            texto = texto.strip()

        return texto, None
    except Exception as e:
        return "", f"Erro ao ler o arquivo {tipo_arquivo}: {e}"
        
def truncar_apos_anvisa(texto):
    if not isinstance(texto, str):
        return texto
    regex_anvisa = r"(aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprovaÃ§Ã£o\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    match = re.search(regex_anvisa, texto, re.IGNORECASE)
    if match:
        end_of_line_pos = texto.find('\n', match.end())
        if end_of_line_pos != -1:
            return texto[:end_of_line_pos]
        else:
            return texto
    return texto

# ----------------- CONFIGURAÃ‡ÃƒO DE SEÃ‡Ã•ES -----------------
def obter_secoes_por_tipo(tipo_bula):
    secoes = {
        "Paciente": [
            "APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO",
            "COMO ESTE MEDICAMENTO FUNCIONA?", "QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
            "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
            "COMO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
            "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?",
            "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
            "DIZERES LEGAIS"
        ],
        "Profissional": [
            "APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "INDICAÃ‡Ã•ES", "RESULTADOS DE EFICÃCIA",
            "CARACTERÃSTICAS FARMACOLÃ“GICAS", "CONTRAINDICAÃ‡Ã•ES",
            "ADVERTÃŠNCIAS E PRECAUÃ‡Ã•ES", "INTERAÃ‡Ã•ES MEDICAMENTOSAS",
            "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO", "POSOLOGIA E MODO DE USAR",
            "REAÃ‡Ã•ES ADVERSAS", "SUPERDOSE", "DIZERES LEGAIS"
        ]
    }
    return secoes.get(tipo_bula, [])

def obter_aliases_secao():
    return {
        "INDICAÃ‡Ã•ES": "PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO?",
        "CONTRAINDICAÃ‡Ã•ES": "QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?",
        "POSOLOGIA E MODO DE USAR": "COMO DEVO USAR ESTE MEDICAMENTO?",
        "REAÃ‡Ã•ES ADVERSAS": "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?",
        "SUPERDOSE": "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
        "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO": "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?"
    }

def obter_secoes_ignorar_ortografia():
    return ["COMPOSIÃ‡ÃƒO", "DIZERES LEGAIS"]

def obter_secoes_ignorar_comparacao():
    return ["COMPOSIÃ‡ÃƒO", "DIZERES LEGAIS", "APRESENTAÃ‡Ã•ES", "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?"]

# ----------------- NORMALIZAÃ‡ÃƒO -----------------
def normalizar_texto(texto):
    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')
    texto = re.sub(r'[^\w\s]', '', texto)
    texto = ' '.join(texto.split())
    return texto.lower()

def normalizar_titulo_para_comparacao(texto):
    """NormalizaÃ§Ã£o robusta para tÃ­tulos, removendo acentos, pontuaÃ§Ã£o e numeraÃ§Ã£o inicial."""
    texto_norm = normalizar_texto(texto)
    texto_norm = re.sub(r'^\d+\s*[\.\-)]*\s*', '', texto_norm).strip()
    return texto_norm

# ----------------- ARQUITETURA DE MAPEAMENTO DE SEÃ‡Ã•ES (VERSÃƒO FINAL) -----------------
def is_titulo_secao(linha):
    """Retorna True se a linha for um possÃ­vel tÃ­tulo de seÃ§Ã£o puro."""
    linha = linha.strip()
    if len(linha) < 4 or len(linha.split()) > 12:
        return False
    if linha.endswith('.') or linha.endswith(':'):
        return False
    if re.search(r'\>\s*\<', linha):
        return False
    if len(linha) > 80:
        return False
    return True

# >>>>> FUNÃ‡ÃƒO CORRIGIDA 1 de 2 <<<<<
def mapear_secoes(texto_completo, secoes_esperadas):
    mapa = []
    linhas = texto_completo.split('\n')
    aliases = obter_aliases_secao()
    
    titulos_possiveis = {}
    for secao in secoes_esperadas:
        titulos_possiveis[secao] = secao
    for alias, canonico in aliases.items():
        if canonico in secoes_esperadas:
            titulos_possiveis[alias] = canonico

    idx = 0
    while idx < len(linhas):
        linha_limpa = linhas[idx].strip()

        if not is_titulo_secao(linha_limpa):
            idx += 1
            continue

        # --- LÃ“GICA DE DETECÃ‡ÃƒO DE TÃTULO DE 1 OU 2 LINHAS ---
        best_match_score_1_linha = 0
        best_match_canonico_1_linha = None
        for titulo_possivel, titulo_canonico in titulos_possiveis.items():
            score = fuzz.token_set_ratio(normalizar_titulo_para_comparacao(titulo_possivel), normalizar_titulo_para_comparacao(linha_limpa))
            if score > best_match_score_1_linha:
                best_match_score_1_linha = score
                best_match_canonico_1_linha = titulo_canonico

        best_match_score_2_linhas = 0
        best_match_canonico_2_linhas = None
        titulo_combinado = ""
        if (idx + 1) < len(linhas):
            linha_seguinte = linhas[idx + 1].strip()
            if len(linha_seguinte.split()) < 7:
                titulo_combinado = f"{linha_limpa} {linha_seguinte}"
                for titulo_possivel, titulo_canonico in titulos_possiveis.items():
                    score = fuzz.token_set_ratio(normalizar_titulo_para_comparacao(titulo_possivel), normalizar_titulo_para_comparacao(titulo_combinado))
                    if score > best_match_score_2_linhas:
                        best_match_score_2_linhas = score
                        best_match_canonico_2_linhas = titulo_canonico
        
        limiar_score = 95
        
        if best_match_score_2_linhas > best_match_score_1_linha and best_match_score_2_linhas >= limiar_score:
            if not mapa or mapa[-1]['canonico'] != best_match_canonico_2_linhas:
                mapa.append({
                    'canonico': best_match_canonico_2_linhas,
                    'titulo_encontrado': titulo_combinado,
                    'linha_inicio': idx,
                    'score': best_match_score_2_linhas,
                    'num_linhas_titulo': 2
                })
            idx += 2
        elif best_match_score_1_linha >= limiar_score:
            if not mapa or mapa[-1]['canonico'] != best_match_canonico_1_linha:
                mapa.append({
                    'canonico': best_match_canonico_1_linha,
                    'titulo_encontrado': linha_limpa,
                    'linha_inicio': idx,
                    'score': best_match_score_1_linha,
                    'num_linhas_titulo': 1
                })
            idx += 1
        else:
            idx += 1
            
    mapa.sort(key=lambda x: x['linha_inicio'])
    return mapa

# >>>>> FUNÃ‡ÃƒO CORRIGIDA 2 de 2 <<<<<
def obter_dados_secao(secao_canonico, mapa_secoes, linhas_texto, tipo_bula):
    """
    Extrai o conteÃºdo de uma seÃ§Ã£o, procurando ativamente pelo prÃ³ximo tÃ­tulo para determinar o fim.
    Esta versÃ£o verifica se o prÃ³ximo tÃ­tulo estÃ¡ em uma Ãºnica linha ou dividido em duas linhas consecutivas.
    """
    # TÃ­tulos oficiais da bula para o tipo selecionado
    TITULOS_OFICIAIS = {
        "Paciente": [
            "APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO",
            "COMO ESTE MEDICAMENTO FUNCIONA?", "QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
            "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
            "COMO DEVO USAR ESTE MEDICAMENTO?",
            "O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
            "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?",
            "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
            "DIZERES LEGAIS"
        ],
        "Profissional": [
            "APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "INDICAÃ‡Ã•ES", "RESULTADOS DE EFICÃCIA",
            "CARACTERÃSTICAS FARMACOLÃ“GICAS", "CONTRAINDICAÃ‡Ã•ES",
            "ADVERTÃŠNCIAS E PRECAUÃ‡Ã•ES", "INTERAÃ‡Ã•ES MEDICAMENTOSAS",
            "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO", "POSOLOGIA E MODO DE USAR",
            "REAÃ‡Ã•ES ADVERSAS", "SUPERDOSE", "DIZERES LEGAIS"
        ]
    }

    titulos_lista = TITULOS_OFICIAIS.get(tipo_bula, [])
    # Normaliza a lista de tÃ­tulos oficiais uma vez para otimizar a busca
    titulos_norm_set = {normalizar_titulo_para_comparacao(t) for t in titulos_lista}

    for i, secao_mapa in enumerate(mapa_secoes):
        if secao_mapa['canonico'] != secao_canonico:
            continue

        titulo_encontrado = secao_mapa['titulo_encontrado']
        linha_inicio = secao_mapa['linha_inicio']
        num_linhas_titulo = secao_mapa.get('num_linhas_titulo', 1)
        
        # O conteÃºdo comeÃ§a DEPOIS do tÃ­tulo (1 ou 2 linhas)
        linha_inicio_conteudo = linha_inicio + num_linhas_titulo

        # --- LÃ“GICA DE BUSCA APRIMORADA (1 ou 2 linhas) ---
        prox_idx = None
        for j in range(linha_inicio_conteudo, len(linhas_texto)):
            # Verifica a linha atual (busca de 1 linha)
            linha_atual = linhas_texto[j].strip()
            linha_atual_norm = normalizar_titulo_para_comparacao(linha_atual)

            if linha_atual_norm in titulos_norm_set:
                prox_idx = j  # Encontrou um tÃ­tulo em uma Ãºnica linha
                break

            # Se nÃ£o encontrou, verifica a combinaÃ§Ã£o da linha atual + prÃ³xima (busca de 2 linhas)
            if (j + 1) < len(linhas_texto):
                linha_seguinte = linhas_texto[j + 1].strip()
                # Concatena a linha atual com a prÃ³xima para formar um possÃ­vel tÃ­tulo
                titulo_duas_linhas = f"{linha_atual} {linha_seguinte}"
                titulo_duas_linhas_norm = normalizar_titulo_para_comparacao(titulo_duas_linhas)

                if titulo_duas_linhas_norm in titulos_norm_set:
                    prox_idx = j  # Encontrou um tÃ­tulo dividido em duas linhas
                    break
        # --- FIM DA LÃ“GICA DE BUSCA ---

        linha_fim = prox_idx if prox_idx is not None else len(linhas_texto)

        conteudo = [linhas_texto[idx] for idx in range(linha_inicio_conteudo, linha_fim)]
        conteudo_final = "\n".join(conteudo).strip()
        
        return True, titulo_encontrado, conteudo_final

    return False, None, ""

# ----------------- COMPARAÃ‡ÃƒO DE CONTEÃšDO -----------------
# ----------------- COMPARAÃ‡ÃƒO DE CONTEÃšDO -----------------
def verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula):
Â  Â  secoes_esperadas = obter_secoes_por_tipo(tipo_bula)
Â  Â  secoes_faltantes, diferencas_conteudo, similaridades_secoes, diferencas_titulos = [], [], [], []
Â  Â  secoes_ignorar_upper = [s.upper() for s in obter_secoes_ignorar_comparacao()]

Â  Â  linhas_ref = texto_ref.split('\n')
Â  Â  linhas_belfar = texto_belfar.split('\n')
Â  Â  mapa_ref = mapear_secoes(texto_ref, secoes_esperadas)
Â  Â  mapa_belfar = mapear_secoes(texto_belfar, secoes_esperadas)

Â  Â  secoes_belfar_encontradas = {m['canonico']: m for m in mapa_belfar}

Â  Â  for secao in secoes_esperadas:
Â  Â  Â  Â  melhor_titulo = None # <-- [MODIFICAÃ‡ÃƒO 1] Inicializa a variÃ¡vel aqui
Â  Â  Â  Â  encontrou_ref, _, conteudo_ref = obter_dados_secao(secao, mapa_ref, linhas_ref, tipo_bula)
Â  Â  Â  Â  encontrou_belfar, titulo_belfar, conteudo_belfar = obter_dados_secao(secao, mapa_belfar, linhas_belfar, tipo_bula)

Â  Â  Â  Â  if not encontrou_belfar:
Â  Â  Â  Â  Â  Â  melhor_score = 0
Â  Â  Â  Â  Â  Â  melhor_titulo = None
Â  Â  Â  Â  Â  Â  for m in mapa_belfar:
Â  Â  Â  Â  Â  Â  Â  Â  score = fuzz.token_set_ratio(normalizar_titulo_para_comparacao(secao), normalizar_titulo_para_comparacao(m['titulo_encontrado']))
Â  Â  Â  Â  Â  Â  Â  Â  if score > melhor_score:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  melhor_score = score
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  melhor_titulo = m['titulo_encontrado']
Â  Â  Â  Â  Â  Â  if melhor_score >= 95:
Â  Â  Â  Â  Â  Â  Â  Â  diferencas_titulos.append({'secao_esperada': secao, 'titulo_encontrado': melhor_titulo})
Â  Â  Â  Â  Â  Â  Â  Â  for m in mapa_belfar:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if m['titulo_encontrado'] == melhor_titulo:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # LÃ³gica para pegar conteÃºdo da seÃ§Ã£o encontrada por similaridade
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  next_section_start = len(linhas_belfar)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_index = mapa_belfar.index(m)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if current_index + 1 < len(mapa_belfar):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  next_section_start = mapa_belfar[current_index + 1]['linha_inicio']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Pega o conteÃºdo a partir da linha *apÃ³s* o tÃ­tulo encontrado
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  conteudo_belfar = "\n".join(linhas_belfar[m['linha_inicio']+1:next_section_start])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  Â  Â  encontrou_belfar = True
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  secoes_faltantes.append(secao)
Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  if encontrou_ref and encontrou_belfar:
Â  Â  Â  Â  Â  Â  secao_comp = normalizar_titulo_para_comparacao(secao)
Â  Â  Â  Â  Â  Â  # Usa o 'titulo_belfar' (da busca direta) ou 'melhor_titulo' (da busca fuzzy)
Â  Â  Â  Â  Â  Â  titulo_belfar_comp = normalizar_titulo_para_comparacao(titulo_belfar if titulo_belfar else melhor_titulo)

Â  Â  Â  Â  Â  Â  if secao_comp != titulo_belfar_comp:
Â  Â  Â  Â  Â  Â  Â  Â  if not any(d['secao_esperada'] == secao for d in diferencas_titulos):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  diferencas_titulos.append({'secao_esperada': secao, 'titulo_encontrado': titulo_belfar if titulo_belfar else melhor_titulo})

Â  Â  Â  Â  Â  Â  if secao.upper() in secoes_ignorar_upper:
Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  if normalizar_texto(conteudo_ref) != normalizar_texto(conteudo_belfar):
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # --- [MODIFICAÃ‡ÃƒO 2] ---
Â  Â  Â  Â  Â  Â  Â  Â  # Define o tÃ­tulo que foi realmente encontrado (pode ser da busca normal ou fuzzy)
Â  Â  Â  Â  Â  Â  Â  Â  titulo_real_encontrado = titulo_belfar if titulo_belfar else melhor_titulo
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  diferencas_conteudo.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'secao': secao,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'conteudo_ref': conteudo_ref,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'conteudo_belfar': conteudo_belfar,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'titulo_encontrado': titulo_real_encontrado # <-- Salva o tÃ­tulo real
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  Â  Â  # --- [FIM DA MODIFICAÃ‡ÃƒO] ---
Â  Â  Â  Â  Â  Â  Â  Â  similaridades_secoes.append(0)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  similaridades_secoes.append(100)

Â  Â  return secoes_faltantes, diferencas_conteudo, similaridades_secoes, diferencas_titulos


# ----------------- ORTOGRAFIA -----------------
def checar_ortografia_inteligente(texto_para_checar, texto_referencia, tipo_bula):
    if not nlp or not texto_para_checar:
        return []

    try:
        secoes_ignorar = obter_secoes_ignorar_ortografia()
        secoes_todas = obter_secoes_por_tipo(tipo_bula)
        texto_filtrado_para_checar = []

        mapa_secoes = mapear_secoes(texto_para_checar, secoes_todas)
        linhas_texto = texto_para_checar.split('\n')

        for secao_nome in secoes_todas:
            if secao_nome.upper() in [s.upper() for s in secoes_ignorar]:
                continue
            
            encontrou, _, conteudo = obter_dados_secao(secao_nome, mapa_secoes, linhas_texto, tipo_bula)
            if encontrou and conteudo:
                texto_filtrado_para_checar.append(conteudo)

        texto_final_para_checar = '\n'.join(texto_filtrado_para_checar)
        
        if not texto_final_para_checar:
            return []

        spell = SpellChecker(language='pt')
        palavras_a_ignorar = {"alair", "belfar", "peticionamento", "urotrobel", "contato"}
        vocab_referencia = set(re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ¢ÃªÃ´Ã£ÃµÃ§Ã¼]+\b', texto_referencia.lower()))
        doc = nlp(texto_para_checar)
        entidades = {ent.text.lower() for ent in doc.ents}

        spell.word_frequency.load_words(
            vocab_referencia.union(entidades).union(palavras_a_ignorar)
        )

        palavras = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ¢ÃªÃ´Ã£ÃµÃ§Ã¼]+\b', texto_final_para_checar.lower())
        erros = spell.unknown(palavras)
        return list(sorted(set([e for e in erros if len(e) > 3])))[:20]

    except Exception as e:
        return []

# ----------------- DIFERENÃ‡AS PALAVRA A PALAVRA -----------------
def marcar_diferencas_palavra_por_palavra(texto_ref, texto_belfar, eh_referencia):
    def tokenizar(txt):
        return re.findall(r'\n|[A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿0-9_]+|[^\w\s]', txt, re.UNICODE)

    def norm(tok):
        if re.match(r'[A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿0-9_]+$', tok):
            return normalizar_texto(tok)
        return tok

    ref_tokens = tokenizar(texto_ref)
    bel_tokens = tokenizar(texto_belfar)
    ref_norm = [norm(t) for t in ref_tokens]
    bel_norm = [norm(t) for t in bel_tokens]

    matcher = difflib.SequenceMatcher(None, ref_norm, bel_norm, autojunk=False)
    indices = set()
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag != 'equal':
            indices.update(range(i1, i2) if eh_referencia else range(j1, j2))

    tokens = ref_tokens if eh_referencia else bel_tokens
    marcado = []
    for idx, tok in enumerate(tokens):
        if idx in indices and tok.strip() != '':
            marcado.append(f"<mark style='background-color: #ffff99; padding: 2px;'>{tok}</mark>")
        else:
            marcado.append(tok)

    # --- LÃ“GICA DE RECONSTRUÃ‡ÃƒO DE TEXTO CORRIGIDA ---
    # Esta lÃ³gica junta os tokens de forma mais inteligente,
    # evitando espaÃ§os antes de pontuaÃ§Ã£o ou depois de quebras de linha.
    resultado = ""
    for i, tok in enumerate(marcado):
        if i == 0:
            resultado += tok
            continue

        tok_anterior_raw = re.sub(r'^<mark[^>]*>|</mark>$', '', marcado[i-1])
        raw_tok = re.sub(r'^<mark[^>]*>|</mark>$', '', tok)

        # Adiciona espaÃ§o SE:
        # O token atual NÃƒO Ã© pontuaÃ§Ã£o, NÃƒO Ã© newline, E
        # O token anterior NÃƒO Ã© newline, NÃƒO Ã© parÃªntese de abertura
        if not re.match(r'^[.,;:!?)\]]$', raw_tok) and \
           raw_tok != '\n' and \
           tok_anterior_raw != '\n' and \
           not re.match(r'^[(\[]$', tok_anterior_raw):
            resultado += " " + tok
        else:
            resultado += tok
    # --- FIM DA CORREÃ‡ÃƒO ---
            
    resultado = re.sub(r"(</mark>)\s+(<mark[^>]*>)", " ", resultado)
    return resultado

# ----------------- MARCAÃ‡ÃƒO POR SEÃ‡ÃƒO COM ÃNDICES -----------------
def marcar_divergencias_html(texto_original, secoes_problema, erros_ortograficos, tipo_bula, eh_referencia=False):
    texto_trabalho = texto_original
    
    if secoes_problema:
        for diff in secoes_problema:
            conteudo_ref = diff['conteudo_ref']
            conteudo_belfar = diff['conteudo_belfar']
            
            conteudo_a_marcar = conteudo_ref if eh_referencia else conteudo_belfar
            
            # Garante que o conteÃºdo a marcar nÃ£o seja vazio para evitar replace em todo o texto
            if conteudo_a_marcar and conteudo_a_marcar in texto_trabalho:
                conteudo_marcado = marcar_diferencas_palavra_por_palavra(
                    conteudo_ref, 
                    conteudo_belfar, 
                    eh_referencia
                )
                texto_trabalho = texto_trabalho.replace(conteudo_a_marcar, conteudo_marcado, 1)

    if erros_ortograficos and not eh_referencia:
        for erro in erros_ortograficos:
            pattern = r'(?<![<>a-zA-Z])(?<!mark>)(?<!;>)\b(' + re.escape(erro) + r')\b(?![<>])'
            texto_trabalho = re.sub(
                pattern,
                r"<mark style='background-color: #FFDDC1; padding: 2px;'>\1</mark>",
                texto_trabalho,
                flags=re.IGNORECASE
            )
            
    regex_anvisa = r"((?:aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprovaÃ§Ã£o\s+na\s+anvisa:)\s*[\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
    match = re.search(regex_anvisa, texto_original, re.IGNORECASE)
    
    if match:
        frase_anvisa = match.group(1)
        if frase_anvisa in texto_trabalho:
            texto_trabalho = texto_trabalho.replace(
                frase_anvisa,
                f"<mark style='background-color: #cce5ff; padding: 2px; font-weight: 500;'>{frase_anvisa}</mark>",
                1
            )

    return texto_trabalho

# ----------------- RELATÃ“RIO -----------------
# --- [TOTALMENTE MODIFICADO E CORRIGIDO] ---
def gerar_relatorio_final(texto_ref, texto_belfar, nome_ref, nome_belfar, tipo_bula):
Â  Â Â 
Â  Â  # --- [NOVO] Script Global (Plano C) ---
Â  Â  # Injeta a funÃ§Ã£o de rolagem no escopo GLOBAL (window)
Â  Â  # Isso garante que a funÃ§Ã£o `onclick` possa encontrÃ¡-la.
Â  Â  js_scroll_script = """
Â  Â  <script>
Â  Â  // Verifica se a funÃ§Ã£o jÃ¡ nÃ£o existe para evitar re-declaraÃ§Ã£o
Â  Â  if (!window.handleBulaScroll) {
Â  Â  Â  Â  window.handleBulaScroll = function(anchorIdRef, anchorIdBel) {
Â  Â  Â  Â  Â  Â  // Log para debug (Aperte F12 no navegador para ver)
Â  Â  Â  Â  Â  Â  console.log("Chamada handleBulaScroll:", anchorIdRef, anchorIdBel);

Â  Â  Â  Â  Â  Â  var containerRef = document.getElementById('container-ref-scroll');
Â  Â  Â  Â  Â  Â  var containerBel = document.getElementById('container-bel-scroll');
Â  Â  Â  Â  Â  Â  var anchorRef = document.getElementById(anchorIdRef);
Â  Â  Â  Â  Â  Â  var anchorBel = document.getElementById(anchorIdBel);

Â  Â  Â  Â  Â  Â  if (!containerRef || !containerBel) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error("ERRO: Containers 'container-ref-scroll' ou 'container-bel-scroll' nÃ£o encontrados.");
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if (!anchorRef || !anchorBel) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error("ERRO: Ã‚ncoras '" + anchorIdRef + "' ou '" + anchorIdBel + "' nÃ£o encontradas.");
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  // 1. Rola a PÃGINA PRINCIPAL para a visualizaÃ§Ã£o
Â  Â  Â  Â  Â  Â  containerRef.scrollIntoView({ behavior: 'smooth', block: 'start' });

Â  Â  Â  Â  Â  Â  // 2. Rola DENTRO dos containers (apÃ³s a rolagem principal)
Â  Â  Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var topPosRef = anchorRef.offsetTop - containerRef.offsetTop;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  containerRef.scrollTo({ top: topPosRef - 20, behavior: 'smooth' });
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Destaque visual
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  anchorRef.style.transition = 'background-color 0.5s ease-in-out';
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  anchorRef.style.backgroundColor = '#e6f7ff';
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  setTimeout(() => { anchorRef.style.backgroundColor = 'transparent'; }, 2500);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var topPosBel = anchorBel.offsetTop - containerBel.offsetTop;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  containerBel.scrollTo({ top: topPosBel - 20, behavior: 'smooth' });
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Destaque visual
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  anchorBel.style.transition = 'background-color 0.5s ease-in-out';
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  anchorBel.style.backgroundColor = '#e6f7ff';
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  setTimeout(() => { anchorBel.style.backgroundColor = 'transparent'; }, 2500);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.log("Rolagem interna EXECUTADA.");
Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error("Erro durante a rolagem interna:", e);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }, 700); // 700ms de espera
Â  Â  Â  Â  }
Â  Â  Â  Â  console.log("FunÃ§Ã£o window.handleBulaScroll DEFINIDA.");
Â  Â  }
Â  Â  </script>
Â  Â  """
Â  Â  # Injeta o script uma vez no topo do relatÃ³rio
Â  Â  st.markdown(js_scroll_script, unsafe_allow_html=True)
Â  Â  # --- [FIM DO SCRIPT] ---


Â  Â  st.header("RelatÃ³rio de Auditoria Inteligente")
Â  Â  regex_anvisa = r"(aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprovaÃ§Ã£o\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
Â  Â  match_ref = re.search(regex_anvisa, texto_ref.lower())
Â  Â  match_belfar = re.search(regex_anvisa, texto_belfar.lower())
Â  Â  data_ref = match_ref.group(2).strip() if match_ref else "NÃ£o encontrada"
Â  Â  data_belfar = match_belfar.group(2).strip() if match_belfar else "NÃ£o encontrada"

Â  Â  secoes_faltantes, diferencas_conteudo, similaridades, diferencas_titulos = verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula)
Â  Â  erros_ortograficos = checar_ortografia_inteligente(texto_belfar, texto_ref, tipo_bula)
Â  Â  score_similaridade_conteudo = sum(similaridades) / len(similaridades) if similaridades else 100.0

Â  Â  st.subheader("Dashboard de Veredito")
Â  Â  col1, col2, col3, col4 = st.columns(4)
Â  Â  col1.metric("Conformidade de ConteÃºdo", f"{score_similaridade_conteudo:.0f}%")
Â  Â  col2.metric("Erros OrtogrÃ¡ficos", len(erros_ortograficos))
Â  Â  col3.metric("Data ANVISA (BELFAR)", data_belfar)
Â  Â  col4.metric("SeÃ§Ãµes Faltantes", f"{len(secoes_faltantes)}")

Â  Â  st.divider()
Â  Â  st.subheader("Detalhes dos Problemas Encontrados")
Â  Â  st.info(f"â„¹ï¸ **Datas de AprovaÃ§Ã£o ANVISA:**\n - ReferÃªncia: `{data_ref}`\n - BELFAR: `{data_belfar}`")

Â  Â  if secoes_faltantes:
Â  Â  Â  Â  st.error(f"ğŸš¨ **SeÃ§Ãµes faltantes na bula BELFAR ({len(secoes_faltantes)})**:\n" + "\n".join([f" - {s}" for s in secoes_faltantes]))
Â  Â  else:
Â  Â  Â  Â  st.success("âœ… Todas as seÃ§Ãµes obrigatÃ³rias estÃ£o presentes")
Â  Â  Â  Â Â 
Â  Â  if diferencas_conteudo:
Â  Â  Â  Â  st.warning(f"âš ï¸ **DiferenÃ§as de conteÃºdo encontradas ({len(diferencas_conteudo)} seÃ§Ãµes):**")
Â  Â  Â  Â  expander_caixa_style = (
Â  Â  Â  Â  Â  Â  "height: 350px; overflow-y: auto; border: 2px solid #d0d0d0; border-radius: 6px; "
Â  Â  Â  Â  Â  Â  "padding: 16px; background-color: #ffffff; font-size: 14px; line-height: 1.8; "
Â  Â  Â  Â  Â  Â  "font-family: 'Georgia', 'Times New Roman', serif; text-align: justify;"
Â  Â  Â  Â  )

Â  Â  Â  Â  for diff in diferencas_conteudo:
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- [INÃCIO DA MODIFICAÃ‡ÃƒO] ---
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  secao_canonico_raw = diff['secao'] # Pega o nome canÃ´nico (Ex: "QUAIS OS MALES...")
Â  Â  Â  Â  Â  Â  titulo_display = diff.get('titulo_encontrado') or secao_canonico_raw
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if not titulo_display:Â 
Â  Â  Â  Â  Â  Â  Â  Â  titulo_display = secao_canonico_raw

Â  Â  Â  Â  Â  Â  # --- [NOVA LÃ“GICA PARA FORÃ‡AR O NÃšMERO 9] ---
Â  Â  Â  Â  Â  Â  # Normaliza o nome canÃ´nico para uma verificaÃ§Ã£o segura
Â  Â  Â  Â  Â  Â  secao_canonico_norm = normalizar_texto(secao_canonico_raw)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Verifica se estamos na seÃ§Ã£o de "SUPERDOSE"
Â  Â  Â  Â  Â  Â  if "o que fazer se alguem usar uma quantidade maior" in secao_canonico_norm:
Â  Â  Â  Â  Â  Â  Â  Â  # Se o tÃ­tulo que pegamos (ex: "O QUE FAZER...") nÃ£o comeÃ§ar com "9", nÃ³s forÃ§amos.
Â  Â  Â  Â  Â  Â  Â  Â  if not normalizar_texto(titulo_display).startswith("9"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  titulo_display = f"9. {titulo_display}"
Â  Â  Â  Â  Â  Â  # --- [FIM DA NOVA LÃ“GICA] ---

Â  Â  Â  Â  Â  Â  with st.expander(f"ğŸ“„ {titulo_display} - âŒ CONTEÃšDO DIVERGENTE"):
Â  Â  Â  Â  Â  Â  # --- [FIM DA MODIFICAÃ‡ÃƒO] ---
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # --- [MODIFICADO] ---
Â  Â  Â  Â  Â  Â  Â  Â  secao_canonico = diff['secao']
Â  Â  Â  Â  Â  Â  Â  Â  anchor_id_ref = _create_anchor_id(secao_canonico, "ref")
Â  Â  Â  Â  Â  Â  Â  Â  anchor_id_bel = _create_anchor_id(secao_canonico, "bel")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  expander_html_ref = marcar_diferencas_palavra_por_palavra(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  diff['conteudo_ref'], diff['conteudo_belfar'], eh_referencia=True
Â  Â  Â  Â  Â  Â  Â  Â  ).replace('\n', '<br>')
Â  Â  Â  Â  Â  Â  Â  Â  expander_html_belfar = marcar_diferencas_palavra_por_palavra(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  diff['conteudo_ref'], diff['conteudo_belfar'], eh_referencia=False
Â  Â  Â  Â  Â  Â  Â  Â  ).replace('\n', '<br>')
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # Adiciona 'cursor: pointer;' e um 'title' para feedback
Â  Â  Â  Â  Â  Â  Â  Â  clickable_style = expander_caixa_style + " cursor: pointer; transition: background-color 0.3s ease;"
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # --- [A MUDANÃ‡A CRÃTICA] ---
Â  Â  Â  Â  Â  Â  Â  Â  # Criamos o HTML da caixa clicÃ¡vel com o 'onclick' chamando a funÃ§Ã£o GLOBAL.
Â  Â  Â  Â  Â  Â  Â  Â  # Usamos aspas simples (') para o HTML e duplas (") para os parÃ¢metros do JavaScript.
Â  Â  Â  Â  Â  Â  Â  Â  html_ref_box = f"<div onclick='window.handleBulaScroll(\"{anchor_id_ref}\", \"{anchor_id_bel}\")' style='{clickable_style}' title='Clique para ir Ã  seÃ§Ã£o' onmouseover='this.style.backgroundColor=\"#f0f8ff\"' onmouseout='this.style.backgroundColor=\"#ffffff\"'>{expander_html_ref}</div>"
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # --- [LINHA CORRIGIDA - SEM O ERRO DE SINTAXE] ---
Â  Â  Â  Â  Â  Â  Â  Â  html_bel_box = f"<div onclick='window.handleBulaScroll(\"{anchor_id_ref}\", \"{anchor_id_bel}\")' style='{clickable_style}' title='Clique para ir Ã  seÃ§Ã£o' onmouseover='this.style.backgroundColor=\"#f0f8ff\"' onmouseout='this.style.backgroundColor=\"#ffffff\"'>{expander_html_belfar}</div>"
Â  Â  Â  Â  Â  Â  Â  Â  # --- [FIM DA CORREÃ‡ÃƒO] ---

Â  Â  Â  Â  Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  with c1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("**ReferÃªncia:** (Clique na caixa para rolar)")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(html_ref_box, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  with c2:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("**BELFAR:** (Clique na caixa para rolar)")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(html_bel_box, unsafe_allow_html=True)
Â  Â  else:
Â  Â  Â  Â  st.success("âœ… ConteÃºdo das seÃ§Ãµes estÃ¡ idÃªntico")

Â  Â  if erros_ortograficos:
Â  Â  Â  Â  st.info(f"ğŸ“ **PossÃ­veis erros ortogrÃ¡ficos ({len(erros_ortograficos)} palavras):**\n" + ", ".join(erros_ortograficos))

Â  Â  if not any([secoes_faltantes, diferencas_conteudo, diferencas_titulos]) and len(erros_ortograficos) < 5:
Â  Â  Â  Â  st.success("ğŸ‰ **Bula aprovada!** Nenhum problema crÃ­tico encontrado.")

Â  Â  st.divider()
Â  Â  st.subheader("VisualizaÃ§Ã£o Lado a Lado com Destaques")
Â  Â  st.markdown(
Â  Â  Â  Â  "**Legenda:** <mark style='background-color: #ffff99; padding: 2px;'>Amarelo</mark> = DivergÃªncias | "
Â  Â  Â  Â  "<mark style='background-color: #FFDDC1; padding: 2px;'>Rosa</mark> = Erros ortogrÃ¡ficos | "
Â  Â  Â  Â  "<mark style='background-color: #cce5ff; padding: 2px;'>Azul</mark> = Data ANVISA",
Â  Â  Â  Â  unsafe_allow_html=True
Â  Â  )

Â  Â  html_ref_marcado = marcar_divergencias_html(texto_original=texto_ref, secoes_problema=diferencas_conteudo, erros_ortograficos=[], tipo_bula=tipo_bula, eh_referencia=True).replace('\n', '<br>')
Â  Â  html_belfar_marcado = marcar_divergencias_html(texto_original=texto_belfar, secoes_problema=diferencas_conteudo, erros_ortograficos=erros_ortograficos, tipo_bula=tipo_bula, eh_referencia=False).replace('\n', '<br>')

Â  Â  caixa_style = (
Â  Â  Â  Â  "height: 700px; overflow-y: auto; border: 2px solid #999; border-radius: 4px; "
Â  Â  Â  Â  "padding: 24px 32px; background-color: #ffffff; "
Â  Â  Â  Â  "font-family: 'Georgia', 'Times New Roman', serif; font-size: 14px; "
Â  Â  Â  Â  "line-height: 1.8; box-shadow: 0 2px 12px rgba(0,0,0,0.15); "
Â  Â  Â  Â  "text-align: justify; color: #000000;"
Â  Â  )
Â  Â  col1, col2 = st.columns(2, gap="medium")
Â  Â  with col1:
Â  Â  Â  Â  st.markdown(f"**ğŸ“„ {nome_ref}**")
Â  Â  Â  Â  # ID do container principal
Â  Â  Â  Â  st.markdown(f"<div id='container-ref-scroll' style='{caixa_style}'>{html_ref_marcado}</div>", unsafe_allow_html=True)
Â  Â  with col2:
Â  Â  Â  Â  st.markdown(f"**ğŸ“„ {nome_belfar}**")
Â  Â  Â  Â  # ID do container principal
Â  Â  Â  Â  st.markdown(f"<div id='container-bel-scroll' style='{caixa_style}'>{html_belfar_marcado}</div>", unsafe_allow_html=True)
        
# ----------------- INTERFACE -----------------
st.set_page_config(layout="wide", page_title="Auditoria de Bulas", page_icon="ğŸ”¬")
st.title("ğŸ”¬ InteligÃªncia Artificial para Auditoria de Bulas")
st.markdown("Sistema avanÃ§ado de comparaÃ§Ã£o literal e validaÃ§Ã£o de bulas farmacÃªuticas")
st.divider()

st.header("ğŸ“‹ ConfiguraÃ§Ã£o da Auditoria")
tipo_bula_selecionado = st.radio("Tipo de Bula:", ("Paciente", "Profissional"), horizontal=True)
col1, col2 = st.columns(2)
with col1:
    st.subheader("ğŸ“„ Arquivo da Anvisa")
    pdf_ref = st.file_uploader("Envie o arquivo da Anvisa (.docx ou .pdf)", type=["docx", "pdf"], key="ref")
with col2:
    st.subheader("ğŸ“„ Arquivo Marketing")
    pdf_belfar = st.file_uploader("Envie o PDF do Marketing", type="pdf", key="belfar")

if st.button("ğŸ” Iniciar Auditoria Completa", use_container_width=True, type="primary"):
    if pdf_ref and pdf_belfar:
        with st.spinner("ğŸ”„ Processando e analisando as bulas..."):
            
            # Determina dinamicamente o tipo de arquivo da Anvisa
            tipo_arquivo_ref = 'docx' if pdf_ref.name.lower().endswith('.docx') else 'pdf'
            texto_ref, erro_ref = extrair_texto(pdf_ref, tipo_arquivo_ref)
            
            texto_belfar, erro_belfar = extrair_texto(pdf_belfar, 'pdf')

            if not erro_ref:
                texto_ref = truncar_apos_anvisa(texto_ref)
            if not erro_belfar:
                texto_belfar = truncar_apos_anvisa(texto_belfar)

            if erro_ref or erro_belfar:
                st.error(f"Erro ao processar arquivos: {erro_ref or erro_bf}")
            else:
                gerar_relatorio_final(texto_ref, texto_belfar, "Arquivo da Anvisa", "Arquivo Marketing", tipo_bula_selecionado)
    else:
        st.warning("âš ï¸ Por favor, envie ambos os arquivos para iniciar a auditoria.")

st.divider()
st.caption("Sistema de Auditoria de Bulas v18.0 | Arquitetura de Mapeamento Final")
