# pages/2_Conferencia_MKT.py
#
# VersÃ£o v40 - CorreÃ§Ã£o Definitiva do Mapeamento
# - CORRIGIDA a funÃ§Ã£o 'corrigir_quebras_em_titulos' (v40).
#Â  Â Ela agora ignora linhas vazias e junta corretamente os
#Â  Â tÃ­tulos de MKT separados por '\n\n'.
# - Isso corrige o bug "4 nÃ£o ta puxando" e o "6 engolindo 7".
# - MantÃ©m o foco 100% em Paciente e o layout "achatado" do MKT.
# - MantÃ©m a correÃ§Ã£o do '\n' em 'normalizar_texto' (v32).
# - MantÃ©m a correÃ§Ã£o do 'is_titulo_secao' (v34).

import re
import difflib
import unicodedata
import io
import streamlit as st
import fitzÂ  # PyMuPDF
import docx
import spacy
from thefuzz import fuzz
from spellchecker import SpellChecker

# ----------------- MODELO NLP (carregado apenas uma vez) -----------------
@st.cache_resource
def carregar_modelo_spacy():
Â  Â  try:
Â  Â  Â  Â  return spacy.load("pt_core_news_lg")
Â  Â  except OSError:
Â  Â  Â  Â  st.warning("Modelo 'pt_core_news_lg' nÃ£o encontrado. Algumas funÃ§Ãµes ficam reduzidas.")
Â  Â  Â  Â  return None

nlp = carregar_modelo_spacy()

# ----------------- UTILITÃRIOS DE NORMALIZAÃ‡ÃƒO (v32) -----------------
def normalizar_texto(texto):
Â  Â  if not isinstance(texto, str):
Â  Â  Â  Â  return ""
Â  Â  texto = texto.replace('\n', ' ') # <-- [CORREÃ‡ÃƒO V32] Essencial para comparar tÃ­tulos MKT
Â  Â  texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')
Â  Â  texto = re.sub(r'[^\w\s]', '', texto)
Â  Â  texto = ' '.join(texto.split())
Â  Â  return texto.lower()

def normalizar_titulo_para_comparacao(texto):
Â  Â  texto_norm = normalizar_texto(texto or "")
Â  Â  texto_norm = re.sub(r'^\d+\s*[\.\-)]*\s*', '', texto_norm).strip()
Â  Â  return texto_norm

# ----------------- FUNÃ‡ÃƒO MISSING: truncar_apos_anvisa -----------------
def truncar_apos_anvisa(texto):
Â  Â  """
Â  Â  Corta o texto apÃ³s a menÃ§Ã£o de aprovaÃ§Ã£o na ANVISA (mantÃ©m atÃ© a data).
Â  Â  Retorna o texto truncado ou o texto original se nÃ£o encontrar a expressÃ£o.
Â  Â  """
Â  Â  if not isinstance(texto, str):
Â  Â  Â  Â  return texto
Â  Â  regex_anvisa = r"((?:aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova\w+\s+na\s+anvisa:)\s*([\d]{1,2}\s*/\s*[\d]{1,2}\s*/\s*[\d]{2,4}))"
Â  Â  match = re.search(regex_anvisa, texto, re.IGNORECASE)
Â  Â  if not match:
Â  Â  Â  Â  return texto
Â  Â  cut_off_position = match.end(1)
Â  Â  # mantem um possÃ­vel ponto logo apÃ³s
Â  Â  pos_match = re.search(r'^\s*\.', texto[cut_off_position:], re.IGNORECASE)
Â  Â  if pos_match:
Â  Â  Â  Â  cut_off_position += pos_match.end()
Â  Â  return texto[:cut_off_position]

def extrair_texto(arquivo, tipo_arquivo, is_marketing_pdf=False):
Â  Â  if arquivo is None:
Â  Â  Â  Â  return "", f"Arquivo {tipo_arquivo} nÃ£o enviado."
Â  Â  try:
Â  Â  Â  Â  arquivo.seek(0)
Â  Â  Â  Â  texto = ""
Â  Â  Â  Â  full_text_list = []

Â  Â  Â  Â  if tipo_arquivo == 'pdf':
Â  Â  Â  Â  Â  Â  with fitz.open(stream=arquivo.read(), filetype="pdf") as doc:
Â  Â  Â  Â  Â  Â  Â  Â  if is_marketing_pdf:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for page in doc:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rect = page.rect
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  clip_esquerda = fitz.Rect(0, 0, rect.width / 2, rect.height)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  clip_direita = fitz.Rect(rect.width / 2, 0, rect.width, rect.height)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  texto_esquerda = page.get_text("text", clip=clip_esquerda, sort=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  texto_direita = page.get_text("text", clip=clip_direita, sort=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_text_list.append(texto_esquerda)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_text_list.append(texto_direita)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for page in doc:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_text_list.append(page.get_text("text", sort=True))
Â  Â  Â  Â  Â  Â  texto = "\n\n".join(full_text_list)
Â  Â  Â  Â  elif tipo_arquivo == 'docx':
Â  Â  Â  Â  Â  Â  doc = docx.Document(arquivo)
Â  Â  Â  Â  Â  Â  texto = "\n".join([p.text for p in doc.paragraphs])

Â  Â  Â  Â  if texto:
Â  Â  Â  Â  Â  Â  # remove caracteres invisÃ­veis e normaliza quebras
Â  Â  Â  Â  Â  Â  caracteres_invisiveis = ['\u00AD', '\u200B', '\u200C', '\u200D', '\uFEFF']
Â  Â  Â  Â  Â  Â  for c in caracteres_invisiveis:
Â  Â  Â  Â  Â  Â  Â  Â  texto = texto.replace(c, '')
Â  Â  Â  Â  Â  Â  texto = texto.replace('\r\n', '\n').replace('\r', '\n')
Â  Â  Â  Â  Â  Â  texto = texto.replace('\u00A0', ' ')

Â  Â  Â  Â  Â  Â  # [v45] Remove "INFORMAÃ‡Ã•ES AO PACIENTE" - LINHA COMPLETA
Â  Â  Â  Â  Â  Â  linhas_temp = texto.split('\n')
Â  Â  Â  Â  Â  Â  linhas_filtradas_info = []
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  for linha in linhas_temp:
Â  Â  Â  Â  Â  Â  Â  Â  linha_upper = linha.upper().strip()
Â  Â  Â  Â  Â  Â  Â  Â  # Checa se a linha contÃ©m apenas essas expressÃµes
Â  Â  Â  Â  Â  Â  Â  Â  if re.match(r'^\s*INFORMA[Ã‡C][OÃ•]ES\s+(AO|PARA(\s+O)?)\s+PACIENTE\s*[:\-\.]?\s*$', linha_upper):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continueÂ  # Pula essa linha
Â  Â  Â  Â  Â  Â  Â  Â  if re.match(r'^\s*BULA\s+PARA\s+(O\s+)?PACIENTE\s*[:\-\.]?\s*$', linha_upper):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continueÂ  # Pula essa linha
Â  Â  Â  Â  Â  Â  Â  Â  linhas_filtradas_info.append(linha)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  texto = '\n'.join(linhas_filtradas_info)

Â  Â  Â  Â  Â  Â  # padrÃµes de ruÃ­do (mantidos da v26.58)
Â  Â  Â  Â  Â  Â  padrao_ruido_linha_regex = (
Â  Â  Â  Â  Â  Â  Â  Â  r'bula do paciente|pÃ¡gina \d+\s*de\s*\d+'
Â  Â  Â  Â  Â  Â  Â  Â  r'|(Tipologie|Tipologia) da bula:.*|(Merida|Medida) da (bula|trÃºa):?.*'
Â  Â  Â  Â  Â  Â  Â  Â  r'|(ImpressÃ£e|ImpressÃ£o):? Frente/Verso|Papel[\.:]? Ap \d+gr'
Â  Â  Â  Â  Â  Â  Â  Â  r'|Cor:? Preta|contato:?|artes@belfar\.com\.br'
Â  Â  Â  Â  Â  Â  Â  Â  r'|CLORIDRATO DE NAFAZOLINA: Times New Roman'
Â  Â  Â  Â  Â  Â  Â  Â  r'|^\s*FRENTE\s*$|^\s*VERSO\s*$'
Â  Â  Â  Â  Â  Â  Â  Â  r'|^\s*\d+\s*mm\s*$'
Â  Â  Â  Â  Â  Â  	 r'|^\s*BELFAR\s*$|^\s*REZA\s*$|^\s*GEM\s*$|^\s*ALTEFAR\s*$|^\s*RECICLAVEL\s*$|^\s*BUL\d+\s*$'
Â  Â  Â  Â  Â  Â  Â  Â  r'|BUL_CLORIDRATO_DE_[A-Z].*'
Â  Â  Â  Â  Â  Â  Â  Â  r'|\d{2}\s\d{4}\s\d{4}.*'
Â  Â  Â  Â  Â  Â  Â  Â  r'|cloridrato de ambroxo\s*$'
Â  Â  Â  Â  Â  Â  	 r'|Normal e Negrito\. Co\s*$'
Â  Â  Â  Â  Â  Â  	 r'|cloridrato de ambroxol Belfar Ltda\. Xarope \d+ mg/mL'
Â  	 Â  Â  Â  Â  Â  r'|^\s*\d+\s+CLORIDRATO\s+DE\s+NAFAZOLINA.*'
Â  Â  Â  Â  Â  Â  Â  Â  r'|^\s*INFORMA[Ã‡C][OÃ•]ES\s+(AO|PARA)\s+(O\s+)?PACIENTE.*'
Â  Â  Â  Â  Â  Â  Â  Â  r'|^\s*BULA\s+PARA\s+(O\s+)?PACIENTE.*'
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  padrao_ruido_linha = re.compile(padrao_ruido_linha_regex, re.IGNORECASE)

Â  Â  Â  Â  Â  Â  padrao_ruido_inline_regex = (
Â  Â  Â  Â  Â  Â  Â  Â  r'BUL_CLORIDRATO_DE_NA[\s\S]{0,20}?\d+'
Â  Â  Â  Â  Â  Â  	 r'|New[\s\S]{0,10}?Roman[\s\S]{0,50}?(?:mm|\d+)'
Â  Â  Â  Â  Â  Â  	 r'|AFAZOLINA_BUL\d+V\d+.*?'
Â  Â  Â  Â  Â  Â  	 r'|BUL_CLORIDRATO_DE_NAFAZOLINA_BUL\d+V\d+'
Â  Â  Â  Â  Â  Â  	 r'|AMBROXOL_BUL\d+V\d+'
Â  Â  Â  Â  Â  Â  	 r'|es New Roman.*?'
Â  Â  Â  Â  Â  Â  	 r'|rpo \d+.*?'
Â  Â  Â  Â  Â  Â  	 r'|olL: Times New Roman.*?'
Â  Â  Â  Â  Â  Â  	 r'|(?<=\s)\d{3}(?=\s[a-zA-Z])'
Â  Â  Â  Â  Â  Â  	 r'|(?<=\s)mm(?=\s)'
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  padrao_ruido_inline = re.compile(padrao_ruido_inline_regex, re.IGNORECASE)

Â  Â  Â  Â  Â  Â  texto = re.sub(r'(BUL_CLORIDRATO_DE_NAFAZOLINA)\s*(\d{2,4})', r'__KEEPBUL_\1_\2__', texto, flags=re.IGNORECASE)
Â  Â  Â  Â  Â  Â  texto = padrao_ruido_inline.sub(' ', texto)
Â  Â  Â  Â  Â  Â  texto = re.sub(
Â  Â  Â  Â  	 Â  Â  r'__KEEPBUL_(BUL_CLORIDRATO_DE_NAFAZOLINA)_(\d{2,4})__',
Â  Â  Â  Â  	 Â  Â  lambda m: f"{m.group(1).replace('_', ' ')} {m.group(2)}",
Â  Â  Â  Â  	 Â  Â  texto,
Â  Â  Â  Â  	 Â  Â  flags=re.IGNORECASE
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # remover numeracao solta no MKT
Â  Â  Â  Â  Â  Â  if is_marketing_pdf:
Â  Â  Â  Â  Â  Â  Â  Â  texto = re.sub(r'(?m)^\s*\d{1,2}\.\s*', '', texto)
Â  Â  Â  Â  Â  Â  Â  Â  texto = re.sub(r'(?<=\s)\d{1,2}\.(?=\s)', ' ', texto)

Â  Â  Â  Â  Â  Â  linhas = texto.split('\n')
Â  Â  Â  Â  Â  Â  linhas_filtradas = []
Â  Â  Â  Â  Â  Â  for linha in linhas:
Â  Â  Â  Â  Â  Â  Â  Â  linha_strip = linha.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if padrao_ruido_linha.search(linha_strip):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  	 linha_limpa = re.sub(r'\s{2,}', ' ', linha_strip).strip()
Â  Â  Â  Â  Â  Â  	 if is_marketing_pdf and not re.search(r'[A-Za-zÃÃ‰ÃÃ“ÃšÃ‚ÃŠÃ”ÃƒÃ•Ã‡Ã¡Ã©Ã­Ã³ÃºÃ¢ÃªÃ´Ã£ÃµÃ§]', linha_limpa):
Â  Â  Â  Â  Â  Â  	 	 continue
Â  Â  Â  Â  Â  Â  	 if linha_limpa:
Â  Â  Â  Â  Â  Â  	 	 linhas_filtradas.append(linha_limpa)
Â  Â  Â  Â  Â  Â  	 elif not linhas_filtradas or linhas_filtradas[-1] != "":
Â  Â  Â  Â  Â  Â  	 	 linhas_filtradas.append("")
Â  Â  Â  Â  Â  Â  texto = "\n".join(linhas_filtradas)
Â  Â  Â  Â  Â  Â  texto = re.sub(r'\n{3,}', '\n\n', texto)
Â  Â  Â  Â  Â  Â  texto = re.sub(r'[ \t]+', ' ', texto)
Â  Â  Â  Â  Â  Â  texto = texto.strip()
Â  Â  Â  Â  Â  Â  return texto, None

Â  Â  except Exception as e:
Â  Â  	 return "", f"Erro ao ler o arquivo {tipo_arquivo}: {e}"

# ----------------- DETECÃ‡ÃƒO DE TÃTULOS (v34 - Corrigida) -----------------
def is_titulo_secao(linha):
Â  Â  if not linha:
Â  Â  Â  Â  return False
Â  Â  ln = linha.strip()
Â  Â  if len(ln) < 4:
Â  Â  	 return False
Â  Â  if len(ln.split('\n')) > 3: # Se tiver mais de 3 linhas juntas, nÃ£o Ã© um tÃ­tulo
Â  Â  	 return False
Â  Â  	 
Â  Â  ln_primeira_linha = ln.split('\n')[0] # Checa sÃ³ a primeira linha
Â  Â  
Â  Â  if len(ln_primeira_linha.split()) > 20: # Um tÃ­tulo nÃ£o deve ser tÃ£o longo
Â  Â  	 return False

Â  Â  # Regra 1: ComeÃ§a com nÃºmero (Ex: "1. ... INDICADO?")
Â  Â  if re.match(r'^\d+\s*[\.\-)]*\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‚ÃŠÃ”ÃƒÃ•Ã‡]', ln_primeira_linha):
Â  Â  	 return True
Â  Â  
Â  Â  # Regra 2: Ã‰ TUDO MAIÃšSCULO (Ex: "APRESENTAÃ‡Ã•ES")
Â  Â  if ln_primeira_linha.isupper():
Â  Â  	 # [CORREÃ‡ÃƒO V34] - A exceÃ§Ã£o agora Ã© se terminar com PONTO.
Â  Â  	 # Isso filtra "TODO MEDICAMENTO..." mas permite tÃ­tulos
Â  Â  	 # que contenham a palavra "medicamento".
Â  Â  	 if ln_primeira_linha.endswith('.'):
Â  Â  	 	 	return False
Â  Â  	 return True # Ã‰ maiÃºsculo e nÃ£o termina com ponto.
Â  Â  	 
Â  Â  return False

# ----------------- CORREÃ‡ÃƒO DE QUEBRAS EM TÃTULOS (v41 - Corrigida) -----------------
# Esta funÃ§Ã£o Ã© ESSENCIAL para juntar os tÃ­tulos do MKT
def corrigir_quebras_em_titulos(texto):
Â  Â  if not texto:
Â  Â  	 return texto
Â  Â  linhas = texto.split("\n")
Â  Â  linhas_corrigidas = []
Â  Â  buffer = ""
Â  Â  linhas_vazias_consecutivas = 0
Â  Â  
Â  Â  for linha in linhas:
Â  Â  	 linha_strip = linha.strip()
Â  Â  	 
Â  Â  	 if not linha_strip: # Ã‰ uma linha vazia
Â  Â  	 	 linhas_vazias_consecutivas += 1
Â  Â  	 	 # Se temos mais de 1 linha vazia, forÃ§a o flush do buffer
Â  Â  	 	 if linhas_vazias_consecutivas > 1 and buffer:
Â  Â  	 	 	 linhas_corrigidas.append(buffer)
Â  Â  	 	 	 buffer = ""
Â  Â  	 	 # Se nÃ£o hÃ¡ buffer, adiciona a linha vazia
Â  Â  	 	 if not buffer:
Â  Â  	 	 	 linhas_corrigidas.append("")
Â  Â  	 	 continue
Â  Â  	 
Â  Â  	 # Reset do contador de linhas vazias
Â  Â  	 linhas_vazias_consecutivas = 0
Â  Â  	 
Â  Â  	 is_potential_title = is_titulo_secao(linha_strip)
Â  Â  	 
Â  Â  	 if is_potential_title and len(linha_strip.split()) < 20: # Se for um tÃ­tulo potencial
Â  Â  	 	 if buffer:
Â  Â  	 	 	 # Junta com a linha anterior usando espaÃ§o ao invÃ©s de \n
Â  Â  	 	 	 buffer += " " + linha_strip
Â  Â  	 	 else:
Â  Â  	 	 	 buffer = linha_strip # ComeÃ§a um novo tÃ­tulo
Â  Â  	 else: # Ã‰ uma linha de conteÃºdo
Â  Â  	 	 if buffer:
Â  Â  	 	 	 linhas_corrigidas.append(buffer) # Salva o tÃ­tulo anterior
Â  Â  	 	 	 buffer = ""
Â  Â  	 	 linhas_corrigidas.append(linha_strip) # Salva a linha de conteÃºdo
Â  Â  	 	 
Â  Â  if buffer: # Salva o Ãºltimo tÃ­tulo
Â  Â  	 linhas_corrigidas.append(buffer)
Â  Â  
Â  Â  # Limpa quebras de linha duplas mas mantÃ©m uma quebra entre seÃ§Ãµes
Â  Â  resultado = "\n".join(linhas_corrigidas)
Â  Â  return re.sub(r'\n{3,}', '\n\n', resultado)

# ----------------- CONFIGURAÃ‡ÃƒO DE SEÃ‡Ã•ES (v30 - Paciente Apenas) -----------------
def obter_secoes_por_tipo(tipo_bula):
Â  Â  secoes = {
Â  Â  	 "Paciente": [
Â  Â  	 	 "APRESENTAÃ‡Ã•ES",
Â  Â  	 	 "COMPOSIÃ‡ÃƒO",
Â  Â  	 	 "1.PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO?",
Â  Â  	 	 "2.COMO ESTE MEDICAMENTO FUNCIONA?",
Â  Â  	 	 "3.QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?",
Â  Â  	 	 "4.O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
Â  Â  	 	 "5.ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
Â  Â  	 	 "6.COMO DEVO USAR ESTE MEDICAMENTO?",
Â  Â  	 	 "7.O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
Â  Â  	 	 "8.QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?",
Â  Â  	 	 "9.O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
Â  Â  	 	 "DIZERES LEGAIS"
Â  Â  	 ]
Â  Â  	 # "Profissional" key removida
Â  Â  }
Â  Â  # Retorna as seÃ§Ãµes do Paciente se tipo_bula="Paciente", ou lista vazia
Â  Â  return secoes.get(tipo_bula, [])

def obter_aliases_secao():
Â  Â  # v30 - Apenas Aliases de Paciente
Â  Â  return {
Â  Â  	 "PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO?": "1.PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO?",
Â  Â  	 "COMO ESTE MEDICAMENTO FUNCIONA?": "2.COMO ESTE MEDICAMENTO FUNCIONA?",
Â  Â  	 "QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?": "3.QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?",
Â  Â  	 "O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?": "4.O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?",
Â  Â  	 "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICamento?": "5.ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?",
Â  Â  	 "COMO DEVO USAR ESTE MEDICAMENTO?": "6.COMO DEVO USAR ESTE MEDICAMENTO?",
Â  Â  	 "O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?": "7.O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?",
Â  Â  	 "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?": "8.QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?",
Â  Â  	 "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?": "9.O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?",
Â  Â  }

def obter_secoes_ignorar_comparacao():
Â  Â  return ["APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "DIZERES LEGAIS"]

def obter_secoes_ignorar_ortografia():
Â  Â  return ["APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "DIZERES LEGAIS"]

# ----------------- FUNÃ‡ÃƒO 'CORE' (v31 - Simplificada) -----------------
# LÃ³gica simples que depende do 'corrigir_quebras_em_titulos'
def mapear_secoes(texto_completo, secoes_esperadas):
Â  Â  mapa = []
Â  Â  texto_normalizado = re.sub(r'\n{2,}', '\n', texto_completo or "")
Â  Â  # As linhas agora vÃªm prÃ©-juntadas por 'corrigir_quebras_em_titulos'
Â  Â  linhas = texto_normalizado.split('\n')Â 
Â  Â  aliases = obter_aliases_secao()

Â  Â  # 1. Criar lookup de todos os tÃ­tulos possÃ­veis
Â  Â  titulos_possiveis = {}
Â  Â  for secao in secoes_esperadas:
Â  Â  	 titulos_possiveis[secao] = secao
Â  Â  for alias, canon in aliases.items():
Â  Â  	 if canon in secoes_esperadas:
Â  Â  	 	 titulos_possiveis[alias] = canon

Â  Â  titulos_norm_lookup = {normalizar_titulo_para_comparacao(t): c for t, c in titulos_possiveis.items()}
Â  Â  limiar_score = 85

Â  Â  for idx, linha in enumerate(linhas):
Â  Â  	 linha_strip = linha.strip()
Â  Â  	 
Â  Â  	 # 2. Checa se a linha (que pode ser multi-linha, ex: "TITULO\nPARTE 2") Ã© um tÃ­tulo
Â  Â  	 if not linha_strip or not is_titulo_secao(linha_strip):
Â  Â  	 	 continue
Â  Â  	 
Â  Â  	 # [CorreÃ§Ã£o v32] A normalizaÃ§Ã£o agora trata o '\n'
Â  Â  	 norm_linha = normalizar_titulo_para_comparacao(linha_strip)
Â  Â  	 
Â  Â  	 best_score = 0
Â  Â  	 best_canonico = None
Â  Â  	 for titulo_norm, canonico in titulos_norm_lookup.items():
Â  Â  	 	 score = fuzz.token_set_ratio(titulo_norm, norm_linha)
Â  Â  	 	 if score > best_score:
Â  Â  	 	 	 best_score = score
Â  Â  	 	 	 best_canonico = canonico
Â  Â  	 
Â  Â  	 if best_score < limiar_score:
Â  Â  	 	 	for titulo_norm, canonico in titulos_norm_lookup.items():
Â  Â  	 	 	 	 if titulo_norm and titulo_norm in norm_linha:
Â  Â  	 	 	 	 	 	best_score = 90
Â  Â  	 	 	 	 	 	best_canonico = canonico
Â  Â  	 	 	 	 	 	break

Â  Â  	 # 3. Avalia o match
Â  Â  	 if best_score >= limiar_score and best_canonico:
Â  Â  	 	 num_lines = len(linha_strip.split('\n')) # Conta as linhas que foram "coladas"
Â  Â  	 	 
Â  Â  	 	 if not mapa or mapa[-1]['canonico'] != best_canonico:
Â  Â  	 	 	 mapa.append({
Â  Â  	 	 	 	 'canonico': best_canonico,
Â  Â  	 	 	 	 'titulo_encontrado': linha_strip,
Â  Â  	 	 	 	 'linha_inicio': idx,
Â  Â  	 	 	 	 'score': best_score,
Â  Â  	 	 	 	 'num_linhas_titulo': num_lines
Â  Â  	 	 	 })
Â  Â  
Â  Â  mapa.sort(key=lambda x: x['linha_inicio'])
Â  Â  return mapa


# ----------------- OBTER DADOS DE SEÃ‡ÃƒO (v35 - LÃ³gica v31 Restaurada) -----------------
def obter_dados_secao(secao_canonico, mapa_secoes, linhas_texto_split):
Â  Â  idx_secao_atual = -1
Â  Â  for i, secao_mapa in enumerate(mapa_secoes):
Â  Â  	 if secao_mapa['canonico'] == secao_canonico:
Â  Â  	 	 idx_secao_atual = i
Â  Â  	 	 break
Â  Â  if idx_secao_atual == -1:
Â  Â  	 return False, None, ""
Â  Â  secao_atual_info = mapa_secoes[idx_secao_atual]
Â  Â  
Â  Â  # O 'titulo_encontrado' Ã© a linha "colada" (ex: "TITULO\nPARTE 2")
Â  Â  titulo_encontrado = secao_atual_info['titulo_encontrado']
Â  Â  
Â  Â  # 'linha_inicio' Ã© o Ã­ndice (em linhas_texto_split) onde esse tÃ­tulo colado estÃ¡
Â  Â  linha_inicio = secao_atual_info['linha_inicio']
Â  Â  
Â  Â  # O conteÃºdo comeÃ§a na linha SEGUINTE do 'linhas_texto_split'
Â  Â  linha_inicio_conteudo = linha_inicio + 1Â 
Â  Â  
Â  Â  linha_fim = len(linhas_texto_split)
Â  Â  if (idx_secao_atual + 1) < len(mapa_secoes):
Â  Â  	 # O fim Ã© o inÃ­cio da prÃ³xima seÃ§Ã£o mapeada
Â  Â  	 linha_fim = mapa_secoes[idx_secao_atual + 1]['linha_inicio']
Â  Â  
Â  Â  # Pega o conteÃºdo, ignorando o prÃ³prio tÃ­tulo
Â  Â  # (range(start, end) exclui 'end', entÃ£o ele para exatamente antes da prÃ³xima seÃ§Ã£o)
Â  Â  conteudo = [linhas_texto_split[idx] for idx in range(linha_inicio_conteudo, linha_fim)]
Â  Â  
Â  Â  conteudo_final_sem_titulo = "\n".join(conteudo).strip()
Â  Â  
Â  Â  if conteudo_final_sem_titulo:
Â  Â  	 conteudo_final = f"{titulo_encontrado}\n\n{conteudo_final_sem_titulo}"
Â  Â  else:
Â  Â  	 conteudo_final = f"{titulo_encontrado}"
Â  Â  	 
Â  Â  return True, titulo_encontrado, conteudo_final

# ----------------- EXTRAI QUALIFIERS INICIAIS (RESTRITO) -----------------
def _extrair_linhas_qualificadoras_iniciais(texto, max_lines=4):
Â  Â  if not texto:
Â  Â  	 return [], texto
Â  Â  linhas = texto.split('\n')
Â  Â  qualifiers = []
Â  Â  i = 0
Â  Â  while i < min(len(linhas), max_lines):
Â  Â  	 ln = linhas[i].strip()
Â  Â  	 if not ln:
Â  Â  	 	 i += 1
Â  Â  	 	 continue
Â  Â  	 ln_up = ln.upper()
Â  Â  	 if 'USO NASAL' in ln_up and 'ADULTO' in ln_up:
Â  Â  	 	 qualifiers.append(ln)
Â  Â  	 	 i += 1
Â  Â  	 	 continue
Â  Â  	 if 'USO NASAL' in ln_up and i+1 < len(linhas) and 'ADULTO' in linhas[i+1].upper():
Â  Â  	 	 qualifiers.append(ln)
Â  Â  	 	 qualifiers.append(linhas[i+1].strip())
Â  Â  	 	 i += 2
Â  Â  	 	 continue
Â  Â  	 break
Â  Â  restante = '\n'.join(linhas[i:]).strip()
Â  Â  return qualifiers, restante

# ----------------- REALOCAR QUALIFIERS (RESTRITO) -----------------
def realocar_qualifiers_inplace(conteudos, src_section='COMPOSIÃ‡ÃƒO', dst_section='APRESENTAÃ‡Ã•ES'):
Â  Â  src = conteudos.get(src_section)
Â  Â  dst = conteudos.get(dst_section)
Â  Â  if not src or not dst:
Â  Â  	 return
Â  Â  if not src.get('conteudo_bel', "").strip():
Â  Â  	 return
Â  Â  qualifiers_bel, restante_bel = _extrair_linhas_qualificadoras_iniciais(src['conteudo_bel'], max_lines=4)
Â  Â  if not qualifiers_bel:
Â  Â  	 return
Â  Â  if not dst.get('encontrou_bel', False):
Â  Â  	 return
Â  Â  qual_text = ' '.join(q for q in qualifiers_bel if q.strip())
Â  Â  if not qual_text:
Â  Â  	 return
Â  Â  if re.search(r'\b(?:cont[eÃ©]m|mg\b|ml\b|equivalente|q\.s\.p|qsp)\b', qual_text, flags=re.IGNORECASE):
Â  Â  	 return
Â  Â  if len(restante_bel.strip()) < 30:
Â  Â  	 return
Â  Â  dst_norm = normalizar_texto(dst.get('conteudo_bel', ""))
Â  Â  if normalizar_texto(qual_text) in dst_norm:
Â  Â  	 src['conteudo_bel'] = restante_bel
Â  Â  	 return
Â  Â  lines_dst = dst.get('conteudo_bel', "").split('\n')
Â  Â  title_dst = lines_dst[0] if lines_dst and lines_dst[0].strip() else dst_section
Â  Â  rest_dst = '\n'.join(lines_dst[1:]).strip() if len(lines_dst) > 1 else ""
Â  Â  combined = f"{title_dst}\n\n{qual_text}\n\n{rest_dst}".strip()
Â  Â  dst['conteudo_bel'] = combined
Â  Â  src['conteudo_bel'] = restante_bel

# ----------------- VERIFICAÃ‡ÃƒO E COMPARAÃ‡ÃƒO (MODIFICADO) -----------------
def verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula):
Â  Â  secoes_esperadas = obter_secoes_por_tipo(tipo_bula)
Â  Â  secoes_faltantes = []
Â  Â  diferencas_titulos = [] # <-- MODIFICADO: Esta lista serÃ¡ populada primeiro
Â  Â  relatorio_comparacao_completo = []
Â  Â  similaridade_geral = []
Â  Â  secoes_ignorar_upper = [s.upper() for s in obter_secoes_ignorar_comparacao()]

Â  Â  # Importante: As linhas here jÃ¡ estÃ£o "coladas" pelo 'corrigir_quebras_em_titulos'
Â  Â  linhas_ref = re.sub(r'\n{2,}', '\n', texto_ref or "").split('\n')
Â  Â  linhas_belfar = re.sub(r'\n{2,}', '\n', texto_belfar or "").split('\n')

Â  Â  mapa_ref = mapear_secoes(texto_ref or "", secoes_esperadas)
Â  Â  mapa_belfar = mapear_secoes(texto_belfar or "", secoes_esperadas)

Â  Â  conteudos = {}
Â  Â  for sec in secoes_esperadas:
Â  Â  	 encontrou_ref, titulo_ref, conteudo_ref = obter_dados_secao(sec, mapa_ref, linhas_ref)
Â  Â  	 encontrou_bel, titulo_bel, conteudo_bel = obter_dados_secao(sec, mapa_belfar, linhas_belfar)
Â  Â  	 conteudos[sec] = {
Â  Â  	 	 'encontrou_ref': encontrou_ref,
Â  Â  	 	 'titulo_ref': titulo_ref or "",
Â  Â  	 	 'conteudo_ref': conteudo_ref or "",
Â  Â  	 	 'encontrou_bel': encontrou_bel,
Â  Â  	 	 'titulo_bel': titulo_bel or "",
Â  Â  	 	 'conteudo_bel': conteudo_bel or ""
Â  Â  	 }
Â  Â  	 if not encontrou_bel:
Â  Â  	 	 secoes_faltantes.append(sec)

Â  Â  realocar_qualifiers_inplace(conteudos, src_section='COMPOSIÃ‡ÃƒO', dst_section='APRESENTAÃ‡Ã•ES')

Â  Â  # --- [INÃCIO DA MODIFICAÃ‡ÃƒO] ---
Â  Â  # 1. Encontrar tÃ­tulos diferentes ANTES de construir o relatÃ³rio
Â  Â  titulos_ref_encontrados = {m['canonico']: m['titulo_encontrado'] for m in mapa_ref}
Â  Â  titulos_belfar_encontrados = {m['canonico']: m['titulo_encontrado'] for m in mapa_belfar}
Â  Â  secoes_com_titulos_diferentes = set()
Â  Â  
Â  Â  # 'diferencas_titulos' (a lista) Ã© populada here agora
Â  Â  for secao_canonico, titulo_ref in titulos_ref_encontrados.items():
Â  Â  	 if secao_canonico in titulos_belfar_encontrados:
Â  Â  	 	 titulo_bel = titulos_belfar_encontrados[secao_canonico]
Â  Â  	 	 if normalizar_titulo_para_comparacao(titulo_ref) != normalizar_titulo_para_comparacao(titulo_bel):
Â  Â  	 	 	 secoes_com_titulos_diferentes.add(secao_canonico) # Adiciona ao set para lookup rÃ¡pido
Â  Â  	 	 	 diferencas_titulos.append({'secao_esperada': secao_canonico, 'titulo_encontrado': titulo_bel})
Â  Â  # --- [FIM DA MODIFICAÃ‡ÃƒO] ---


Â  Â  for sec in secoes_esperadas:
Â  Â  	 item = conteudos[sec]
Â  Â  	 encontrou_ref = item['encontrou_ref']
Â  Â  	 encontrou_bel = item['encontrou_bel']
Â  Â  	 conteudo_ref = item['conteudo_ref']
Â  Â  	 conteudo_bel = item['conteudo_bel']
Â  Â  	 titulo_ref = item.get('titulo_ref') or ""
Â  Â  	 titulo_bel = item.get('titulo_bel') or ""

Â  Â  	 # [CORREÃ‡ÃƒO v28] - Bloco desativado
Â  Â  	 # ... (cÃ³digo omitido) ...

Â  Â  	 if not encontrou_bel:
Â  Â  	 	 relatorio_comparacao_completo.append({'secao': sec, 'status': 'faltante', 'conteudo_ref': conteudo_ref, 'conteudo_belfar': ""})
Â  Â  	 	 continue

Â  Â  	 if encontrou_ref and encontrou_bel:
Â  Â  	 	 if sec.upper() in secoes_ignorar_upper:
Â  Â  	 	 	 relatorio_comparacao_completo.append({'secao': sec, 'status': 'identica', 'conteudo_ref': conteudo_ref, 'conteudo_belfar': conteudo_bel})
Â  Â  	 	 	 similaridade_geral.append(100)
Â  Â  	 	 else:
Â  Â  	 	 	 # --- [INÃCIO DA MODIFICAÃ‡ÃƒO] ---
Â  Â  	 	 	 # 2. Verificar se o TÃTULO Ã© diferente (usando o set) OU se o CONTEÃšDO Ã© diferente
Â  Â  	 	 	 titulo_difere = sec in secoes_com_titulos_diferentes
Â  Â  	 	 	 conteudo_difere = normalizar_texto(conteudo_ref) != normalizar_texto(conteudo_bel)

Â  Â  	 	 	 if titulo_difere or conteudo_difere:
Â  Â  	 	 	 	 # Se o tÃ­tulo OU o conteÃºdo diferir, marca como 'diferente'
Â  Â  	 	 	 	 relatorio_comparacao_completo.append({'secao': sec, 'status': 'diferente', 'conteudo_ref': conteudo_ref, 'conteudo_belfar': conteudo_bel})
Â  Â  	 	 	 	 similaridade_geral.append(0) # Se o tÃ­tulo ou conteÃºdo for diferente, conta como 0%
Â  Â  	 	 	 else:
Â  Â  	 	 	 	 # Somente se AMBOS forem idÃªnticos
Â  Â  	 	 	 	 relatorio_comparacao_completo.append({'secao': sec, 'status': 'identica', 'conteudo_ref': conteudo_ref, 'conteudo_belfar': conteudo_bel})
Â  Â  	 	 	 	 similaridade_geral.append(100)
Â  Â  	 	 	 # --- [FIM DA MODIFICAÃ‡ÃƒO] ---

Â  Â  # --- [INÃCIO DA MODIFICAÃ‡ÃƒO] ---
Â  Â  # O loop que populava 'diferencas_titulos' foi movido para cima.
Â  Â  # A funÃ§Ã£o agora retorna a lista 'diferencas_titulos' que foi populada anteriormente.
Â  Â  return secoes_faltantes, relatorio_comparacao_completo, similaridade_geral, diferencas_titulos
Â  Â  # --- [FIM DA MODIFICAÃ‡ÃƒO] ---

# ----------------- ORTOGRAFIA, MARCAÃ‡ÃƒO, DIFERENÃ‡AS (mantidos) -----------------
def checar_ortografia_inteligente(texto_para_checar, texto_referencia, tipo_bula):
Â  Â  if not nlp or not texto_para_checar:
Â  Â  	 return []
Â  Â  try:
Â  Â  	 secoes_ignorar = obter_secoes_ignorar_ortografia()
Â  Â  	 secoes_todas = obter_secoes_por_tipo(tipo_bula)
Â  Â  	 texto_filtrado_para_checar = []
Â  Â  	 mapa_secoes = mapear_secoes(texto_para_checar, secoes_todas)
Â  Â  	 linhas_texto = re.sub(r'\n{2,}', '\n', texto_para_checar).split('\n')
Â  Â  	 for secao_nome in secoes_todas:
Â  Â  	 	 if secao_nome.upper() in [s.upper() for s in secoes_ignorar]:
Â  Â  	 	 	 continue
Â  Â  	 	 encontrou, _, conteudo = obter_dados_secao(secao_nome, mapa_secoes, linhas_texto)
Â  Â  	 	 if encontrou and conteudo:
Â  Â  	 	 	 texto_filtrado_para_checar.append(conteudo)
Â  Â  	 texto_final_para_checar = "\n".join(texto_filtrado_para_checar)
Â  Â  	 if not texto_final_para_checar:
Â  Â  	 	 return []
Â  Â  	 spell = SpellChecker(language='pt')
Â  Â  	 palavras_a_ignorar = {"alair", "belfar", "peticionamento", "urotrobel", "contato", "iobeguane"}
Â  Â  	 vocab_referencia = set(re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ¢ÃªÃ´Ã£ÃµÃ§Ã¼]+\b', texto_referencia.lower()))
Â  Â  	 doc = nlp(texto_para_checar)
Â  Â  	 entidades = {ent.text.lower() for ent in doc.ents}
Â  Â  	 spell.word_frequency.load_words(vocab_referencia.union(entidades).union(palavras_a_ignorar))
Â  Â  	 palavras = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ¢ÃªÃ´Ã£ÃµÃ§Ã¼]+\b', texto_final_para_checar.lower())
Â  Â  	 erros = spell.unknown(palavras)
Â  Â  	 return list(sorted(set([e for e in erros if len(e) > 3])))[:20]
Â  Â  except Exception:
Â  Â  	 return []

def marcar_diferencas_palavra_por_palavra(texto_ref, texto_belfar, eh_referencia):
Â  Â  texto_ref = texto_ref or ""
Â  Â  texto_belfar = texto_belfar or ""
Â  Â  def tokenizar(txt):
Â  Â  	 return re.findall(r'\n|[A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿0-9_]+|[^\w\s]', txt, re.UNICODE)
Â  Â  def norm(tok):
Â  Â  	 if re.match(r'[A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿0-9_]+$', tok):
Â  Â  	 	 return normalizar_texto(tok)
Â  Â  	 return tok
Â  Â  ref_tokens = tokenizar(texto_ref)
Â  Â  bel_tokens = tokenizar(texto_belfar)
Â  Â  ref_norm = [norm(t) for t in ref_tokens]
Â  Â  bel_norm = [norm(t) for t in bel_tokens]
Â  Â  matcher = difflib.SequenceMatcher(None, ref_norm, bel_norm, autojunk=False)
Â  Â  indices = set()
Â  Â  for tag, i1, i2, j1, j2 in matcher.get_opcodes():
Â  Â  	 if tag != 'equal':
Â  Â  	 	 indices.update(range(i1, i2) if eh_referencia else range(j1, j2))
Â  Â  tokens = ref_tokens if eh_referencia else bel_tokens
Â  Â  marcado = []
Â  Â  for idx, tok in enumerate(tokens):
Â  Â  	 if idx in indices and tok.strip() != '':
Â  Â  	 	 marcado.append(f"<mark style='background-color: #ffff99; padding: 2px;'>{tok}</mark>")
Â  Â  	 else:
Â  Â  	 	 marcado.append(tok)
Â  Â  resultado = ""
Â  Â  for i, tok in enumerate(marcado):
Â  Â  	 if i == 0:
Â  Â  	 	 resultado += tok
Â  Â  	 	 continue
Â  Â  	 tok_anterior_raw = re.sub(r'^<mark[^>]*>|</mark>$', '', marcado[i-1])
Â  Â  	 raw_tok = re.sub(r'^<mark[^>]*>|</mark>$', '', tok)
Â  Â  	 if not re.match(r'^[.,;:!?)\\]$', raw_tok) and raw_tok != '\n' and tok_anterior_raw != '\n' and not re.match(r'^[(\\[]$', tok_anterior_raw):
Â  Â  	 	 resultado += " " + tok
Â  Â  	 else:
Â  Â  	 	 resultado += tok
Â  Â  resultado = re.sub(r"(</mark>)\s+(<mark[^>]*>)", " ", resultado)
Â  Â  return resultado

# ----------------- FORMATAÃ‡ÃƒO PARA LEITURA (v42 - Layout Melhorado - MODIFICADO) -----------------
def formatar_html_para_leitura(html_content, aplicar_numeracao=False):
Â  Â  if html_content is None:
Â  Â  	 return ""
Â  Â  
Â  Â  # --- LÃ“GICA DE TÃTULO RESTRITA (v30 - Paciente Apenas) ---
Â  Â  try:
Â  Â  	 secoes_validas = obter_secoes_por_tipo("Paciente")Â 
Â  Â  	 aliases = obter_aliases_secao()
Â  Â  	 
Â  Â  	 titulos_validos_norm = set(normalizar_titulo_para_comparacao(s) for s in secoes_validas)
Â  Â  	 titulos_validos_norm.update(normalizar_titulo_para_comparacao(a) for a in aliases.keys())
Â  Â  except NameError:
Â  Â  	 titulos_validos_norm = set()
Â  Â  # --- FIM DA LÃ“GICA DE TÃTULO ---

Â  Â  cor_titulo = "#0b5686" if aplicar_numeracao else "#0b8a3e"
Â  Â  # [v42] Melhorado: tÃ­tulo com mais destaque visual e espaÃ§amento
Â  Â  # REMOVIDO: cor_titulo da definiÃ§Ã£o base, serÃ¡ definido dinamicamente
Â  Â  estilo_titulo_base = (
Â  Â  	 f"font-family: 'Georgia', 'Times New Roman', serif; "
Â  Â  	 f"font-weight: 700; "
Â  Â  	 f"font-size: 16px; "
Â  Â  	 f"margin-top: 16px; "
Â  Â  	 f"margin-bottom: 12px; "
Â  Â  	 f"line-height: 1.4; "
Â  Â  	 f"display: block;"
Â  Â  )

Â  Â  linhas = html_content.split('\n')
Â  Â  linhas_formatadas = []
Â  Â  linha_anterior_foi_titulo = False

Â  Â  for linha in linhas:
Â  Â  	 linha_strip = linha.strip()
Â  Â  	 
Â  Â  	 if not linha_strip:
Â  Â  	 	 # [v42] Melhor controle de espaÃ§amento apÃ³s tÃ­tulos
Â  Â  	 	 if not linha_anterior_foi_titulo:
Â  Â  	 	 	 linhas_formatadas.append("")Â 
Â  Â  	 	 linha_anterior_foi_titulo = False
Â  Â  	 	 continue

Â  Â  	 linha_strip_sem_tags = re.sub(r'</?(?:mark|strong)[^>]*>', '', linha_strip, flags=re.IGNORECASE).strip()
Â  Â  	 
Â  Â  	 # --- [INÃCIO DA MODIFICAÃ‡ÃƒO] ---
Â  Â  	 # LÃ³gica de detecÃ§Ã£o de tÃ­tulo modificada para usar fuzzy matching
Â  Â  	 is_title = False
Â  Â  	 if linha_strip_sem_tags:
Â  Â  	 	 linha_norm_sem_tags = normalizar_titulo_para_comparacao(linha_strip_sem_tags)
Â  Â  	 	 
Â  Â  	 	 if linha_norm_sem_tags in titulos_validos_norm:
Â  Â  	 	 	 is_title = True
Â  Â  	 	 else:
Â  Â  	 	 	 if is_titulo_secao(linha_strip_sem_tags):
Â  Â  	 	 	 	 best_score = 0
Â  Â  	 	 	 	 for valid_norm in titulos_validos_norm:
Â  Â  	 	 	 	 	 score = fuzz.ratio(linha_norm_sem_tags, valid_norm)
Â  Â  	 	 	 	 	 if score > best_score:
Â  Â  	 	 	 	 	 	 best_score = score
Â  Â  	 	 	 	 
Â  Â  	 	 	 	 if best_score > 85: # Limiar de 85
Â  Â  	 	 	 	 	 is_title = True
Â  Â  	 # --- [FIM DA MODIFICAÃ‡ÃƒO] ---

Â  Â  	 if is_title:
Â  Â  	 	 # --- [INÃCIO DA MODIFICAÃ‡ÃƒO] ---
Â  Â  	 	 # Checa se o tÃ­tulo TEM o marca-texto amarelo
Â  Â  	 	 is_divergent = '#ffff99' in linha_strip
Â  Â  	 	 
Â  Â  	 	 # Define a cor do texto: Se for divergente, usa PRETO. SenÃ£o, usa a cor padrÃ£o.
Â  Â  	 	 cor_atual = "#000000" if is_divergent else cor_titulo
Â  Â  	 	 
Â  Â  	 	 # Monta o estilo final com a cor correta
Â  Â  	 	 estilo_titulo_inline_atualizado = f"{estilo_titulo_base} color: {cor_atual};"
Â  Â  	 	 # --- [FIM DA MODIFICAÃ‡ÃƒO] ---

Â  Â  	 	 titulo_formatado = linha_strip
Â  Â  	 	 
Â  Â  	 	 # [v42] Melhorado: remove TODAS as quebras de linha internas e normaliza espaÃ§os
Â  Â  	 	 titulo_formatado = titulo_formatado.replace("\n", " ")
Â  Â  	 	 titulo_formatado = titulo_formatado.replace("<br>", " ")
Â  Â  	 	 titulo_formatado = titulo_formatado.replace("<br/>", " ")
button_formatado = re.sub(r'\s+', ' ', titulo_formatado)Â  # Normaliza mÃºltiplos espaÃ§os

Â  Â  	 	 if not aplicar_numeracao:
Â  Â  	 	 	 # Remove numeraÃ§Ã£o preservando tags <mark>
Â  Â  	 	 	 titulo_formatado = re.sub(r'^\s*(<mark[^>]*>)?\s*\d+\s*[\.\-)]*\s*(</mark>)?', r'\1\2', titulo_formatado, flags=re.IGNORECASE)
Â  Â  	 	 	 titulo_formatado = re.sub(r'^\s*\d+\s*[\.\-)]*\s*', '', titulo_formatado)
Â  Â  	 	 
Â  Â  	 	 # [v42] Adiciona margem superior para separar do conteÃºdo anterior
Â  Â  	 	 if linhas_formatadas and linhas_formatadas[-1]:
Â  Â  	 	 	 linhas_formatadas.append("")Â  # EspaÃ§o antes do tÃ­tulo
Â  Â  	 	 
Â  Â  	 	 # Usa o estilo ATUALIZADO
Â  Â  	 	 linhas_formatadas.append(f'<div style="{estilo_titulo_inline_atualizado}">{titulo_formatado.strip()}</div>')
Â  Â  	 	 linha_anterior_foi_titulo = True
Â  Â  	 
Â  Â  	 else:
Â  Â  	 	 linhas_formatadas.append(linha_strip)
Â  Â  	 	 linha_anterior_foi_titulo = False
Â  Â  
Â  Â  # [v42] Melhorado: junta com <br> e faz limpeza mais eficiente
Â  Â  html_content_final = "<br>".join(linhas_formatadas)
Â  Â  
Â  Â  # Remove mÃºltiplas quebras consecutivas (mantÃ©m no mÃ¡ximo 2)
Â  Â  html_content_final = re.sub(r'(<br\s*/?>\s*){3,}', '<br><br>', html_content_final)
Â  Â  # Remove quebras no inÃ­cio
Â  Â  html_content_final = re.sub(r'^\s*(<br\s*/?>\s*)+', '', html_content_final)
Â  Â  # Remove quebras no final
Â  Â  html_content_final = re.sub(r'(<br\s*/?>\s*)+$', '', html_content_final)
Â  Â  
Â  Â  return html_content_final
# ----------------- MARCAÃ‡ÃƒO HTML (FUNÃ‡ÃƒO AUSENTE) -----------------
def marcar_divergencias_html(texto_original, secoes_problema_lista_dicionarios, erros_ortograficos, tipo_bula, eh_referencia):
Â  Â  """
Â  Â  Recria o texto HTML completo, marcando seÃ§Ãµes divergentes e erros ortogrÃ¡ficos.
Â  Â  Usa a funÃ§Ã£o 'marcar_diferencas_palavra_por_palavra' para as seÃ§Ãµes com 'status' == 'diferente'.
Â  Â  """
Â  Â  if not texto_original:
Â  Â  	 return ""

Â  Â  secoes_esperadas = obter_secoes_por_tipo(tipo_bula)
Â  Â  secoes_ignorar_comp = [s.upper() for s in obter_secoes_ignorar_comparacao()]
Â  Â  
Â  Â  # Mapear o texto que estamos processando (Ref ou Belfar)
Â  Â  # v40 - Usando o texto PRÃ‰-PROCESSADO por 'corrigir_quebras_em_titulos'
Â  Â  linhas_texto = re.sub(r'\n{2,}', '\n', texto_original).split('\n')
Â  Â  mapa_secoes_texto = mapear_secoes(texto_original, secoes_esperadas)

Â  Â  # Criar um lookup rÃ¡pido para os problemas
Â  Â  problemas_lookup = {item['secao']: item for item in secoes_problema_lista_dicionarios}

Â  Â  texto_html_final_secoes = {}
Â  Â  
Â  Â  # 1. Processar todas as seÃ§Ãµes encontradas no texto original
Â  Â  for i, secao_info in enumerate(mapa_secoes_texto):
Â  Â  	 secao_canonico = secao_info['canonico']
Â  Â  	 
Â  Â  	 # Obter o conteÃºdo completo desta seÃ§Ã£o (com tÃ­tulo)
Â  Â  	 # v40 - Usando o 'obter_dados_secao' corrigido
Â  Â  	 encontrou, titulo, conteudo_secao_atual = obter_dados_secao(secao_canonico, mapa_secoes_texto, linhas_texto)
Â  Â  	 
Â  Â  	 if not encontrou:
Â  Â  	 	 continue

Â  Â  	 item_problema = problemas_lookup.get(secao_canonico)

Â  Â  	 # Se a seÃ§Ã£o Ã© problemÃ¡tica (diferente) E NÃƒO Ã© ignorada
Â  Â  	 # (GraÃ§as Ã  modificaÃ§Ã£o, 'status' == 'diferente' agora tambÃ©m se o tÃ­tulo for diferente)
Â  Â  	 if item_problema and item_problema['status'] == 'diferente' and secao_canonico.upper() not in secoes_ignorar_comp:
Â  Â  	 	 texto_ref_problema = item_problema.get('conteudo_ref', '')
Â  Â  	 	 texto_bel_problema = item_problema.get('conteudo_belfar', '')
Â  Â  	 	 
Â  Â  	 	 # Usamos a funÃ§Ã£o jÃ¡ existente para marcar as palavras
Â  Â  	 	 html_marcado = marcar_diferencas_palavra_por_palavra(
Â  Â  	 	 	 texto_ref_problema,Â 
Â  Â  	 	 	 texto_bel_problema,Â 
Â  Â  	 	 	 eh_referencia=eh_referencia
Â  Â  	 	 )
Â  Â  	 	 texto_html_final_secoes[secao_canonico] = html_marcado
Â  Â  	 
Â  Â  	 # Se nÃ£o Ã© problemÃ¡tica, ou Ã© ignorada, apenas adiciona o conteÃºdo original
Â  Â  	 # (O conteÃºdo 'belfar' jÃ¡ pode conter o tÃ­tulo destacado, se for diferente)
Â  	 	 else:
Â  Â  	 	 if eh_referencia:
Â  Â  	 	 	 	texto_html_final_secoes[secao_canonico] = item_problema.get('conteudo_ref', conteudo_secao_atual) if item_problema else conteudo_secao_atual
Â  Â  	 	 else:
Â  Â  	 	 	 	texto_html_final_secoes[secao_canonico] = item_problema.get('conteudo_belfar', conteudo_secao_atual) if item_problema else conteudo_secao_atual


Â  Â  # 2. Reconstruir o texto na ordem que foi encontrado no arquivo
Â  Â  html_bruto = "\n\n".join(texto_html_final_secoes.get(m['canonico'], '') for m in mapa_secoes_texto if m['canonico'] in texto_html_final_secoes)

Â  Â  # 3. Aplicar marcaÃ§Ã£o de erros ortogrÃ¡ficos (apenas no texto Belfar)
Â  Â  if not eh_referencia and erros_ortograficos:
Â  Â  	 import html
Â  Â  	 # Regex para encontrar as palavras de erro, mas evitando estar dentro de tags HTML
Â  Â  	 try:
Â  Â  	 	 palavras_regex = r'\b(' + '|'.join(re.escape(e) for e in erros_ortograficos) + r')\b'
Â  Â  	 	 
Â  Â  	 	 partes = re.split(r'(<[^>]+>)', html_bruto) # Divide por tags HTML
Â  Â  	 	 resultado_final = []
Â  Â  	 	 for parte in partes:
Â  Â  	 	 	 if parte.startswith('<'):
Â  Â  	 	 	 	 resultado_final.append(parte) # Ã‰ uma tag, mantÃ©m
Â  Â  	 	 	 else:
Â  Â  	 	 	 	 # NÃ£o Ã© uma tag, aplicar regex de ortografia
Â  Â  	 	 	 	 parte_escapada = html.unescape(parte)
Â  Â  	 	 	 	 parte_marcada = re.sub(
Â  Â  	 	 	 	 	 palavras_regex,Â 
Â  Â  	 Â  	 	 	 	 lambda m: f"<mark style='background-color: #ffcccb; padding: 2px; border: 1px dashed red;'>{m.group(1)}</mark>",Â 
Â  Â  	 Â  	 	 	 	 parte_escapada,Â 
Â  Â  	 Â  	 	 	 	 flags=re.IGNORECASE
Â  Â  	 	 	 	 )
Â  Â  	 	 	 	 resultado_final.append(parte_marcada)
Â  Â  	 	 html_bruto = "".join(resultado_final)
Â  Â  	 except re.error:
Â  Â  	 	 # Evita que um regex mal formado (ex: palavra com caractere especial) quebre a app
Â  Â  	 	 passÂ 

Â  Â  return html_bruto

# ----------------- GERAÃ‡ÃƒO DE RELATÃ“RIO E UI (mantido layout original) -----------------
def gerar_relatorio_final(texto_ref, texto_belfar, nome_ref, nome_belfar, tipo_bula):
Â  Â  st.header("RelatÃ³rio de Auditoria Inteligente")
Â  Â  # A 'diferencas_titulos' agora Ã© usada pela 'verificar_secoes_e_conteudo' para definir o status
Â  Â  secoes_faltantes, relatorio_comparacao_completo, similaridades, diferencas_titulos = verificar_secoes_e_conteudo(texto_ref, texto_belfar, tipo_bula)
Â  Â  erros_ortograficos = checar_ortografia_inteligente(texto_belfar, texto_ref, tipo_bula)
Â  Â  score_similaridade_conteudo = sum(similaridades) / len(similaridades) if similaridades else 100.0

Â  Â  st.subheader("Dashboard de Veredito")
Â  Â  col1, col2, col3, col4 = st.columns(4)
Â  Â  col1.metric("Conformidade de ConteÃºdo", f"{score_similaridade_conteudo:.0f}%")
Â  Â  col2.metric("Erros OrtogrÃ¡ficos", len(erros_ortograficos))
Â  Â  
Â  Â  # Regex para a mÃ©trica (apenas para extrair a data)
Â  Â  rx_metrica = r"(aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova\w+\s+na\s+anvisa:)\s*([\d]{1,2}/[\d]{1,2}/[\d]{2,4})"
Â  Â  match_ref = re.search(rx_metrica, (texto_ref or "").lower())
Â  Â  match_bel = re.search(rx_metrica, (texto_belfar or "").lower())
Â  Â  data_ref = match_ref.group(2) if match_ref else "NÃ£o encontrada"
Â  Â  data_bel = match_bel.group(2) if match_bel else "NÃ£o encontrada"
Â  Â  col3.metric("Data ANVISA (Ref)", data_ref)
Â  Â  col4.metric("SeÃ§Ãµes Faltantes", f"{len(secoes_faltantes)}")

Â  Â  st.divider()
Â  Â  st.subheader("AnÃ¡lise Detalhada SeÃ§Ã£o por SeÃ§Ã£o")

Â  Â  expander_caixa_style = (
Â  Â  	 "height: 350px; overflow-y: auto; border: 2px solid #d0d0d0; border-radius: 6px; "
Â  Â  	 "padding: 16px; background-color: #ffffff; font-size: 14px; line-height: 1.8; "
Â  Â  	 "font-family: 'Georgia', 'Times New Roman', serif; text-align: left;"
Â  Â  	 "overflow-wrap: break-word; word-break: break-word;"
Â  Â  )

Â  Â  if secoes_faltantes:
Â  Â  	 st.error(f"ğŸš¨ **SeÃ§Ãµes faltantes na bula Arquivo MKT ({len(secoes_faltantes)})**:\n" + "\n".join([f"Â  - {s}" for s in secoes_faltantes]))
Â  Â  else:
Â  Â  	 st.success("âœ… Todas as seÃ§Ãµes obrigatÃ³rias estÃ£o presentes")

Â  Â  st.markdown("---")

Â  Â  for item in relatorio_comparacao_completo:
Â  Â  	 secao_nome = item['secao']
Â  Â  	 status = item['status']
Â  Â  	 conteudo_ref_str = item.get('conteudo_ref') or ""
Â  Â  	 conteudo_belfar_str = item.get('conteudo_belfar') or ""
Â  Â  	 is_ignored_section = secao_nome.upper() in [s.upper() for s in obter_secoes_ignorar_comparacao()]

Â  Â  	 if status == 'diferente':
Â  Â  	 	 with st.expander(f"ğŸ“„ {secao_nome} - âŒ CONTEÃšDO DIVERGENTE"):
Â  Â  	 	 	 c1, c2 = st.columns(2)
Â  Â  	 	 	 with c1:
Â  Â  	 	 	 	 st.markdown("**Arquivo ANVISA:**")
Â  Â  	 	 	 	 # --- [INÃCIO DA CORREÃ‡ÃƒO] ---
Â  Â  	 	 	 	 # 1. Aplicar o marca-texto de diferenÃ§as
Â  Â  	 	 	 	 html_ref_com_marcas = marcar_diferencas_palavra_por_palavra(
Â  Â  	 	 	 	 	 conteudo_ref_str, 
Â  Â  	 	 	 	 	 conteudo_belfar_str, 
Â  Â  	 	 	 	 	 eh_referencia=True
Â  Â  	 	 	 	 )
Â  Â  	 	 	 	 # 2. Formatar o HTML (que agora contÃ©m as marcas) para exibiÃ§Ã£o
Â  Â  	 	 	 	 html_ref = formatar_html_para_leitura(html_ref_com_marcas, aplicar_numeracao=True)
Â  Â  	 	 	 	 st.markdown(f"<div style='{expander_caixa_style}'>{html_ref}</div>", unsafe_allow_html=True)
Â  Â  	 	 	 	 # --- [FIM DA CORREÃ‡ÃƒO] ---
Â  Â  	 	 	 with c2:
Â  Â  	 	 	 	 st.markdown("**Arquivo MKT:**")
Â  Â  	 	 	 	 # --- [INÃCIO DA CORREÃ‡ÃƒO] ---
Â  Â  	 	 	 	 # 1. Aplicar o marca-texto de diferenÃ§as
Â  Â  	 	 	 	 html_bel_com_marcas = marcar_diferencas_palavra_por_palavra(
Â  Â  	 	 	 	 	 conteudo_ref_str, 
Â  Â  	 	 	 	 	 conteudo_belfar_str, 
Â  Â  	 	 	 	 	 eh_referencia=False
Â  Â  	 	 	 	 )
Â  Â  	 	 	 	 # 2. Formatar o HTML (que agora contÃ©m as marcas) para exibiÃ§Ã£o
Â  Â  	 	 	 	 html_bel = formatar_html_para_leitura(html_bel_com_marcas, aplicar_numeracao=False)
Â  Â  	 	 	 	 st.markdown(f"<div style='{expander_caixa_style}'>{html_bel}</div>", unsafe_allow_html=True)
Â  Â  	 	 	 	 # --- [FIM DA CORREÃ‡ÃƒO] ---
Â  Â  	 else:
Â  Â  	 	 expander_title = f"ğŸ“„ {secao_nome} - âœ… CONTEÃšDO IDÃŠNTICO"
Â  Â  	 	 if is_ignored_section:
Â  Â  	 	 	 expander_title = f"ğŸ“„ {secao_nome} - âœ”ï¸ NÃƒO CONFERIDO (Regra de NegÃ³cio)"
Â  Â  	 	 with st.expander(expander_title):
Â  Â  	 	 	 c1, c2 = st.columns(2)
Â  Â  	 	 	 with c1:
Â  Â  	 	 	 	 st.markdown("**Arquivo ANVISA:**")
Â  Â  	 	 	 	 # (Aqui nÃ£o precisa de marca-texto, pois o status Ã© 'identica')
Â  Â  	 	 	 	 html_ref = formatar_html_para_leitura(conteudo_ref_str, aplicar_numeracao=True)
Â  Â  	 	 	 	 st.markdown(f"<div style='{expander_caixa_style}'>{html_ref}</div>", unsafe_allow_html=True)
Â  Â  	 	 	 with c2:
Â  Â  	 	 	 	 st.markdown("**Arquivo MKT:**")
Â  Â  	 	 	 	 # (Aqui nÃ£o precisa de marca-texto, pois o status Ã© 'identica')
Â  Â  	 	 	 	 html_bel = formatar_html_para_leitura(conteudo_belfar_str, aplicar_numeracao=False)
Â  Â  	 	 	 	 st.markdown(f"<div style='{expander_caixa_style}'>{html_bel}</div>", unsafe_allow_html=True)

Â  Â  if erros_ortograficos:
Â  Â  	 st.info(f"ğŸ“ **PossÃ­veis erros ortogrÃ¡ficos ({len(erros_ortograficos)} palavras):**\n" + ", ".join(erros_ortograficos))

Â  Â  st.divider()
Â  Â  st.subheader("ğŸ¨ VisualizaÃ§Ã£o Lado a Lado com Destaques")

Â  Â  # --- [INÃCIO DA LÃ“GICA DE DESTAQUE AZUL DA ANVISA] ---
Â  Â  
Â  Â  # 1. Definir o regex para encontrar a data da ANVISA (Grupo 1 captura tudo)
Â  Â  rx_anvisa_highlight = r"((?:aprovad[ao]\s+pela\s+anvisa\s+em|data\s+de\s+aprova\w+\s+na\s+anvisa:)\s*[\d]{1,2}\s*/\s*[\d]{1,2}\s*/\s*[\d]{2,4})"
Â  Â  
Â  Â  # 2. Aplicar placeholders ÃšNICOS no texto original (case-insensitive)
Â  Â  #Â  Â  'texto_ref' e 'texto_belfar' sÃ£o os argumentos da funÃ§Ã£o (o texto processado v40)
Â  Â  texto_ref_com_placeholder = re.sub(rx_anvisa_highlight, r"__ANVISA_START__\1__ANVISA_END__", texto_ref or "", flags=re.IGNORECASE)
Â  Â  texto_belfar_com_placeholder = re.sub(rx_anvisa_highlight, r"__ANVISA_START__\1__ANVISA_END__", texto_belfar or "", flags=re.IGNORECASE)

Â  Â  # 3. Passar os textos com placeholders para a funÃ§Ã£o de marcaÃ§Ã£o de diff/ortografia
Â  Â  html_ref_bruto = marcar_divergencias_html(texto_original=texto_ref_com_placeholder, secoes_problema_lista_dicionarios=relatorio_comparacao_completo, erros_ortograficos=[], tipo_bula=tipo_bula, eh_referencia=True)
Â  Â  html_belfar_marcado_bruto = marcar_divergencias_html(texto_original=texto_belfar_com_placeholder, secoes_problema_lista_dicionarios=relatorio_comparacao_completo, erros_ortograficos=erros_ortograficos, tipo_bula=tipo_bula, eh_referencia=False)

Â  Â  # 4. Definir o estilo do highlight azul e substituir os placeholders pelo HTML final
Â  Â  blue_highlight_style = "background-color: #DDEEFF; padding: 1px 3px; border: 1px solid #0000FF; border-radius: 3px;"
Â  Â  
Â  Â  html_ref_bruto = html_ref_bruto.replace("__ANVISA_START__", f"<mark style='{blue_highlight_style}'>")
Â  Â  html_ref_bruto = html_ref_bruto.replace("__ANVISA_END__", "</mark>")
Â  Â  
Â  Â  html_belfar_marcado_bruto = html_belfar_marcado_bruto.replace("__ANVISA_START__", f"<mark style='{blue_highlight_style}'>")
Â  Â  html_belfar_marcado_bruto = html_belfar_marcado_bruto.replace("__ANVISA_END__", "</mark>")
Â  Â  
Â  Â  # --- [FIM DA LÃ“GICA DE DESTAQUE AZUL DA ANVISA] ---


Â  Â  # [CORREÃ‡ÃƒO v31] - Simplificado, sem tipo_bula
Â  Â  # Agora formatamos o HTML que jÃ¡ contÃ©m os destaques (amarelo, vermelho E azul)
Â  Â  html_ref_marcado = formatar_html_para_leitura(html_ref_bruto, aplicar_numeracao=True)
Â  Â  html_belfar_marcado = formatar_html_para_leitura(html_belfar_marcado_bruto, aplicar_numeracao=False)

Â  Â  caixa_style = (
Â  	 	 "max-height: 700px; overflow-y: auto; border: 1px solid #e0e0e0; border-radius: 8px; padding: 20px 24px; "
Â  	 	 "background-color: #ffffff; font-size: 15px; line-height: 1.7; box-shadow: 0 4px 12px rgba(0,0,0,0.08);"
Â  	 	 "text-align: left; overflow-wrap: break-word; word-break: break-word;"
Â  Â  )
Â  Â  title_style = ("font-size: 1.25rem; font-weight: 600; margin-bottom: 8px; color: #31333F;")

Â  Â  col1, col2 = st.columns(2, gap="large")
Â  Â  with col1:
Â  Â  	 st.markdown(f"<div style='{title_style}'>{nome_ref}</div>", unsafe_allow_html=True)
Â  Â  	 st.markdown(f"<div style='{caixa_style}'>{html_ref_marcado}</div>", unsafe_allow_html=True)
Â  Â  with col2:
Â  Â  	 st.markdown(f"<div style='{title_style}'>{nome_belfar}</div>", unsafe_allow_html=True)
Â  Â  	 st.markdown(f"<div style='{caixa_style}'>{html_belfar_marcado}</div>", unsafe_allow_html=True)

# ----------------- INTERFACE PRINCIPAL (UI) (v31 - Paciente Apenas) -----------------
st.set_page_config(layout="wide", page_title="Auditoria de Bulas", page_icon="ğŸ”¬")
st.title("ğŸ”¬ InteligÃªncia Artificial para Auditoria de Bulas")
st.markdown("Envie o arquivo da ANVISA (pdf/docx) e o PDF Marketing (MKT).")

st.divider()
# [CORREÃ‡ÃƒO v30] - Removido st.radio, hardcoded para "Paciente"
tipo_bula_selecionado = "Paciente"Â 

col1, col2 = st.columns(2)
with col1:
Â  Â  st.subheader("ğŸ“„ Arquivo ANVISA")
Â  Â  pdf_ref = st.file_uploader("Envie o arquivo da Anvisa (.docx ou .pdf)", type=["docx", "pdf"], key="ref")
with col2:
Â  Â  st.subheader("ğŸ“„ Arquivo MKT")
Â  Â  pdf_belfar = st.file_uploader("Envie o PDF do Marketing", type="pdf", key="belfar")

if st.button("ğŸ” Iniciar Auditoria Completa", use_container_width=True, type="primary"):
Â  Â  if not (pdf_ref and pdf_belfar):
Â  Â  	 st.warning("âš ï¸ Por favor, envie ambos os arquivos para iniciar a auditoria.")
Â  Â  else:
Â  Â  	 with st.spinner("ğŸ”„ Processando e analisando as bulas..."):
Â  Â  	 	 tipo_arquivo_ref = 'docx' if pdf_ref.name.lower().endswith('.docx') else 'pdf'
Â  Â  	 	 
Â  Â  	 	 # [v40] Texto RAW Ã© extraÃ­do
Â  Â  	 	 texto_ref_raw, erro_ref = extrair_texto(pdf_ref, tipo_arquivo_ref, is_marketing_pdf=False)
Â  Â  	 	 texto_belfar_raw, erro_belfar = extrair_texto(pdf_belfar, 'pdf', is_marketing_pdf=True)
Â  Â  	 	 
Â  Â  	 	 texto_ref_processado = texto_ref_raw
Â  Â  	 	 texto_belfar_processado = texto_belfar_raw

Â  Â  	 	 if not erro_ref:
Â  Â  	 	 	 # [CORREÃ‡ÃƒO v40] RE-ATIVADO para prÃ©-processar
Â  Â  	 	 	 texto_ref_processado = corrigir_quebras_em_titulos(texto_ref_raw)
Â  Â  	 	 	 texto_ref_processado = truncar_apos_anvisa(texto_ref_processado)
Â  Â  	 	 if not erro_belfar:
Â  Â  	 	 	 # [CORREÃ‡ÃƒO v40] RE-ATIVADO para prÃ©-processar
Â  Â  	 	 	 texto_belfar_processado = corrigir_quebras_em_titulos(texto_belfar_raw)
Â  Â  	 	 	 texto_belfar_processado = truncar_apos_anvisa(texto_belfar_processado)

Â  Â  	 	 if erro_ref or erro_belfar:
Â  Â  	 	 	 st.error(f"Erro ao processar arquivos: {erro_ref or erro_belfar}")
Â  Â  	 	 elif not texto_ref_processado or not texto_belfar_processado:
Â  Â  	 	 	 st.error("Erro: Um dos arquivos estÃ¡ vazio ou nÃ£o pÃ´de ser lido corretamente.")
Â  	 	 	 else:
Â  Â  	 	 	 # [v40] Passa o texto PRÃ‰-PROCESSADO para o verificador
Â  Â  	 	 	 gerar_relatorio_final(texto_ref_processado, texto_belfar_processado, pdf_ref.name, pdf_belfar.name, tipo_bula_selecionado)

st.divider()
st.caption("Sistema de Auditoria de Bulas v40 | Mapeamento PrÃ©-processado (Corrigido).")
